---
title: "Redundancy analysis (RDA)"
subtitle: "Selection of the climatic variables, variance partitionning & identification of outlier SNPs"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::html_document2:
    df_print: kable
    fig.caption: yes
    number-sections: true
    toc: yes
    toc_depth: 4
    #toc_float:
    #  collapsed: no
editor_options:
  chunk_output_type: console
bibliography: references.bib
always_allow_html: true
---

```{css, echo=FALSE}
pre {
  max-height: 150px;
  overflow-y: auto;
  overflow-x: auto;
  font-size: 10px;
}

body{
  font-size: 12px;
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=F)
options(width = 300)
library(knitr)
library(kableExtra)
library(dplyr)
library(psych)
library(tidyverse)
library(raster)
library(stringr)
library(ggbiplot)
library(corrplot)
library(vegan)
library(xtable)
library(reshape2)
library(robust)
library(qvalue)
library(ggpubr)
library(magrittr)
library(readxl)
library(ggridges)
library(treemap)
library(RColorBrewer)
library(cowplot)
library(ggVennDiagram)
library(adespatial) # to calculate the Moran eigen vectors
library(here)
library(geosphere) # to calculate geodesic distances among population locations
library(geodist) # to calculate geodesic distances among population locations

# my own functions
source(here("scripts/functions/kable_mydf.R")) # building pretty tables for the html
source(here("scripts/functions/extract_climatedt_metadata.R")) # extracting meta data of the climatic variables in ClimateDT
```

```{r Functions, echo=F}
# Functions from other sources:
source(here("scripts/functions/corpmat.R")) # to compute the matrix of p-value
source(here("scripts/functions/rdadapt.R")) # to conduct a RDA based genome scan (from Capblancq & Forester 2021)
source(here("scripts/functions/detectoutliers.R")) # to identify outliers based on their RDA loadings (from  Forester et al. 2018)

# Function to generate a corrplot in png
# ======================================
make_corrplot <- function(df,variables,fig_options){
  
  # correlation matrix
  cor <- cor(df[,variables]) 
  
  # matrix of the p-value of the correlation
  pmat <- corpmat(cor)

  # Generate a correlation plot
  png(filename=fig_options$path,
      width=fig_options$width,
      height=fig_options$height,
      res=fig_options$res)
  corrplot::corrplot(cor, 
                     method="color", 
                     col=colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))(200),
                     type="upper", 
                     order="hclust",
                     addCoef.col = "black", # Add coefficient of correlation
                     tl.col="black", 
                     tl.srt=45, #Text label color and rotation
                   
                     # Combine with significance
                     p.mat = pmat, 
                     sig.level = 0.01, 
                     insig = "blank",
                     
                     # hide correlation coefficient on the principal diagonal
                     diag=FALSE,
                     number.cex=0.6)
  dev.off()
  
}

# Function to generate a corrplot in pdf
# ======================================
make_corrplot_pdf <- function(df,variables,fig_options){
  
  # correlation matrix
  cor <- cor(df[,variables]) 
  
  # matrix of the p-value of the correlation
  pmat <- corpmat(cor)

  # Generate a correlation plot
  pdf(file=fig_options$path,
      width=fig_options$width,
      height=fig_options$height)
  corrplot::corrplot(cor, 
                     method="color", 
                     col=colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))(200),
                     type="upper", 
                     order="hclust",
                     addCoef.col = "black", # Add coefficient of correlation
                     tl.col="black", 
                     tl.srt=45, #Text label color and rotation
                   
                     # Combine with significance
                     p.mat = pmat, 
                     sig.level = 0.01, 
                     mar=c(0,0,0,0),
                     insig = "blank",
                     
                     # hide correlation coefficient on the principal diagonal
                     diag=FALSE,
                     number.cex=0.6)
  dev.off()
  
}
```


# Introduction

Most analyses conducted in this document are based on:

  - @forester2018comparing and the associated [vignette](https://popgen.nescent.org/2018-03-27_RDA_GEA.html). 
  
  - @capblancq2021redundancy and the associated [Github repository](https://github.com/Capblancq/RDA-landscape-genomics).
  
  - @capblancqEvaluationRedundancyAnalysis2018
  

RDA can either be performed on *individual-based genotypes* (i.e. allele counts 0, 1 or 2) or *population-based allele frequencies*. @forester2018comparing suggests to use individual-based allele counts when most samples have individual coordinates and individual environment data (which depends on the resolution of the environmental data across the study area). 

In the present study, we use *population-level allele frequencies* as several genotypes were collected at each sampling site (i.e. source population) and therefore experience the same climatic conditions. Moreover, the sample sizes varies across populations.

**Comment:** when I first conducted these analyses (in the third chapter of my PhD), I used *individual-based genotypes* because I accounted for the neutral population genetic structure with the ancestry coefficients from @jaramillo2015molecular, which are at the genotype level (i.e. proportion of gene pool assignment for each genotype). As the population genetic structure is highly confounded with the climatic gradients across the populations sampled (see section \@ref(VarPart)), correcting for population structure with the ancestry coefficient most likely resulted in overcorrection for population structure. In this document, we only use the *individual-based allele counts* for variance partitioning in section \@ref(VarPart), in which we estimate the relative contribution of climate, population structure and geography.

**Choices made in this document:**

  - Number of PC axes included in the pRDA to account for the population genetic structure: see section \@ref(PCscores). 
  
```{r SetNbPCscores}
nb_PCscores <- 3
```
  
# Downloading the data

## Genomic data


```{r LoadGenomicData}
# Individual-based allele counts
# ==============================
geno_ind <- read.csv(here("data/DryadRepo/ImputedGenomicData_AlleleCounts_withoutmaf.csv"),row.names = 1) %>% 
  t() %>% 
  as.data.frame()

kable_mydf(geno_ind[1:10,1:10], boldfirstcolumn = T)


# Population-based allele frequencies
# ===================================
geno_pop <- read.csv(here("data/DryadRepo/ImputedGenomicData_AlleleFrequencies_withoutmaf.csv"),
                     row.names = 1)

kable_mydf(geno_pop[1:10,1:10] %>% round(3), boldfirstcolumn = T)
```

The genomic dataset with *individual-based allele counts* contains `r nrow(geno_ind)` clones (i.e. genotypes) and `r ncol(geno_ind)` SNPs. The genomic dataset with *population-based allele frequencies* contains `r nrow(geno_pop)` populations and `r ncol(geno_pop)` SNPs.

RDA requires complete data frames (i.e., no missing data). Missing data were imputed based on the main gene pool of the clone, i.e. using the most common allele at each SNP (see report `1_FormattingGenomicData.Rmd`).

## Climatic data


### Load ClimateDT data 

Climatic data comes from the [Climate Downscaling Tool (ClimateDT)](https://www.ibbr.cnr.it/climate-dt/) and were provided by Maurizio Marchi (CREA, Italy). The full description of the climatic variables is available [here](https://www.ibbr.cnr.it/climate-dt/?action=fldlist). 

In this document, we used the **point estimate climatic data not adjusted for elevation**.

**Reference period:** The climatic conditions at the location of the populations (i.e. climatic conditions under which the populations have evolved) correspond to the mean climatic conditions across the period **1901-1950**.

The dataset which contains the climatic data also contains the geographical coordinates and elevation of the populations, and dbMEMs.

```{r LoadClimateDToutputs}
clim <- readRDS(here("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationPointEstimates_ReferencePeriods_noADJ.rds"))[[1]]$ref_means %>% 
  dplyr::select(-contains("tmn"),-contains("tmx"),-contains("prc"))

kable_mydf(clim[1:10,1:10], boldfirstcolumn = F)

extract_climatedt_metadata(var_clim = clim %>% dplyr::select(-pop,-contains("ude")) %>% colnames()) %>% 
  dplyr::select(label,description,unit) %>% 
  set_colnames(str_to_title(colnames(.))) %>% 
  kable_mydf(font_size = 12)
```

### Distance-based Moran's Eigenvector Maps (dbMEMs)

Some papers/resources :

 - The vignette [Moran’s Eigenvector Maps and related methods for the spatial multiscale analysis of ecological data](https://cran.r-project.org/web/packages/adespatial/vignettes/tutorial.html) by Stéphane Dray.

 - @draySpatialModellingComprehensive2006
 
 - @forester2018comparing
 
 - @gutakerGenomicHistoryEcology2020
 
 - @laskyGenomeenvironmentAssociationsSorghum2015
 
Moran’s Eigenvector Maps (MEMs) are calculated based on a spatial weighting matrix (SWM) and are orthogonal vectors maximizing the spatial autocorrelation (measured by Moran’s coefficient) of the sampled locations. Distance-based MEMs are calculated based on a particular SWM which is a geographic distance matrix. 
 
We first calculate a matrix of geodesic distances (in meters) among population locations using [great-circle distances](https://en.wikipedia.org/wiki/Great-circle_distance) calculated for the WGS84 ellipsoid. The shortest path between two points on an ellipsoid is called the geodesic. The WGS84 ellipsoid is the best available global ellipsoid.
We compared the distances calculated with the function `geodist`of the R package `geodist` and the function `distm` from the R package `geosphere`. 

```{r CalculateGeodesicDistancesAmongPopulationLocations}
# convert long-lat coordinates to a matrix of geodesic distances in meters

# 1) with the R package geodist
geodist(clim[,c("longitude","latitude")], measure = "geodesic")  %>% .[1:4,1:4]

# 2) with the R package geoshere
distm(clim[,c("longitude","latitude")], fun = distGeo) %>% .[1:4,1:4]
```

The two functions give the same results :)

We then calculate the dbMEMs with the function `dbmem` of the `adespatial` R package. Similarly to @laskyGenomeenvironmentAssociationsSorghum2015, we only keep MEMs with positive eigenvalues. 

```{r CalculatedbMEMswithGeodesicDistances, eval = T}
# to calculate dbMEMs using geodesic distances and  keep only positive eigenvalues
dbmems <- distm(clim[,c("longitude","latitude")], fun = distGeo) %>% as.dist() %>%  dbmem(MEM.autocor = "positive")
```

We get a message informing the we do not use Euclidean distances. I think this is ok: we do not have to convert geodesic distances to Euclidean distances.

```{r CalculatedbMEMswithEuclideanDistances, eval = F}
# to calculate dbMEMs using Euclidean distances and  keep only positive eigenvalues
dbmems <- distm(clim[,c("longitude","latitude")], fun = distGeo) %>% dist(method="euclidean") %>%  dbmem(MEM.autocor = "positive")
```

We add the dbMEMs to the dataset with the climatic variables:

```{r AdddbMEMsToClimDataset}
clim <- clim %>% bind_cols(dbmems)  # we add the distance-based Moran’s Eigenvector Maps (dbMEMs)
```

In the variance partitioning section, we use all the dbMEMs with positive eigenvalues: 
  
```{r SetNbdbMEMs}
nb_dbMEMs <- dim(dbmems)[[2]]
```

### Filtering the climatic variables

```{r IdCorrelatedClimaticVariables}
# Function to identify climatic variable with a correlation coeff higher than a given threshold
identify_corr_var <- function(df,corr_threshold){

# calculate the correlation matrix among the variables
clim_cor <- df %>% 
  dplyr::select(-pop,-elevation,-contains("itude")) %>% 
  cor()

# attribute NA to the lower triangle and diagonal of the matrix
clim_cor[lower.tri(clim_cor,diag=T)] <- NA

# build a dataframe with the correlated variables
clim_cor <- clim_cor %>% 
  melt() %>% 
  na.omit() %>% 
  dplyr::filter(value>corr_threshold)

}

# we want to identify variables with a correlation coefficient higher than:
corr_threshold <- 0.95

# we ran the function to identify the highly correlated variables
clim_cor <- identify_corr_var(df=clim,corr_threshold = corr_threshold)

kable_mydf(clim_cor, boldfirstcolumn = F)
```

`r nrow(clim_cor)` pairs of variables have a correlation coefficient higher than `r corr_threshold`.

We remove some variables so that there are no more pairs of variables with a correlation coefficient greater than `r corr_threshold`.


```{r FilteringClimVariables, results="hide"}
clim_var_to_rm <- c("bio7", # we keep bio4
                    "bio17","bio18","bio14", # we keep SP
                    "bio16","bio19", # we keep bio12
                    "bio11", # we keep bio6
                    "bio2", # we keep Eref
                    "bio10", # we keep MWMT
                    "bio13") # low biological interest

clim <- clim %>% dplyr::select(-all_of(clim_var_to_rm))

# we check that there are no more pairs of highly correlated variables
identify_corr_var(df=clim,corr_threshold = 0.95) %>% nrow()

# Export the names of the pre-selected climatic variables (for the Supplementary Information)
clim %>% 
  dplyr::select(-pop,-elevation,-contains("ude"),-contains("MEM")) %>% 
  colnames() %>% 
  saveRDS(file=here("outputs/VariableSelection/PreselectedClimaticVariableNames.rds"))
```

### Viz 

We can look at the distribution of the pre-selected climatic variables.

```{r PlotDistributionClimaticVariables, fig.height=9, fig.width=9}
p <- clim %>% 
  dplyr::select(-pop,-contains("itude"),-elevation,-contains("MEM")) %>% 
  pivot_longer(everything(),names_to="variable") %>% 
  ggplot(aes(x=value)) +  
  geom_histogram(aes(y=after_stat(density)), colour="blue",fill="white",bins = 34) +
  geom_density(alpha=.2,fill="pink") +
  facet_wrap(~variable,scales="free") + 
  theme_bw() 

p %>% ggsave(file=here("figs/ExploratoryAnalyses/DistributionPreselectedClimaticVariables.png"),
               width=15,height=12)

p
```

We also look at the correlation among the pre-selected climatic variables:

```{r CorrelationsPanels,fig.height=6,fig.width=6, results="hide"}
# Generate figures to visualize correlations among climatic variables

# ===
# PNG
# ===
fig_options <- list(
  path = here("figs/ExploratoryAnalyses/CorrplotClimVariables.png"),
  width=1000,
  height=1000,
  res=100)

make_corrplot(df = clim,
              variables = colnames(clim)[-1],
              fig_options = fig_options)

# ===
# PDF
# ===
fig_options <- list(
  path = here("figs/ExploratoryAnalyses/CorrplotClimVariables.pdf"),
  width=10,
  height=8)

make_corrplot_pdf(df = clim,
                  variables = colnames(clim)[-1],
                  fig_options = fig_options)
```

![](../figs/ExploratoryAnalyses/CorrplotClimVariables.png)

We also look at the correlation among the climatic variables with a principal component analysis:

```{r PCAClimVariables,fig.height=6,fig.width=6, results="hide"}
# Generate a PCA
pca <- prcomp(clim[,-1], center = TRUE,scale. = TRUE)

p <- ggbiplot(pca,varname.size =4) +  
  ylim(-4, 2.5) +    
  xlim(-3, 3) + 
  theme_minimal(base_size = 12)

ggsave(p,
       file=here("figs/ExploratoryAnalyses/PCAClimVariables.png"),
       width=8,height=8,
       bg="white")
p
```



## Population genetic structure

```{r LoadingInformationAboutMainGenePools}
gps <- readRDS(here("data/GenomicData/MainGenePoolInformation.rds"))
```

### Ancestry coefficients

The proportion of gene pool assignment was estimated in @jaramillo2015molecular for each genotype with the *STRUCTURE* software.

```{r GenerateListDfIndividualLevel}
# We will store two datasets in a list: one with raw variables, the other one with mean-centered variables

listdf_ind <- list()

listdf_ind$df <- gps$clon_level %>% 
  left_join(clim,by="pop") %>% # merge with the climatic variables
  dplyr::select(-main_gp_clon_code,-contains("gp_pop")) %>% 
  arrange(clon) # the clones have to be in the same order as in the genomic data.

# Run this line to check that the order of the clones in the genomic data and explanatory variables data is the same.
# identical(as.vector(listdf_ind$df$clon),rownames(geno_ind)) # should be TRUE 

listdf_ind$df[1:10,1:14] %>% 
  mutate(across(where(is.numeric), round, 2)) %>% 
  kable_mydf(boldfirstcolumn = F)

# create df with standardized variables (ie centered and scaled)
listdf_ind$dfsc <- listdf_ind$df %>% 
  dplyr::mutate(across(where(is.numeric), ~ (. - mean(.)) / sd(.)))

listdf_ind$dfsc[1:10,1:14] %>% 
  mutate(across(where(is.numeric), round, 2)) %>% 
  kable_mydf(boldfirstcolumn = F)
```


### PC scores{#PCscores}

Another way to account for population structure in the RDA models is to use PCs from a *principal component analysis* (PCA) as proxies of the population evolutionary history. This is the method used in @capblancq2021redundancy and @capblancq2023common.

As advised in @capblancq2021redundancy, the estimation of the population genetic structure should be performed on genomic data not filtered for minor allele frequencies because small genetic variations are expected to be involved in differentiating neutral genetic groups. So, we use *population-based allele frequencies* not filtered for MAF and imputed for missing data (based on the most common allele in the gene pool, see report `1_FormattingGenomicData.Rmd`).


```{r LoadImtGenDataMAF}
geno_pop_maf <-  read.csv(here("data/DryadRepo/ImputedGenomicData_AlleleFrequencies_withmaf.csv"))

kable_mydf(geno_pop_maf[1:10,1:8], boldfirstcolumn = F)
```

We run the PCA with the `rda` function of the `vegan` package, which performs a PCA when no predictor is included.

```{r RunPCA, fig.height=4,fig.width=6}
pca <- rda(geno_pop_maf[,-1], scale=T)

# Screeplot of the PCA eigenvalues
screeplot(pca, type = "barplot", npcs=10, main="PCA Eigenvalues")
```

Based on the screeplot, retaining **three** or **four** PCs may be reasonable to account for neutral population structure in downstream analyses. 

<span style="color: red;">**We keep the first `r nb_PCscores` PCs.**</span>

```{r GenerateListDfPopLevelNotScaled}
# We store two datasets in a list: one with raw variables, the other one with mean-centered variables

listdf_pop <- list()

listdf_pop$df <- data.frame(pop = geno_pop_maf[,1], # population id
                            PCs = scores(pca, choices=c(1:3), display="sites", scaling="none")) %>% #
  setNames(c("pop", "PC1", "PC2", "PC3")) %>% 
  inner_join(clim, by="pop")


# extract mean and variance of the PC scores
listdf_pop$df %>% 
  dplyr::select(contains("PC")) %>% 
  dplyr::summarise(across(everything(),list(mean=mean,sd=sd))) %>% 
  pivot_longer(everything()) %>% 
  mutate(PC = str_sub(name,1,3),
         index = str_sub(name,5,-1)) %>%
  dplyr::select(-name) %>% 
  pivot_wider(names_from="index",values_from="value") %>% 
  kable_mydf(boldfirstcolumn = F)
```

The PC scores have a mean of O but a standard deviation of 0.17, so we scale them too so that they have the same standard deviation as the climatic variables.

```{r GenerateListDfPopLevelScaled}
listdf_pop$dfsc <- listdf_pop$df %>% 
  dplyr::mutate(across(where(is.numeric), ~ (. - mean(.)) / sd(.)))

kable_mydf(listdf_pop$dfsc[1:8,1:9], boldfirstcolumn = F)
```


### Population main gene pool

```{r CreateNewColumWithMainGenePoolPopulations}
# We add the gene pool information to the dataframes in listdf_pop
listdf_pop <- listdf_pop %>% 
  modify(\(x) right_join(x,gps$pop_level,by="pop"))

saveRDS(listdf_pop, here("outputs/RDA/RDA_explanatorydataframes_PopLevel.rds"))

kable_mydf(listdf_pop$dfsc[1:8,1:7], boldfirstcolumn = F)
```

```{r DefineMainGPcolor}
# Colors of the main gene pool for the following figures (PCA and RDA)
bg <- c("orangered3","gold2","darkorchid3","navyblue","turquoise2","green3") # define the colors
GPs <- listdf_pop$df$main_gp_pop %>%  as.factor()
levels(GPs) <- list("Northern Africa" = "Q1",
                    "Corsica" = "Q2",
                    "Central Spain" = "Q3",
                    "French Atlantic" = "Q4",
                    "Iberian Atlantic" = "Q5",
                    "South-eastern Spain" = "Q6")
```


### Plot the PCA

We plot the PCA performed on **population-based allele frequencies not filtered for MAF** (section \@ref(PCscores)). The figure is stored in `PCAplot.pdf`.

```{r PlotPCA, fig.width=10,fig.height=6, results="hide"}
pdf(width=9,height=5,here("figs/RDA/PCAplot.pdf"))
par(mfrow=c(1,2),mar=c(4,4,0.5,0.5))
lapply(2:3, function(second_axis){
  plot(pca, type="n", scaling=3, choices=c(1,second_axis),
       xlab=paste0("PC1 (",round(summary(eigenvals(pca))[2,1]*100,2),"%)"),
       ylab=paste0("PC",second_axis," (",round(summary(eigenvals(pca))[2,second_axis]*100,2),"%)"))
  points(pca, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[GPs], choices=c(1,second_axis))
  if(second_axis==3) legend("bottomright", legend=levels(GPs), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg, title="Main gene pool",title.adj=0.05)
recordPlot()})
dev.off()
```


# Selecting the climatic variables

The selection procedure of the climatic variables is a critical step of the genomic offset approaches, and more generally the landscape genomic approaches. In the present study, we selected the climatic variables based on three criteria:

  - contribution to the genetic variance.
  
  - biological relevance.
  
  - exposure to climate change.
  

## Criteria 1: a predictive approach{#StepwiseSelection}

To determine which climatic variables contribute the most to explain the genetic variance, we used a *predictive approach* using *RDA with stepwise selection*, where the goal is to *maximize the genetic variance* explained by a set of predictors [@capblancq2021redundancy].

For that, we use the selection procedure from the `ordiR2step` function of the package `vegan`. 

We have to specify two models:

  - a *null* model where the response is explained only by an intercept.

  - a *full* model including all variables. 
  
In the `ordi2step` function, the default criteria for including the variables is based on both *significance* of the newly selected variables, and the comparison of *adjusted variation* ($R^2_{adj}$) explained by the selected variables to $R^2_{adj}$ explained by the full model. If the new variable is not significant or the $R^2_{adj}$ of the model including this new variable does not exceed the $R^2_{adj}$ of the full model, the selection procedure stops.

We use the following stopping criteria: variable significance of p < 0.01 using 1000 permutations, and the $R^2_{adj}$ of the full model.

```{r NumberStewiseSelectionModels}
# How many iterations of the stepwise selection procedure do we perform?
nbmodels <- 100
```

We perform `r nbmodels` iterations of the stepwise selection procedure.

```{r StepwiseSelectionPopLevel, eval=F}
# we standardize the climatic variables
climsc <- clim %>% dplyr::mutate(across(where(is.numeric), ~ (. - mean(.)) / sd(.)))

# null model
rda_null <- rda(geno_pop ~ 1, climsc)

# formula full model
formula_full_model <- colnames(climsc)[!colnames((climsc)) %in% c("pop",
                                                                  "elevation","latitude","longitude",
                                                                  paste0("MEM",1:5))] %>% 
  paste(collapse= " + ") # climatic variables
formula_full_model <- paste0("geno_pop ~ ",formula_full_model) %>% as.formula()

# full model
rda_full <- rda(formula_full_model, climsc)

# Stepwise selection with ordiR2step function
sumstepwise <- lapply(1:nbmodels, function(x) {
  mod <- ordiR2step(rda_null, rda_full, Pin = 0.01, R2permutations = 1000, R2scope = T)
  return(names(mod$CCA$envcentre))}) %>% 
  setNames(paste0("model",1:nbmodels)) %>% 
  ldply(function(x) data.frame(variables=x),.id="models") %>%  
  dplyr::summarise(count(variables)) %>% 
  setNames(c("variable","count"))

saveRDS(sumstepwise,file=here(paste0("outputs/VariableSelection/SummaryStepwiseSelection_PopLevel_",nbmodels,"models.rds")))
```

```{r SummaryStepwiseSelection}
sumstepwise <- readRDS(file=here(paste0("outputs/VariableSelection/SummaryStepwiseSelection_PopLevel_",nbmodels,"models.rds")))

kable_mydf(sumstepwise, boldfirstcolumn = F)
```


According to the stepwise selection procedure, the climatic variables that maximize the variance of the genomic data are:
  
  - `bio3`: isothermality (`bio2`/`bio7`) (x100) (index) with `bio2` the mean diurnal range (mean of monthly (max temp - min temp)) and `bio7` the temperature annual range (`bio5`-`bio6`, with `bio5` the max temperature of warmest month and `bio6` the minimum temperature of the coldest month).

  - `bio4`: temperature seasonality (standard deviation x100) (in °C).

  - `bio15`: precipitation seasonality (coefficient of Variation).
  


## Criteria 2: biological relevance to the study goals{#BioRelevance}

Reminder of the study goals:

  - *evaluate* the genomic offset predictions with different methods.
  
  - provide *GO estimates* for the studied populations to identify populations that will show the highest disruption of their current gene-environment relationships under climate change (those estimates will be provided based on the 'best performing' genomic offset predictions in the evaluation part).
  
Given the study goals, the set of selected climatic variables has to capture the changes in climatic conditions that are likely to threaten the viability of the maritime pine populations. In the context of climate change and in the Mediterranean area, it appears necessary to include climatic variables capturing the summer drought conditions. 

The set of climatic variables has also to capture the climatic conditions that are likely to drive population vulnerability (decrease in fitness) in the different evaluation parts, which may be driven by different climatic variables than the climatic variables that are likely to drive population vulnerability in natural conditions. Therefore, one option may be not to select the same climatic variables for the different study goals and evaluation methods, which is discussed below.

### Climatic variables relevant for the evaluation part{#ClimVarEvalPart}


> Evaluating genomic offset predictions with mortality data from common gardens after a strong summer drought

Differences among populations in their seedling survival in common gardens after a strong summer drought is likely to be mainly driven by their differences in adaptation to summer drought conditions. 

For this evaluation step, the genomic offset has to be calculated with climatic variables capturing the summer-drought conditions. It has also to be noted that, even though the gene-environment relationships are estimated with a set of climatic variables incorporating summer drought related variables, these variables may not be important in explaining the genomic composition across the landscape and therefore may little contribute to the genomic offset predictions. 

Therefore, I think that this evaluation part requires that the genomic offset has to be estimated with a set of climatic variables including summer drought-related variables, and that these variables should contribute to some extent to the genomic offset predictions (i.e. contribute to explaining the current genomic composition across the landscape).

In the case where summer drought-related variables do not contribute much to the genomic composition across the landscape, it could be relevant to estimate a genomic offset based only on climatic variables capturing summer droughts, aka a *summer-drought genomic offset*.



> Evaluating genomic offset predictions with height data from common gardens

Height of young trees in common gardens is likely to be impacted by both winter and summer conditions, and both temperature and precipitation conditions. 

Ideally, for this evaluation part, the genomic offset has to be estimated on a set of variables incorporating both summer drought conditions and mean climatic conditions across the whole year (aka a *yearly-climate genomic offset*).

It may still be interesting to compare height in common gardens with the summer-drought genomic offset predictions. If the  summer-drought genomic offset predictions are more associated with height in common gardens than yearly-climate genomic offset predictions, it could mean that height is mostly impacted by summer conditions in the studied common gardens.

> Evaluating genomic offset predictions with mortality data from natural populations

In natural populations, climate change can *directly* impact tree mortality through more and more frequent and intense summer droughts. In contrast, an increase in winter temperatures is highly unlikely to *directly* impact the death of adult trees. However, increased temperatures in winter can benefit to pests and pathogens, which can *indirectly* impact tree death. Note here that in National Forest Inventories, a tree is not counted as dead if its death is attributed to pests. However, mortality is a multifactorial process and it can be very difficult (if not impossible) to determine the relative contributions of climate, pests and other factors to tree death.

Therefore, in this evaluation part, the genomic offset should be estimated with a set of climatic variables including both summer drought conditions and annual climatic conditions.

It may also be interesting to evaluate the association between summer-drought genomic offset predictions and mortality rates in NFI to determine whether current mortality rates in natural populations may be largely attributed to maladaptation to summer drought conditions.


> Evaluating genomic offset predictions with predictions from ecophysiological models

It would be very interesting to compare the genomic offset predictions with predictions of the risk of hydraulic failure from ecophysiological models such as Surreau. In this case, the genomic offset predictions should capture potential maladaptation to summer-drought conditions. However, in the present study, we did not go further on this point.


### Climatic variables relevant for providing GO predictions

We aimed to provide GO predictions capturing both the changes in annual climatic conditions (e.g. mean annual temperature or precipitation) and in seasonal climatic conditions (e.g. summer droughts).

**Winter cold temperatures:**  Previous studies found that maritime pine populations show strong patterns of adaption to temperatures, and especially cold temperatures [@grivet2011molecular and @archambeau2023reduced]. We did not include climatic variables related to winter cold temperatures because, in the context of climate change, the expected increase in winter cold temperatures may benefit maritime pine populations. In such a scenario, populations undergoing strong variations in winter cold conditions will have a high genomic offset, which will not reflect a potential maladaptation but will, on the contrary, inform about a potential increase in their fitness under climate change. Increased winter cold temperatures may also impact the survival of young trees, the reproductive ability of adult trees or the dynamics of pests and pathogens. However, it is not clear how this negative impacts may counterbalance the positive effects of cooler winter, and that is why we did not include climatic variables related to winter cold temperatures in the set of climatic variables used to make genomic offset predictions.



## Criteria 3: exposure to climate change{#ExpCC}

We checked the exposure to climate change in the document `CheckingPastFutureClimatesPopulationLocations.qmd`.

## Selected variables

### One or several set?

At the beginning of the study, we used two sets of climatic variables: one capturing the summer-drought conditions and one the mean annual conditions. The main reasons were:

  - as said in section \@ref(BioRelevance), it may be relevant not to select the same climatic variables for the different study goals and evaluation methods. 
  
  - it was hard to find a set of climatic variables capturing both the summer drought and annual conditions, without included variables that were not too correlated.

However, using different sets of climatic variables adds a supplementary level of complexity to the paper, which is already very dense. At the end, we decided to use only one set of climatic variables capturing both the summer drought conditions and the mean annual conditions. The drawback of this approach is that the variables capturing the summer-drought conditions may not be important to explain the gene-environment relationships, which would result in genomic offset predictions that will not capture population vulnerability to drought conditions, which is problematic in some of the evaluation parts (see \@ref(ClimVarEvalPart))

### Sets of climatic variables

Variance partitioning and candidate SNP identification were performed for three sets of climatic variables. We included in each set climatic variables capturing both summer and annual climatic conditions. For each set, we checked that the VIFs (variance inflation factors) were not too high in the RDA (lower than 10), which indicates that their respective effects can be identified separately in the RDA. We selected the set of climatic variables that best explain the genomic data.


> set 1

```{r VizSet1, fig.width=5,fig.height=5}
set1_var <- list(name="Set 1",
                 code="set1_var",
                 variables=c("bio12","bio1","SP","MWMT","bio15", "bio4", "bio3"))
```

> set 2


```{r VizSet2, fig.width=10,fig.height=10}
set2_var <- list(name="Set 2",
                 code="set2_var",
                 variables=c("bio1","bio12","bio15","bio3","bio4","SHM"))
```


> set 3


```{r VizSet3, fig.width=10,fig.height=10}
set3_var <- list(name="Set 3",
                 code="set3_var",
                 variables=c("AHM", "SHM", "bio15", "bio4", "bio3"))
```

```{r MetaDataSelectedClimaticVariables}
clim_var_selected <- c(set1_var$variables, 
                       set2_var$variables,
                       set3_var$variables) %>% unique()

extract_climatedt_metadata(var_clim = clim_var_selected) %>% 
  dplyr::select(label,description,unit) %>% 
  set_colnames(str_to_title(colnames(.))) %>% 
  kable_mydf(font_size = 12)
```

### Viz correlation

We can look at the correlation among variables and with the PCs scores and geographic variables.

```{r VizCorrSelectedVariables, fig.height=12,fig.width=12, results="hide"}
fig_options <- list(
  path = here("figs/ExploratoryAnalyses/CorrplotSelectedClimVariables.png"),
  width=900,
  height=900,
  res=100)

make_corrplot(df = listdf_pop$df,
              variables = c("longitude","latitude","PC1","PC2","PC3",clim_var_selected),
              fig_options = fig_options)
```

```{r ColorClimVar}
# Define the colors associated with each climatic variable for the following visualizations
color_clim_var <- sample(c('#1f78b4','#a6cee3','#6a3d9a','#e31a1c','#33a02c','#ffff33','#fb9a99',
                    '#FF7FE6', '#FFB675', '#51FF74','#B4FF32'), length(clim_var_selected), replace=F) %>%
  setNames(clim_var_selected) 
```


# Variance partitioning{#VarPart}

We want to disentangle the *relative contribution* of different factors in explaining genetic variation, namely:

  - *climate*, either captured by the *summer-drought* climate variables or the *yearly* climate variables.
  
  - *neutral population structure*, captured by the ancestry coefficients from @jaramillo2015molecular for the individual-based allele counts, or captured by the first `r nb_PCscores` PC scores for the **population-based allele frequencies**. 
  
  - *geography*, accounted for by the population coordinates (longitude and latitude) or by the distance-based Moran's eigenvector maps (dbMEMs) with positive eigenvalues (`r nb_dbMEMs` in our study). 
  
  

We will run:

  - one *full* RDA with all factors (population structure, environment and geographical distance), i.e. no variable conditioning.
  
  - three *partial* RDA in which the factor of interest is conditioned by the other two factors.
  

  
```{r FunctionVarPart}
var_part <- function(df_geno, select_clim_var, df_var, scale_rda, center_rda, geography, nb_dbMEMs){

# The df of the explanatory variables has to include only the variables included in the model
df_var <- df_var %>% 
  dplyr::select(all_of(select_clim_var$variables),
                starts_with("Q"),
                starts_with("PC"),
                ends_with("itude"),
                contains("MEM"))


# Build formulas of the RDA models
# ================================
form_clim_var <- paste(select_clim_var$variables,collapse= " + ") # climatic variables
form_pgs_var <- colnames(df_var) %>% stringr::str_subset("^Q|^PC") %>%  paste(collapse= " + ") # pop structure

if(geography=="coordinates"){
  form_geo_var <- colnames(df_var) %>% stringr::str_subset("itude") %>%  paste(collapse= " + ") # coordinates
} else {
  form_geo_var <- colnames(df_var) %>%  
    stringr::str_subset("MEM") %>%  
   `[`(1:nb_dbMEMs) %>% # keep only the n first MEMs
    paste(collapse= " + ") # coordinates
}

# complete model formulas
form_full_rda <- paste("df_geno ~ ",
                       paste(c(form_clim_var,form_pgs_var,form_geo_var),collapse=" + " )) %>% 
  as.formula()

form_clim_rda <- paste("df_geno ~ ",
                       form_clim_var,"+ Condition(",paste(c(form_pgs_var,form_geo_var),collapse=" + " ), ")") %>% 
  as.formula()

form_pgs_rda <- paste("df_geno ~ ",
                       form_pgs_var,"+ Condition(",paste(c(form_clim_var,form_geo_var),collapse=" + " ), ")") %>% 
  as.formula()

form.geo_rda <- paste("df_geno ~ ",
                       form_geo_var,"+ Condition(",paste(c(form_clim_var,form_pgs_var),collapse=" + " ), ")") %>% 
  as.formula()


# Run the RDA models
# ==================

# Full RDA
full_rda <- rda(form_full_rda, 
                data=df_var, 
                scale=scale_rda,
                center=center_rda) 
anova_full_rda <- anova(full_rda)

# Partial RDA: pure climatic model
clim_rda <- rda(form_clim_rda, 
                data=df_var, 
                scale=scale_rda,
                center=center_rda)
anova_clim_rda <- anova(clim_rda)

# Partial RDA: pure neutral population structure model
pgs_rda <- rda(form_pgs_rda, 
                data=df_var, 
                scale=scale_rda,
                center=center_rda)
anova_pgs_rda <- anova(pgs_rda)

# Partial RDA: pure geography model
geo_rda <- rda(form.geo_rda, 
                data=df_var, 
                scale=scale_rda,
                center=center_rda)
anova_geo_rda <- anova(geo_rda)


# Summary table
# =============

sum_tab_RDA <- tibble("RDA models"=c("Full model: Y ~ clim + geo + pgs.",
                      "Pure climate model: Y ~ clim | (geo + pgs)",
                      "Pure pop. gen. structure model: Y ~ pgs | (geo + clim)",
                      "Pure geography model: Y ~ geo | (pgs + clim)"),
       "Total exp. variance"=c(RsquareAdj(full_rda)[[1]],
              RsquareAdj(clim_rda)[[1]],
              RsquareAdj(pgs_rda)[[1]],
              RsquareAdj(geo_rda)[[1]]),
       "Relative exp. variance"=c(1,
                                  RsquareAdj(clim_rda)[[1]]/RsquareAdj(full_rda)[[1]],
                                  RsquareAdj(pgs_rda)[[1]]/RsquareAdj(full_rda)[[1]],
                                  RsquareAdj(geo_rda)[[1]]/RsquareAdj(full_rda)[[1]]),
       "P-value"=c(anova_full_rda[["Pr(>F)"]][[1]],
                   anova_clim_rda[["Pr(>F)"]][[1]],
                   anova_pgs_rda[["Pr(>F)"]][[1]],
                   anova_geo_rda[["Pr(>F)"]][[1]]))

# Export the table in latex
xtable(sum_tab_RDA, type = "latex",digits=2) %>% 
  print(file = here(paste("tables/VariancePartitioningRDA_",select_clim_var$code,".tex")), include.rownames=FALSE)

return(sum_tab_RDA)
}
```

## Individual-based allele counts{#VarPartInd}

I left this part in the document but I think we should only use the variance partitioning based on population-level allele frequencies. Geography is accounted for with geographical coordinates (longitude and latitude in degrees).

```{r VartPartIndividualLevel, eval=F}
list_sum_var_part <- lapply(list(set1_var, set2_var, set3_var), function(x){

  var_part(df_geno=geno_ind,
          select_clim_var=x,
          df_var=listdf_ind$dfsc %>% as_tibble(), 
          scale_rda=F,center_rda=F,
          geography="coordinates",
          nb_dbMEMs=nb_dbMEMs)
}) %>% setNames(c(set1_var$name,
                  set2_var$name,
                  set3_var$name))

saveRDS(list_sum_var_part, file=here("outputs/RDA/SummaryVartPartIndividualLevel.rds"))
```

```{r ShowSummaryVarPartIndividualLevel, eval=T}
list_sum_var_part <- readRDS(file=here("outputs/RDA/SummaryVartPartIndividualLevel.rds"))

# set 1
kable_mydf(list_sum_var_part[[1]], round_number = 4, boldfirstcolumn = T)

# set 2
kable_mydf(list_sum_var_part[[2]], round_number = 4, boldfirstcolumn = T)

# set 3
kable_mydf(list_sum_var_part[[3]], round_number = 4, boldfirstcolumn = T)
```

## Population-based allele frequencies{#VarPartPop}


### Coordinates as proxies of geography

```{r SetGeographyCoordinates}
geography <- "coordinates"
```


```{r VartPartPopLevelCoordinates, eval=F}
list_sum_var_part <- lapply(list(set1_var,set2_var,set3_var), function(x){
  
  var_part(df_geno=geno_pop,
           select_clim_var=x,
           df_var=listdf_pop$dfsc, 
           scale_rda=F,center_rda=F,
           geography = geography,
           nb_dbMEMs = nb_dbMEMs)
}) %>% setNames(c(set1_var$name,
                  set2_var$name,
                  set3_var$name))

saveRDS(list_sum_var_part, file=here(paste0("outputs/RDA/SummaryVartPartPopLevel_",geography,".rds")))
```

```{r ShowSummaryVarPartPopLevelCoordinates, eval=T}
list_sum_var_part <- readRDS(file=here(paste0("outputs/RDA/SummaryVartPartPopLevel_",geography,".rds")))

# set 1
kable_mydf(list_sum_var_part[[1]], round_number = 4, boldfirstcolumn = T)

# set 2
kable_mydf(list_sum_var_part[[2]], round_number = 4, boldfirstcolumn = T)

# set 3
kable_mydf(list_sum_var_part[[3]], round_number = 4, boldfirstcolumn = T)
```


### dbMEMs as proxies of geography

We keep the first four dbMEMs.

```{r SetGeographyMEMs}
geography <- "dbMEMs"
```

```{r VartPartPopLevelMEMs, eval=F}
list_sum_var_part <- lapply(list(set1_var,set2_var,set3_var), function(x){
  
  var_part(df_geno=geno_pop,
           select_clim_var=x,
           df_var=listdf_pop$dfsc, 
           scale_rda=F,center_rda=F,
           geography = geography,
           nb_dbMEMs = nb_dbMEMs)
}) %>% setNames(c(set1_var$name,
                  set2_var$name,
                  set3_var$name))

saveRDS(list_sum_var_part, file=here(paste0("outputs/RDA/SummaryVartPartPopLevel_",geography,".rds")))
```

```{r ShowSummaryVarPartPopLevelMEMs, eval=T}
list_sum_var_part <- readRDS(file=here(paste0("outputs/RDA/SummaryVartPartPopLevel_",geography,".rds")))

# set 1
kable_mydf(list_sum_var_part[[1]], round_number = 4, boldfirstcolumn = T)

# set 2
kable_mydf(list_sum_var_part[[2]], round_number = 4, boldfirstcolumn = T)

# set 3
kable_mydf(list_sum_var_part[[3]], round_number = 4, boldfirstcolumn = T)
```

### Viz with treemap

We make a treemap to visualize the partitioning of the genomic variation among geography (dbMEMs), climate (set 2) and the neutral genetic structure.

```{r TreemapVarPart, results='hide'}
# we load the outputs of the variance partitioning estimated with dbMEMs and the climatic variables from set 2
tab <- readRDS(file=here("outputs/RDA/SummaryVartPartPopLevel_dbMEMs.rds"))[[2]]

# extract the percentages of variance explained
prop_variance <-tab$`Total exp. variance` * 100

# calculate the percentage of variance explained by the confounded effects of geography, climate and neutral genetic structure:
prop_variance[[1]] <- prop_variance[[1]] - (prop_variance[[2]] + prop_variance[[3]] + prop_variance[[4]]) 

# calculate the percentage of variance that remains unexplained:
prop_variance[[5]] <- 100 - sum(prop_variance)

# Create a vector combining the labels and the values of the treemap
vec <- c("Confounded effects of geography, climate and neutral genetic structure" = prop_variance[[1]],
         "Effects of climate alone" = prop_variance[[2]],
         "Effects of neutral population genetic structure alone" =  prop_variance[[3]],
         "Effects of geography alone" =  prop_variance[[4]],
         "Non-explained" =  prop_variance[[5]])

tab <- tibble(names = paste0(names(vec), " (", round(vec,2), "%)"),
              vals= vec) 

# choose my colors with RColorBrewer
# display.brewer.pal(n = 5, name = "Pastel2") # to see the colors
my_palette <- brewer.pal(n = 5, name = "Pastel2")
my_palette[[5]] <- "#EEEEEE"

# Generate the figure in pdf
pdf(file=here("figs/RDA/treemap_VarPart.pdf"))
treemap(tab,
        index="names",
        vSize="vals",
        title = "",
        palette=my_palette,
        type="index")
dev.off()
```

```{r TreeMapVarPartFiguret, fig.width=7, fig.height=6}
# Show the figure
treemap(tab,
        index="names",
        vSize="vals",
        title = "",
        palette=my_palette,
        type="index")
```

# Identifying loci under selection

  
## Run the RDA{#RunRDAs}

We perform RDA models the six combinations of the three sets of selected climatic variables and accounting or not for the neutral genetic population structure. Here are the models that we run:

  - Allele frequencies ~ set 1 + Condition(PC1 + PC2 + PC3)
  
  - Allele frequencies ~ set 1
  
  - Allele frequencies ~ set 2 + Condition(PC1 + PC2 + PC3)
  
  - Allele frequencies ~ set 2
  
  - Allele frequencies ~ set 3 + Condition(PC1 + PC2 + PC3)
  
  - Allele frequencies ~ set 3 
  
    
RDA summary statistics are summarized in the pdfs `RDAsummary.pdf` and the RDA plots colored by gene pool are shown in the pdfs `RDAplots.pdf`.

The RDA summary plots show that the set with all climatic variables has very high Variance inflated factors, and that's why I decided to use two different sets of variables. 

```{r FunctionToRunRDAmodels}
# =========
# FUNCTIONS
# =========


# Function to create a S3 object with the RDA model and some info
# ===============================================================
new_RDA <- function(form_rda,selected_var,PCs,mod_rda,r2,eigenvalues,model_significance,axis_significance,vif){
  
  structure(
    .Data = list(form_rda=form_rda,
                 selected_var=selected_var,
                 PCs=PCs,
                 mod_rda=mod_rda,
                 r2=r2,
                 eigenvalues=eigenvalues,
                 model_significance=model_significance,
                 axis_significance=axis_significance,
                 vif=vif),
    creation_time = Sys.time(),
    class = "myrda"
  )
  }



# Function to print S3 object of class 'myrda'
# ============================================
print.myrda <- function(x,...){

  print_message <- c(
    paste0("  RDA formula: ", x$form_rda),
    paste0("  Creation time: ", format(attr(x, "creation_time"))),
    paste0(c("  List elements:", names(x)),collapse="   ")
    )

  cat(
    print_message,
    sep = "\n"
  )

}


# Function to run the RDA models and store the info in a S3 object of class 'myrda'
# =================================================================================
runRDA <- function(df,geno_pop,selected_var,pop_structure_correction){


  
  # write RDA formulas
form_clim_var <- paste(selected_var$variables,collapse= " + ")
if(pop_structure_correction==T) {
  PCs <- colnames(df) %>% stringr::str_subset("^PC")
  form_pgs_var <- PCs %>%  paste(collapse= " + ")
  form_rda <- paste("geno_pop ~ ", form_clim_var,"+ Condition(",paste(c(form_pgs_var),collapse=" + " ), ")")
} else {
  PCs = NULL
  form_rda <- paste("geno_pop ~ ", form_clim_var) 
  }
mod_rda <- rda(as.formula(form_rda), df)
r2 <- RsquareAdj(mod_rda)
eigenvalues <- summary(eigenvals(mod_rda, model = "constrained"))
model_significance <- anova.cca(mod_rda, parallel=getOption("mc.cores")) # default is permutation=999
axis_significance <- anova.cca(mod_rda, by="axis", parallel=getOption("mc.cores"))
vif <- vif.cca(mod_rda)

return(new_RDA(form_rda=form_rda,
               selected_var=selected_var,
               PCs=PCs,
               mod_rda=mod_rda,
               r2=r2,
               eigenvalues=eigenvalues,
               model_significance=model_significance,
               axis_significance=axis_significance,
               vif=vif))
  
}



# Function to generate a pdf with the RDA model outputs
# =====================================================
viz_RDAsummary <- function(x){
  
  # check the class of x
  stopifnot("x is not of class myrda" = class(x)=="myrda")
  
  # Generate R2 table
r2_tab <- x$r2 %>% 
  as.data.frame() %>%
  pivot_longer(everything()) %>%  
  column_to_rownames(var ="name") %>% 
  round(2) %>% 
  ggtexttable(rows = row.names(.),cols = NULL, theme = ttheme("blank"))
  
  # Generate table of eigenvalues and proportion of variance explained
eigenvalues_tab <- x$eigenvalues %>% 
  as.data.frame() %>% 
  round(2) %>% 
  ggtexttable(rows = rownames(.), theme = ttheme("blank")) %>% 
  tab_add_hline(at.row = 1:2, row.side = "top", linewidth = 2)

  # Generate table of model and axis significance
signi_tab <- bind_rows(as.data.frame(x$model_significance[-nrow(x$model_significance),]),
          as.data.frame(x$axis_significance[-nrow(x$axis_significance),])) %>% 
  dplyr::mutate(across(!Df, ~ round(.x,3))) %>% 
  ggtexttable(rows = rownames(.), theme = ttheme("blank")) %>% 
  tab_add_hline(at.row = 1:2, row.side = "top", linewidth = 2) %>% 
  tab_add_hline(at.row = 3, row.side = "top", linewidth = 0.01)

  # Generate table for VIF (Variance Inflation Factors)
vif_tab <- x$vif %>% 
  as.data.frame() %>% 
  round(2) %>% 
  rownames_to_column("Variable") %>%
  pivot_wider(values_from=".", names_from = "Variable") %>% 
  ggtexttable(rows = "VIF", theme = ttheme("blank")) %>% 
  tab_add_hline(at.row = 2, row.side = "top", linewidth = 2) 
  
  # Generate the screeplot of the eigenvalues
ggscreeplot <- x$eigenvalues %>% #
  as.data.frame() %>% 
  dplyr::filter(row.names(.) == "Eigenvalue")  %>% 
  pivot_longer(everything(),names_to="PC",values_to="eigenvalues") %>%
  ggplot(aes(x= PC,
             y=eigenvalues,
             group=1)) +
  geom_point(size=4)+
  geom_line() +
  ylab("Eigen values") + xlab("") + 
  labs(title="Scree plot") + 
  theme_bw()


ggarrange(ggarrange(r2_tab,signi_tab,vif_tab,nrow=3),
           ggarrange(eigenvalues_tab,ggscreeplot,nrow=2), 
           nrow = 1, 
           ncol = 2) %>% 
annotate_figure(top = text_grob(x$form_rda, 
                                size = 16, 
                                color = 'black', 
                                face = 'bold'))
  
}


# Function to plot the RDA models
# ==============================
plot_RDA <- function(df,x,GPs){
  
  # check the class of x
  stopifnot("x is not of class myrda" = class(x)=="myrda")
  
  if(x$axis_significance %>% as.data.frame() %>% nrow()-1>2) {
  par(mfrow=c(1,2))
  rdaplots <-  lapply(2:3, function(second_axis){
    plot(x$mod_rda, type="n", scaling=3, choices=c(1,second_axis))
    points(x$mod_rda, display="species", pch=20, cex=0.7, col="gray32", scaling=3, choices=c(1,second_axis))
    points(x$mod_rda, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[GPs], choices=c(1,second_axis))
    text(x$mod_rda, scaling=3, display="bp", col="#0868ac", cex=1, choices=c(1,second_axis))
    if(second_axis==2) legend("topleft", legend=levels(GPs), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)
    recordPlot()
  })} else {
    par(mfrow=c(1,1))
    plot(x$mod_rda, type="n", scaling=3, choices=c(1,2))
    points(x$mod_rda, display="species", pch=20, cex=0.7, col="gray32", scaling=3, choices=c(1,2))
    points(x$mod_rda, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[GPs], choices=c(1,2))
    text(x$mod_rda, scaling=3, display="bp", col="#0868ac", cex=1, choices=c(1,2))
    legend("bottomright", legend=levels(GPs), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)
  }
  
  title(x$form_rda, line=-3,outer = TRUE)
}
```



```{r RunRDAmodels, eval=F, results="hide"}
# We store in a list the four combinations of: 
  # - the two sets of selected climatic variables
  # - correction or not by population structure
rda_combinations <- list(
  list(selected_var = set1_var,
       pop_structure_correction = FALSE),
  list(selected_var = set1_var,
       pop_structure_correction = TRUE),
  list(selected_var = set2_var,
       pop_structure_correction = FALSE),
  list(selected_var = set2_var,
       pop_structure_correction = TRUE),
  list(selected_var = set3_var,
       pop_structure_correction = FALSE),
  list(selected_var = set3_var,
       pop_structure_correction = TRUE))


# Run the RDA models and store their information
rda_models <- lapply(rda_combinations, function(x){
  runRDA(df = listdf_pop$dfsc,
         geno_pop = geno_pop,
         selected_var = x$selected_var,
         pop_structure_correction = x$pop_structure_correction)})

# save the RDA models and their information
saveRDS(rda_models, here("outputs/RDA/RDAmodels.rds"))

# viz RDA models and their summary information
pdf(width = 13, height = 6, here("figs/RDA/RDAsummary.pdf"))
lapply(rda_models, viz_RDAsummary)
dev.off()

# plot RDA models
pdf(width = 12, height = 8, here("figs/RDA/RDAplots.pdf"))
lapply(rda_models, function(x) plot_RDA(df=listdf_pop$dfsc,x=x,GPs=GPs))
dev.off()
```



## Identify outliers

Two methods can be used to identify the outliers with the RDA.

Outliers can be identified based on their *extremeness* along a *distribution of Mahalanobis distances* estimated between each locus and the center of the RDA space using K number of axes [@capblancqEvaluationRedundancyAnalysis2018]. The number of axes used (K) is determined by looking at the amount of information retained on the different axes of the RDA [@capblancqEvaluationRedundancyAnalysis2018]. In our study, we used K=2. The Mahalanobis distances are calculated with the `rdadapt` function from @capblancq2021redundancy, which returns $p$-values and $q$-values for each SNP. Different thresholds can then be used to identify the outliers:

  -  @capblancq2020climate uses a $p$-value threshold with a Bonferroni correction to account for multiple testing: $p$-value < 0.01 / number of SNPs (see [code](https://github.com/Capblancq/Local-Adaptation-Fagus-sylvatica)). In our study, this threshold results in selecting 16 SNPs with the RDA model, and 5 with the pRDA model (and 1 in common between the two methods). 

  - @capblancq2021redundancy ([code](https://github.com/Capblancq/RDA-landscape-genomics)) rank-ordered the SNPs based on their $p$-values (the $p$-value of a given SNP captures how far its Mahalanobis distance is from the distribution of Mahalanobis distances of all SNPs) and identified the 0.2% or 0.5% of the SNPs with the lowest $p$-values. In our study, this threshold results in selecting 19 SNPs (0.002 * `r dim(geno_pop)[[2]]`=`r 0.002*dim(geno_pop)[[2]]`) or 48 SNPs (0.005 * `r dim(geno_pop)[[2]]`=`r 0.005*dim(geno_pop)[[2]]`). We will use this threshold in the following analyses.
  
  - we can also use a FDR (False Discovery Rate) threshold of 5% or 10% to identify outliers as the `rdadapt` function returns both $p$-values and $q$-values [see @franccois2016controlling].

Outliers can also been identified based on the *extreme loadings on each retained axis*. Method used in @forester2018comparing (see [code](https://popgen.nescent.org/2018-03-27_RDA_GEA.html), in which a 3 standard deviation cutoff is used (two-tailed $p$-value = 0.0027). We also use a 3 standard deviation cutoff in the following analyses. 
  

```{r echo=F}
rda_models <- readRDS(here("outputs/RDA/RDAmodels.rds"))
listdf_pop <- readRDS(here("outputs/RDA/RDA_explanatorydataframes_PopLevel.rds"))
```

  
```{r FunctionToIdentifyOutliers, fig.width=19, fig.height=8}
# ====================================
# Function to identify the outlier SNPs
# =====================================

identify_outliers <- function(rda_model, explanatory_data, geno_data){

# outlier detection based on  extreme Mahalanobis distances from the RDA center
# =============================================================================

# Genome scan with K = 2 (degrees of freedom of the X2 distribution)
  # rdadapt is a function to conduct a RDA based genome scan (from Capblancq & Forester 2021)
GSout <- rdadapt(rda_model$mod_rda, 2) %>%  
  as_tibble() %>% 
  mutate(snp=colnames(geno_data)) 

GSout$qvalues %>% hist(col = "orange", 
     main=rda_model$form_rda,
     xlab="Non-calibrated p-values")

# P-values threshold after Bonferroni correction
# outliers_maha <- GSout %>% 
#   filter(pvalues <  0.01/nrow(.)) %>% 
#   mutate(maha_meth = TRUE) %>% 
#   dplyr::select(snp,maha_meth) # we do not keep the p.values and q.values in the outlier table

# FDR threshold of 5%
outliers_maha <- GSout %>%
  filter(qvalues <  0.05) %>%
  mutate(maha_meth = TRUE) %>%
  dplyr::select(snp,maha_meth) # we do not keep the p.values and q.values in the outlier table

# P-values are rank-ordered and we select the 0.5% with the lowest p-values
# outliers_maha <- GSout %>% 
#   arrange(pvalues) %>% 
#   slice(1:(0.005*nrow(.))) %>% 
#   mutate(maha_meth = TRUE) %>% 
#   dplyr::select(snp,maha_meth) # we do not keep the p.values and q.values in the outlier table


# outlier detection based on  extreme axis loadings
# =================================================

# As we identify the SNPs that has loadings along the significant axes,
# we first extract the number of significant axes 
nb_signi_axis <- rda_model$axis_significance %>% 
  as.data.frame() %>% 
  dplyr::rename(pvalue="Pr(>F)") %>% 
  dplyr::filter(pvalue<0.05) %>% 
  nrow()
  
loads <- scores(rda_model$mod_rda, choices=c(1:(nrow(as.data.frame(rda_model$axis_significance))-1)), display="species")
  

outliers_loads <- lapply(1:nb_signi_axis, function(id.axis){
  out <- detectoutliers(loads[,id.axis],3) # function to identify outliers based on their RDA loadings (from  Forester et al. 2018)
  tibble(
    #axis=rep(id.axis,times=length(out)), # we do not keep the information about the axis
    snp = names(out),
    load_meth = TRUE,
    # loading = out # we do not keep the loadings
  )
}) %>% 
  list_rbind() %>% 
  distinct()



# Merge outliers identified by the two methods
# ============================================

all_outliers <- full_join(outliers_maha,outliers_loads, by="snp") %>% 
  mutate(across(c(maha_meth,load_meth), ~replace_na(.,FALSE)))

all_outliers <- map(all_outliers$snp, function(snp){
 cordf <-  cor(explanatory_data[,names(rda_model$vif)],geno_data[,snp]) %>% 
    as.data.frame() %>% 
    rownames_to_column() %>% 
    pivot_wider(names_from="rowname", values_from = "V1") %>% 
     mutate(max_var = names(which.max(abs(.)))) %>% 
     mutate(max_var_clim = names(which.max(abs(.[,rda_model$selected_var$variables]))))
}) %>%
  setNames(all_outliers$snp) %>% 
  list_rbind(names_to = "snp") %>% 
  inner_join(all_outliers,by="snp")


list(rda_model = rda_model,
     GSout = GSout, # keep the p.values for the Manhattan plot
     outliers = all_outliers)

}
```

```{r IdentifyOutliers}
# we identify the outlier SNPs for the four RDA models
rda_outliers <- rda_models %>% 
  lapply(function(x) {
    identify_outliers(rda_model = x, explanatory_data = listdf_pop$dfsc, geno_data = geno_pop)
  })

saveRDS(rda_outliers, here("outputs/RDA/RDA_outliers.rds"))
```

## Outlier visualization


### RDA plots based on Forester et al. (2018)

We visualize the outliers with RDA plots following @forester2018comparing (see [code](https://popgen.nescent.org/2018-03-27_RDA_GEA.html)). Figures are stored in `RDAplots_outliers_1.pdf`.

```{r FunctionToPlotRDAoutliers}
# Function to make one RDA plot with different colors for outlier SNPs
make_one_outlier_rda_plot <- function(mod_rda, data_plots, xlim, ylim, second_axis,arrow_length,outline_col){
  
plot(mod_rda, type="n", scaling=3, xlim=xlim, ylim=ylim, choices=c(1,second_axis))
points(mod_rda, display="species", pch=21, cex=1, col=data_plots$allsnps$nooutlier_color, bg=data_plots$allsnps$nooutlier_bg , scaling=3, choices=c(1,second_axis))
points(mod_rda, display="species", pch=21, cex=1, col=data_plots$allsnps$outlier_color, bg=data_plots$allsnps$outlier_bg, scaling=3, choices=c(1,second_axis))
text(mod_rda, scaling=3, display="bp", col="#0868ac", cex=1, arrow.mul=arrow_length, choices=c(1,second_axis))
legend("topleft", legend=data_plots$legend_names, bty="n", col=outline_col, pch=21, cex=1, pt.bg=data_plots$legend_colors,ncol=1,title=data_plots$legend_title) 
recordPlot()

}




# Function that combines two types of plot:
  # plots in which outliers are colored according to their most associated climatic variable
  # plots in which outliers are colored according to the detection method used to identify them:
      # a method based on the Mahalanobis distances from the center of the RDA space
      # a method based on the extreme SNP loadings on each significant axis
combine_rda_outlier_plots <- function(rda_out,color_clim_var){

# Storing data and options to generate the plots in a list
list_data_plots <- list(clim=list(), # options/data specific to plots with colors based on the climatic variables
                        meth=list()) # options/data specific to plots with colors based on the detection methods


# Figure options shared between the two types of plot
# ===================================================

nooutliers_bg <- '#f1eef6'
outline_col <- 'gray32'
transparent_col <- rgb(0,1,0, alpha=0)


  
# Fig options/data specific to plots based on the climatic variables
# ==================================================================

# Attribute one color to each climatic variable 
selected_var_colors <- tibble(max_var_clim = names(color_clim_var),
                              outlier_bg = color_clim_var) %>% 
  dplyr::filter(max_var_clim %in% rda_out$rda_model$selected_var$variables)

# Generate a dataframe with color information for outliers
outlier_colors <-  rda_out$outliers %>% 
  dplyr::select(snp, max_var_clim) %>% 
  left_join(selected_var_colors, by="max_var_clim")
 
# Generate a dataframe with color information for all SNPs
list_data_plots$clim$allsnps <- tibble(snp=rownames(rda_out$rda_model$mod_rda$CCA$v)) %>% 
  left_join(outlier_colors, by="snp") %>% 
  mutate(outlier_bg = replace_na(outlier_bg,transparent_col),
         outlier_color = ifelse(outlier_bg == transparent_col, transparent_col, outline_col),
         nooutlier_bg = ifelse(outlier_bg == transparent_col, nooutliers_bg, transparent_col),
         nooutlier_color = ifelse(outlier_bg == transparent_col, outline_col, transparent_col))

# Legend options
list_data_plots$clim$legend_title <- 'Climatic variable'
list_data_plots$clim$legend_names <- selected_var_colors$max_var_clim
list_data_plots$clim$legend_colors <- selected_var_colors$outlier_bg

  
# Fig options/data specific to plots based on the detection methods
# =================================================================

# Attribute one color to each method
method_colors <- c('#FCF926','#3BCD24','#CD24B2') %>% setNames(c("Mahalanobis distance","Axis loadings", "Both"))

# Legend options
list_data_plots$meth$legend_colors <- method_colors
list_data_plots$meth$legend_names <- names(method_colors)
list_data_plots$meth$legend_title <- 'Outlier detection method'


# attribute colors to all SNPs
list_data_plots$meth$allsnps <-  tibble(snp=rownames(rda_out$rda_model$mod_rda$CCA$v)) %>% 
  left_join(rda_out$outliers[,c("snp", "load_meth", "maha_meth")],by="snp") %>%  
  mutate(outlier_bg = case_when(load_meth == TRUE & maha_meth == TRUE ~ method_colors["Both"],
                                load_meth == TRUE & maha_meth == FALSE ~ method_colors["Axis loadings"],
                                load_meth == FALSE & maha_meth == TRUE ~ method_colors["Mahalanobis distance"],
                                is.na(load_meth) & is.na(maha_meth) ~ transparent_col),
         outlier_color = ifelse(outlier_bg == transparent_col, transparent_col, outline_col),
         nooutlier_bg = ifelse(outlier_bg == transparent_col, nooutliers_bg, transparent_col),
         nooutlier_color = ifelse(outlier_bg == transparent_col, outline_col, transparent_col))


# Generate the RDA plots
# =====================

# For RDA models with 2 explanatory variables, we can only plot RDA1 vs RDA2

if(rda_out$rda_model$axis_significance %>% as.data.frame() %>% nrow()-1>2) { # rda models with more than 2 climatic variables
    
par(mfrow=c(2,2))
lapply(2:3, function(second_axis){ # generate two plots: RDA1 vs RDA2 and RDA1 vs RDA3
    lapply(list_data_plots, function(x) make_one_outlier_rda_plot(mod_rda = rda_out$rda_model$mod_rda,
                                                                  data_plots = x,
                                                                  xlim=c(-1,1), 
                                                                  ylim=c(-0.5,0.5),
                                                                  arrow_length=1.25,
                                                                  outline_col=outline_col,
                                                                  second_axis=second_axis))

  })} else {  # rda models with 2 climatic variables

par(mfrow=c(1,2))
    lapply(list_data_plots, function(x) make_one_outlier_rda_plot(mod_rda = rda_out$rda_model$mod_rda,
                                                                  data_plots = x,
                                                                  xlim=c(-0.3,0.3), 
                                                                  ylim=c(-0.5,0.5),
                                                                  outline_col=outline_col,
                                                                  arrow_length=0.6,
                                                                  second_axis=2))
    
  }

  title(rda_out$rda_model$form_rda, line=-3,outer = TRUE) # rda model formula as title
   
}
```



```{r PlotRDAoutliers, results='hide'}
# Plot RDA outliers with different colors based either on the detection method or the most associated climatic variable
pdf(width = 12, height = 8, here("figs/RDA/RDAplots_outliers_1.pdf"))
lapply(rda_outliers, function(x) combine_rda_outlier_plots(rda_out = x,color_clim_var = color_clim_var))
dev.off()
```


### RDA plots based on Capblancq and Forester (2021)


We visualize the outliers with RDA and Manhattan plots following @capblancq2021redundancy ([code](https://github.com/Capblancq/RDA-landscape-genomics)). Figures are stored in `RDAplots_outliers_2.pdf`.

```{r FunctionToGGPlotRDAoutliers}
make_rda_ggplot <- function(data_plots,TAB_var){ 

  data_plots$tab[order(data_plots$tab$snp_type),] %>% 
  ggplot() +
  geom_hline(yintercept=0, linetype="dashed", color = gray(.80), linewidth=0.6) +
  geom_vline(xintercept=0, linetype="dashed", color = gray(.80), linewidth=0.6) +
  geom_point(aes(x=RDA1*20, y=RDA2*20, colour = snp_type), size = 1.4) +
  scale_color_manual(values = data_plots$legend_colors) +
  geom_segment(data = TAB_var, aes(xend=RDA1, yend=RDA2, x=0, y=0), 
               colour="black", linewidth=0.15, linetype=1, arrow=arrow(length = unit(0.02, "npc"))) +
  geom_text(data = TAB_var, aes(x=1.1*RDA1, y=1.1*RDA2, label = row.names(TAB_var)), size = 2.5) +
  xlab("RDA 1") + ylab("RDA 2") +
  facet_wrap(~"RDA space") +
  guides(color=guide_legend(title=data_plots$legend_title)) +
  theme_bw(base_size = 11) +
  theme(panel.background = element_blank(), 
        legend.background = element_blank(), 
        panel.grid = element_blank(), 
        plot.background = element_blank(), 
        legend.text=element_text(size=rel(.8)), 
        strip.text = element_text(size=11))
  
  
  
}

make_manhattan_plot <- function(data_plots){ 

data_plots$tab[order(data_plots$tab$snp_type),] %>% 
ggplot() +
  geom_hline(yintercept=-log10(0.01/length(data_plots$tab$pvalues)), linetype="dashed", color = gray(.80), linewidth=0.6) +
  geom_point(aes(x=pos, y=-log10(pvalues), col = snp_type), size=1.4) +
  scale_color_manual(values = data_plots$legend_colors) +
  xlab("Loci") + ylab("-log10(p-values)") +
  facet_wrap(~"Manhattan plot", nrow = 3) +
  guides(color=guide_legend(title=data_plots$legend_title)) +
  theme_bw(base_size = 11) +
  theme(legend.position="right", legend.background = element_blank(), panel.grid = element_blank(), legend.box.background = element_blank(), plot.background = element_blank(), panel.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))
  }


# Function that combines two types of plot:
  # plots in which outliers are colored according to their most associated climatic variable
  # plots in which outliers are colored according to the detection method used to identify them:
      # a method based on the Mahalanobis distances from the center of the RDA space
      # a method based on the extreme SNP loadings on each significant axis
combine_rda_outlier_ggplots <- function(rda_out,color_clim_var){

# Storing data and options to generate the plots in a list
list_data_plots <- list(clim=list(), # options/data specific to plots with colors based on the climatic variables
                        meth=list()) # options/data specific to plots with colors based on the detection methods


# Figure options shared between the two types of plot
# ===================================================

nooutliers_bg <- "gray90"
nooutliers_legend <- "No detection"

locus_scores <- scores(rda_out$rda_model$mod_rda, 
                       choices=c(1:2), # we use K=2 number of axes
                       display="species", # 'species' in the vegan package correspond to the loci
                       scaling="none") %>% 
  as.data.frame() %>% 
  rownames_to_column("snp") %>% 
  as_tibble() %>% 
  inner_join(rda_out$GSout, by="snp") %>% 
  mutate(pos=seq(1:nrow(.)))

TAB_var <- as.data.frame(scores(rda_out$rda_model$mod_rda, choices=c(1,2), display="bp"))
  
# Fig options/data specific to plots based on the climatic variables
# ==================================================================

# Legend options
vec_color_clim_var <- color_clim_var[names(color_clim_var) %in% unique(rda_out$outliers$max_var_clim)]
list_data_plots$clim$legend_title <- 'Climatic variable'
list_data_plots$clim$legend_names <- c(nooutliers_legend,names(vec_color_clim_var))
list_data_plots$clim$legend_colors <- c(nooutliers_bg,vec_color_clim_var) %>% unname()


list_data_plots$clim$tab <-  locus_scores %>% 
  left_join(rda_out$outliers[,c("snp", "max_var_clim")],by="snp") %>%  
  mutate(max_var_clim = replace_na(max_var_clim,nooutliers_legend)) %>% 
  mutate(max_var_clim =factor(max_var_clim,levels=list_data_plots$clim$legend_names)) %>% 
  dplyr::rename(snp_type = max_var_clim)


# Fig options/data specific to plots based on the detection methods
# =================================================================


# Legend options
list_data_plots$meth$legend_colors <- c(nooutliers_bg,'#FCF926','#3BCD24','#CD24B2')
list_data_plots$meth$legend_names <- c(nooutliers_legend,"Mahalanobis distance","Axis loadings", "Both")
list_data_plots$meth$legend_title <- 'Outlier detection'


list_data_plots$meth$tab <-   locus_scores %>% 
  left_join(rda_out$outliers[,c("snp", "load_meth", "maha_meth")],by="snp") %>%  
  mutate(snp_type = case_when(load_meth == TRUE & maha_meth == TRUE ~  list_data_plots$meth$legend_names[[4]],
                              load_meth == TRUE & maha_meth == FALSE ~ list_data_plots$meth$legend_names[[3]],
                              load_meth == FALSE & maha_meth == TRUE ~ list_data_plots$meth$legend_names[[2]],
                              is.na(load_meth) & is.na(maha_meth) ~ list_data_plots$meth$legend_names[[1]])) %>% 
  mutate(snp_type=factor(snp_type,levels=list_data_plots$meth$legend_names)) 



# Generate the RDA plots
# =====================


p1 <- lapply(list_data_plots, function(x) make_rda_ggplot(data_plots = x,
                                                         TAB_var=TAB_var))

p2 <- lapply(list_data_plots, function(x) make_manhattan_plot(data_plots = x))

plot_row <- plot_grid(p1$clim, p1$meth,p2$clim,p2$meth, ncol=2)

# Title options
title <- ggdraw() + 
  draw_label(
    rda_out$rda_model$form_rda,
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )

# merge title and plots
plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
)

   
}
```

```{r GGPlotRDAoutliers, results='hide'}
# Plot RDA outliers with different colors based either on the detection method or the most associated climatic variable
pdf(width = 12, height = 8, here("figs/RDA/RDAplots_outliers_2.pdf"))
lapply(rda_outliers, function(x) combine_rda_outlier_ggplots(rda_out = x, color_clim_var=color_clim_var))
dev.off()
```


We also generate some figures for the Supplementary Information. These figures are only generated for the RDA models that are further used to identify the candidate SNPs, i.e. the RDA models fitted on the set 2 of climatic variables. We call *RDA* the model fitted on the set 2 without correcting for population structure and *pRDA* the model fitted on the set 2 with correcting for population structure

```{r GenerateSIoutlierplots, results="hide"}
# =========================================
# Function to generate the SI outlier plots
# =========================================
generate_SI_outlier_plots <- function(rda_out){
  
  
locus_scores <- scores(rda_out$rda_model$mod_rda, 
                       choices=c(1:2), # we use K=2 number of axes
                       display="species", # 'species' in the vegan package correspond to the loci
                       scaling="none") %>% 
  as.data.frame() %>% 
  rownames_to_column("snp") %>% 
  as_tibble() %>% 
  inner_join(rda_out$GSout, by="snp") %>% 
  mutate(pos=seq(1:nrow(.)))

TAB_var <- as.data.frame(scores(rda_out$rda_model$mod_rda, choices=c(1,2), display="bp"))

# Legend options
legend_colors <- c("gray90",'#CD24B2')
legend_names <- c("Non-outliers","Outliers")
legend_title <- 'Outlier detection'


tab <-   locus_scores %>% 
  left_join(rda_out$outliers[,c("snp", "maha_meth")],by="snp") %>%  
  mutate(snp_type = case_when(maha_meth == TRUE ~  legend_names[[2]],
                              is.na(maha_meth) | maha_meth==FALSE ~ legend_names[[1]])) %>% 
  mutate(snp_type=factor(snp_type,levels=legend_names)) 


# Plot with RDA space
# ===================
p1 <- tab[order(tab$snp_type),] %>% 
  ggplot() +
  geom_hline(yintercept=0, linetype="dashed", color = gray(.80), linewidth=0.6) +
  geom_vline(xintercept=0, linetype="dashed", color = gray(.80), linewidth=0.6) +
  geom_point(aes(x=RDA1*20, y=RDA2*20, colour = snp_type), size = 1.4) +
  scale_color_manual(values = legend_colors) +
  geom_segment(data = TAB_var, aes(xend=RDA1, yend=RDA2, x=0, y=0), 
               colour="black", linewidth=0.15, linetype=1, arrow=arrow(length = unit(0.02, "npc"))) +
  geom_text(data = TAB_var, aes(x=1.1*RDA1, y=1.1*RDA2, label = row.names(TAB_var)), size = 2.5) +
  xlab("RDA 1") + ylab("RDA 2") +
  facet_wrap(~"RDA space") +
  theme_bw(base_size = 11) +
  theme(panel.background = element_blank(), 
        legend.position = "none",
        legend.background = element_blank(), 
        panel.grid = element_blank(), 
        plot.background = element_blank(), 
        legend.text=element_text(size=rel(.8)), 
        strip.text = element_text(size=11))


# Manhattan plot
# ==============
p2 <- tab[order(tab$snp_type),] %>% 
ggplot() +
  geom_hline(yintercept=-log10(0.01/length(tab$pvalues)), linetype="dashed", color = gray(.80), linewidth=0.6) +
  geom_point(aes(x=pos, y=-log10(pvalues), col = snp_type), size=1.4) +
  scale_color_manual(values = legend_colors) +
  xlab("Loci") + ylab("-log10(p-values)") +
  facet_wrap(~"Manhattan plot", nrow = 3) +
  theme_bw(base_size = 11)  +
  theme(legend.position="right",  
        panel.grid = element_blank(), 
        legend.title=element_blank(),
        legend.box.background = element_blank(), plot.background = element_blank(), panel.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))


# Merge the two plots
# ===================
p2_legend <- get_legend(p2)
p2 <- p2 + theme(legend.position = "none")
plot_row <- plot_grid(p1,p2, ncol=2)
plot_row <- plot_grid(plot_row, p2_legend, ncol=2,rel_widths = c(1, 0.1))


# Save the plots as pdf
# =====================
if(grepl("Condition",rda_out$rda_model$form_rda)==TRUE){rda_name <- "pRDA"} else { rda_name <- "RDA"}
ggsave(plot_row, device = "pdf", filename = here(paste0("figs/RDA/SI_outlier_plots_",rda_name,".pdf")), width=12, height=5)
}


# Run the function for the RDA models fitted on the set 2 of climatic variables
lapply(rda_outliers[3:4], function(x) generate_SI_outlier_plots(rda_out = x))
```



## Common outliers

We identify the common outliers among the four RDA models with Venn diagrams. 

```{r VennDiagramOutliers, fig.height=9, fig.width=9, message=F}
venn_diagrams <- lapply(list(1:2,2:3,4:5), function(x) 
  list("RDA" = rda_outliers[[x[1]]]$outliers$snp,
       "pRDA" = rda_outliers[[x[2]]]$outliers$snp) %>% 
  ggVennDiagram(lty="solid", size=0.2, label = "count", label_alpha=0) + 
  scale_fill_gradient2(low = "white", high = 'darkgoldenrod3') + 
  scale_color_manual(values = rep("darkgoldenrod1",6)) + 
  guides(fill = "none") + 
  theme(text = element_text(size=16)) + 
  scale_x_continuous(expand = expansion(mult = .2))) %>% 
  setNames(c(set1_var$name,
           set2_var$name,
           set3_var$name))

venn_diagrams <- ggarrange(venn_diagrams[[1]],
                           venn_diagrams[[2]],
                           venn_diagrams[[3]],
                           labels=names(venn_diagrams))

ggsave(here("figs/RDA/VennDiagramOutliers.pdf"),venn_diagrams, width = 9, height=7)

venn_diagrams
```

# Export climatic variable names

We export the names of the selected climatic variables for the other GEA analyses.

We will use the set 2 of climatic variables in the following analyses because its VIFs are not too high (see `RDAsummary.pdf`) and it explains almost as well as the set 1 the genomic data (see variance explained for the `pure climate model` in section \@ref(VarPart) and the variance explained by the RDA models in section \@ref(RunRDAs)), which is the set that best explains the genomic data but with very high VIFs. 

```{r ExportClimNames}
set2_var$variables %>% saveRDS(here("data/ClimaticData/NamesSelectedVariables.rds"))
```


We export a figure for the Supplementary Information of the distribution of the selected climatic variables:


```{r PlotDistributionSelectedClimaticVariables, fig.height=8, fig.width=10}
p <- clim %>% 
  dplyr::select(any_of(set2_var$variables)) %>% 
  pivot_longer(everything(),names_to="variable") %>% 
  ggplot(aes(x=value)) +  
  geom_histogram(aes(y=after_stat(density)), colour="blue",fill="white",bins = 34) +
  geom_density(alpha=.2,fill="pink") +
  facet_wrap(~variable,scales="free") +
  xlab("Climatic variable") +
  ylab("Density") +
  theme_bw() 

p %>% ggsave(device="pdf",
             file=here("figs/ExploratoryAnalyses/DistributionSelectedClimaticVariables.pdf"),
             width=10,height=8)

p
```

# References

# Session information

```{r SessionInfo}
devtools::session_info()
```
