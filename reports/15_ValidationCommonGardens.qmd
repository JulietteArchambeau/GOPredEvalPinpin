---
title: "Validating genomic offset predictions with mortality and height data from common gardens"
date: last-modified
number-sections: true
format: 
  html:
    toc: true
    toc-depth: 4
    code-fold: true
    page-layout: full
embed-resources: true
bibliography: references.bib
editor_options: 
  chunk_output_type: console
---

<style type="text/css">
body {
   font-size: 15px;
}
code.r{
  font-size: 11px;
}
pre {
  font-size: 11px
}

table {
  font-size: 10px
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev.args = list(png = list(type = "cairo")))
knitr::opts_chunk$set(fig.width = 7,fig.height = 5,cache=F)
options(width = 300)
library(knitr)
library(tidyverse)
library(readxl)
library(xtable)
library(reshape2)
library(kableExtra)
library(magrittr)
library(cowplot)
library(rnaturalearth)
library(raster)
library(RColorBrewer)
library(here)
library(rstan)
library(tidybayes)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(bayesplot)
color_scheme_set("green")
library(paletteer)
library(latex2exp)
library(RCurl)
library(ggpubr)
library(png)
library(RCurl)
library(grid)

# my own function for building tables in reports
source(here("scripts/functions/kable_mydf.R"))

# Scaling the climatic datasets with mean and variance from the population climatic distributions
source(here("scripts/functions/generate_scaled_clim_datasets.R"))

# Colors for the coefficients
colors_coeff <- c("#004586FF","#FF7F0FFF","#FFD320FF","#579D1CFF","#7E0021FF","#83CAFFFF","aquamarine3","#FEB5A2FF","#F02720FF","darkviolet","deeppink","cyan2","chocolate4")


#################################################
# Full method and site names to use in the plots
#################################################

cg_names <- list(caceres = "Cáceres",
                 asturias = "Asturias",
                 madrid = "Madrid",
                 portugal = "Fundão",
                 bordeaux = "Bordeaux")


###################
# Correlation plots
###################

source(here("scripts/functions/corpmat.R")) # to compute the matrix of p-value

# Function to generate a corrplot in pdf
make_corrplot_pdf <- function(df,variables,fig_options,text_size,number_size){
  
  # correlation matrix
  cor <- cor(df[,variables]) 
  
  # matrix of the p-value of the correlation
  pmat <- corpmat(cor)

  # Generate a correlation plot
  pdf(file=fig_options$path,
      width=fig_options$width,
      height=fig_options$height)
  corrplot::corrplot(cor, 
                     method="color", 
                     col=colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))(200),
                     type="upper", 
                     order="hclust",
                     addCoef.col = "black", # Add coefficient of correlation
                     tl.col="black", 
                     tl.srt=45, #Text label color and rotation
                   
                     # Combine with significance
                     p.mat = pmat, 
                     sig.level = 0.01, 
                     mar=c(0,0,0,0),
                     insig = "blank",
                     
                     # hide correlation coefficient on the principal diagonal
                     diag=FALSE,
                     tl.cex = text_size,
                     number.cex=number_size)
  dev.off()
  
}
```



# Introduction

In this report, we evaluate whether genomic offset (GO) predictions from the different GEA methods (LFMM, GF, GDM and RDA) and SNP sets (control, candidate and all SNPs for LFMM) are good predictors of fitness proxies (height and mortality data) from five clonal common gardens located in Spain (Asturias, Madrid, Cáceres), Portugal (Fundão) and France (Pierroton). For that, we predicted the genomic offset of each population when transplanted in the environment of the common garden (so instead of predicting the genomic offset into future climates, we predict it in the new environment of the common garden, i.e. space-for-time approach). The rational is that populations with higher genomic offset in a given common garden are expected to have lower relative fitness in the common garden.

We also calculate the climatic transfer distances (CTD) between the climate-of-origin of the populations and the climate of the common garden (i.e. the absolute value of the difference between the climate of origin of the populations and the climate in the common garden between the tree planting date and the measurement date). We then estimate the association between tree height and mortality and the climatic transfer distances. The climatic transfer distances are calculated for the same set of climatic variables as the one used to calculate the genomic offset (one CTD per climatic variable).


# Data

## Genomic offset predictions

We load the genomic offset predictions estimated from the different GEAs.

```{r LoadGOpredictions}
# Codes of the SNP sets
snp_sets <- readRDS(here("outputs/list_snp_sets.rds"))

# Which RDA method?
RDA_method <- "predict"

# List of methods
meth_names <- c("GDM", "GF", "LFMM", "pRDA", "RDA")

df <- lapply(snp_sets, function(x){

list_snps <- list()

list_snps$GDM <- readRDS(file=here("outputs/GDM/go_predictions.rds"))[[x$set_code]][["go_cg"]]
list_snps$GF <- readRDS(file=here("outputs/GF/go_predictions.rds"))[[x$set_code]][["go_cg"]]
list_snps$LFMM <- readRDS(file=here("outputs/LFMM/go_predictions.rds"))[[x$set_code]][["go_cg"]]
list_snps$pRDA <- readRDS(file=here(paste0("outputs/RDA/go_predictions_",RDA_method,".rds")))[[x$set_code]][["go_cg_corrected"]]
list_snps$RDA <- readRDS(file=here(paste0("outputs/RDA/go_predictions_",RDA_method,".rds")))[[x$set_code]][["go_cg_uncorrected"]]


list_snps %>% 
  bind_rows(.id="method") %>% 
  mutate(input_code = x$set_code,
         input_name = x$set_name,
         method_input_code = paste0(method, "_", input_code),
         method_input_name = paste0(method, " - ", input_name))

}) %>% 
  bind_rows() %>% 
  pivot_longer(cols=names(cg_names),names_to="cg",values_to="varX") 

#####


# df <- lapply(c("control","cand"), function(x){
# 
# list_snps <- list()
# 
# list_snps[[x]]$GDM <- readRDS(file=here("outputs/GDM/go_predictions.rds"))[[x]][["go_cg"]]
# list_snps[[x]]$GF <- readRDS(file=here("outputs/GF/go_predictions.rds"))[[x]][["go_cg"]]
# list_snps[[x]]$RDA <- readRDS(file=here("outputs/RDA/go_predictions.rds"))[[x]][["go_cg"]]
# list_snps[[x]]$LFMM <- readRDS(file=here("outputs/LFMM/go_predictions_snpsets.rds"))[[x]][["go_cg"]]
# 
# 
# list_snps <- list_snps[[x]] %>% 
#   bind_rows(.id="method_type") %>% 
#   mutate(method_input = x)
# 
# return(list_snps)
# }) %>% bind_rows()
# 
# 
# df <- readRDS(file=here("outputs/LFMM/go_predictions_allsnps.rds"))[["go_cg"]] %>% 
#    mutate(method_type = "LFMM",
#           method_input = "all") %>% 
#   bind_rows(df) %>% 
#   pivot_longer(cols=c(readRDS(here("data/ClimaticData/CommonGardens/ClimateCG.rds"))[["cg"]]),names_to="cg",values_to="varX") %>% 
#   mutate(method = paste0(method_type, "_",method_input))
```

## Climatic transfer distances

We calculate the climatic transfer distances.

```{r CalculateCTD}
# selected climatic variables
clim_var <- readRDS(here("data/ClimaticData/NamesSelectedVariables.rds"))

# climatic data in the common gardens (btw planting and measurement dates)
cg_clim <-readRDS(here("data/ClimaticData/CommonGardens/ClimateCG.rds")) %>% 
  dplyr::select(cg,any_of(clim_var)) 

# Loading point estimate climatic data at the location of the populations (reference climatic period)
adj <- "noADJ"  # not adjusted for elevation
ref_period <- "ref_1901_1950" # reference period 1901-1950
clim_past <- readRDS(here(paste0("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationPointEstimates_ReferencePeriods_",adj,".rds")))[[ref_period]]$ref_means %>%
  dplyr::select(pop,any_of(clim_var))

# Preparing the dataset for 
clim_dist <- clim_past

df <- lapply(cg_clim[["cg"]], function(x){
  
# Calculating the CTD for each climatic variable
for(var in clim_var){clim_dist[[var]] <- ( clim_past[[var]] - cg_clim %>% filter(cg == x) %>%  pull(var) ) %>% abs()} 
#names(clim_dist) <- c("pop", str_c(names(clim_past[,-1]),"_CTD"))

# Calculating the Euclidean distances for all climatic variables
list_scaled_clim_df <- generate_scaled_clim_datasets(clim_var, clim_pred = cg_clim)
cg_clim_i <- list_scaled_clim_df$clim_pred %>% filter(cg == x) %>% dplyr::select(-cg)

clim_dist$EucliDist <- map_dbl(1:nrow(list_scaled_clim_df$clim_ref[,-1]),
                               ~ sqrt(sum((list_scaled_clim_df$clim_ref[.x,-1] - cg_clim_i)^2)))
   
return(clim_dist)
}) %>%  
  setNames(cg_clim[["cg"]]) %>% 
  bind_rows(.id="cg") %>% 
  pivot_longer(cols=c(any_of(clim_var),"EucliDist"),names_to="input_code",values_to="varX") %>% 
  mutate(method = "CTD",
         method_input_code = paste0("CTD_",input_code),
         input_name = case_when(input_code == "bio1" ~ "Mean annual temperature (bio1, °C)",
                                input_code == "bio12" ~ "Annual precipitation (bio12, mm)",
                                input_code == "bio15" ~ "Precipitation seasonality (bio15, index)",
                                input_code == "bio3" ~ "Isothermality (bio3, index)",
                                input_code == "bio4" ~ "Temperature seasonality (bio4, °C)",
                                input_code == "SHM" ~ "Summer heat moisture index (SHM, °C/mm)",
                                input_code == "EucliDist" ~ "All climatic variables (Euclidean distance)"),
         method_input_code = paste0("CTD_", input_code),
         method_input_name = paste0("CTD - ", input_name)) %>% 
  bind_rows(df)
```


## Correlation CTDs vs GO predictions

We calculate the correlations among GO predictions and climatic transfer distances in the common gardens.

```{r CorrGOPredsCTDs, results='hide'}
lapply(unique(df$cg), function(site_i){
  
df_corr <- df %>% 
  dplyr::filter(cg==site_i) %>% 
  dplyr::select(method_input_code, varX,pop) %>% 
  pivot_wider(values_from = varX, names_from = method_input_code)

# Corrplot with ggplot
# ====================

correlations <- df_corr %>%  dplyr::select(-pop) %>% cor

# Order variables alphabetically
correlations <- correlations[order(rownames(correlations)), order(colnames(correlations))]
    
# Melt the correlation matrix into a long format
cor_data <- reshape2::melt(correlations)
  
# Filter to only show the lower triangle
cor_data <- cor_data %>% filter(as.numeric(Var1) > as.numeric(Var2))
  
# Plot
ggplot(cor_data, 
       aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "#BB4444", mid = "#FFFFFF", high = "#4477AA", midpoint = 0, limits = c(-1, 1), name="Correlation") +
  geom_text(aes(label = round(value, 2)), color = "black", size = 3) +
  theme_minimal() +
  theme(axis.text.x = element_text(size=11,
                                   angle = 45, 
                                   hjust = 1),
        axis.text.y = element_text(size=11)) +
  labs(x = NULL, y = NULL)
  
# Corrplot with make_corrplot_pdf
# ===============================
fig_options <- list(
  path = here(paste0("figs/ValidationCommonGarden/Corrplot_GOpreds_CTDs_",site_i,".pdf")),
  width=10,
  height=8)

make_corrplot_pdf(df = df_corr,
                  variables = colnames(df_corr)[-c(1:2)],
                  text_size = 0.5,
                  number_size = 0.4,
                  fig_options = fig_options)
  
})
```


## Phenotypic data

We load the survival and mortality data from the five common gardens.

```{r HeightMeasurements}
pheno_data <- readRDS(file=here("data/CommonGardenData/PhenoDataNovember2019_AnnualTraits_UpdatedSept2021_AllSites.rds")) %>% dplyr::rename(pop=prov)

no_nas <- sapply(pheno_data, function(x) length(x)-sum(is.na(x)))

list_pheno <- list()

list_pheno$`Asturias, Spain (37 months)` <- table(pheno_data$site,pheno_data$AST_survmar14)["asturias",]
list_pheno$`Bordeaux, France (85 months)` <- table(pheno_data$site,pheno_data$BDX_surv18)["bordeaux",]
list_pheno$`Cáceres, Spain (8 months)` <- table(pheno_data$site,pheno_data$CAC_survdec11)["caceres",]
list_pheno$`Madrid, Spain (13 months)` <- table(pheno_data$site,pheno_data$MAD_survdec11)["madrid",]
list_pheno$`Fundão, Portugal (27 months)` <- table(pheno_data$site,pheno_data$POR_survmay13)["portugal",]

df_exp_design <- list_pheno %>% 
  bind_rows(.id="cg") %>% 
  setNames(c("Common garden (tree age)",
             "Number of dead trees",
             "Number of trees alive")) %>% 
  mutate("Number of height measurements"=c(no_nas[["AST_htmar14"]],
                                           no_nas[["BDX_htnov18"]],
                                           no_nas[["CAC_htdec11"]],
                                           no_nas[["MAD_htdec11"]],
                                           no_nas[["POR_htmay13"]]))

saveRDS(df_exp_design, file = here("tables/ExpDesign_CG.rds"))

df_exp_design  %>% kable_mydf
```

Height and survival measurements in each common garden:

  - **Asturias** (Spain) in **March 2014** when the trees were 37 month-old (trees were planted in **February 2011**).
  
  - **Bordeaux** (France) in **November 2018** when the trees were 85 month-old (trees were planted in **October 2011**).
  
  - **Cáceres** (Spain) in **December 2011** when the trees were 8 month-old (trees were planted in **April 2011**). Note that for this common garden, we calculate the bioclimatic variables for the entire year 2011 (instead of calculating the variables only for months between April and December). Indeed, the calculation of the annual bioclimatic variables will be wrong if we do not account for some months, e.g. the mean annual temperature will be higher than expected because we do not account for some winter months.  
  
  - **Madrid** (Spain) in **December 2011** when the trees were 13 month-old (trees were planted in **November 2010**).
  
  - **Fundão** (Portugal) in **May 2013** when the trees were 27 month-old (trees were planted in **February 2011**)




# Mortality models

In this section, we want to determine whether **genomic offset (GO)** or **climate transfer distances (CTD)** are associated with the **proportion of dead trees in the populations**, independently in the five common gardens. We build a model that assumes that **the initial sapling height acts as a confounder**. Indeed, trees that were higher at the time of planting have a higher probability of survival. This is particularly true in Madrid and Cáceres (Spain) where the seedlings experienced an extreme drought event the same year they were planted, resulting in very high mortality rates.
Here is the model:
  
\begin{align*} 
a_{p} &\sim \text{Binomial} (N_{p},p_{p}) \\
\text{logit}(p_{p}) &= \beta_{0} +  \beta_{H}H_{p} + \beta_{X}X_{p}\\
\end{align*}


with $a_{p}$ the count of individuals that died in the population $p$, $N_{p}$ the total number of individuals in the population $p$ (=number of individuals that were initially planted in the common garden), $p_p$ is the estimated probability of mortality in the population $p$, $X_{p}$ is the genomic offset or climatic transfer distance for the population $p$ and $H_{p}$ is the BLUPs for height of the population $p$ [population varying intercepts calculated across all common gardens in the model 1 of @archambeau2022combining]. $H_{p}$ is used as a proxy of the initial tree height.

We used the following weakly informative priors:

  
\begin{align*} 
\begin{bmatrix}  \beta_{0,c} \\ \beta_{H} \\ \beta_{X} \end{bmatrix} &\sim \mathcal{N}(0,5)
\end{align*}



## The variables

### Initial tree height (confounder)

We load the population-specific intercepts from the model 1 of @archambeau2022combining.

```{r ExtractHeightInterceptsModel1Archambeauetal2022,message=F,warning=F}
mod_arch2022 <- readRDS(file=here("data/Archambeauetal2022_MOD1.rds"))
pop_heights <- mod_arch2022$fit %>% 
  broom.mixed::tidyMCMC(estimate.method = "mean",conf.int = T) %>% # we take the mean of the prov random intercepts
  filter(str_detect(term, "^(r_prov\\[)")) %>% 
  dplyr::rename(height=estimate,pop=term) %>% 
  mutate(pop=str_sub(pop,8,-12))

pop_heights[1:5,] %>% kable_mydf
```

<span style="color: orange;">**DRYAD REPOSITORY:** We export the height intercepts from @archambeau2022combining to the DRYAD repository: `HeightIntercepts_Archambeauetal2022.csv`.</span>


```{r HeightInterceptsInDryadRepo}
pop_heights %>% write_csv(here("data/DryadRepo/HeightIntercepts_Archambeauetal2022.csv"))
```

### Survival data 

The response variable is counts of dead trees. To calculate these counts, we load the survival data in the common gardens, in which `0` corresponds to dead trees and `1` to survivors.

```{r LoadSurvData}
surv_measurements <- c("AST_survmar14","BDX_surv18","CAC_survdec11","MAD_survdec11","POR_survmay13")
survival_data <- pheno_data %>% 
  dplyr::select(site,block,pop,clon,tree,any_of(surv_measurements)) %>% 
  pivot_longer(cols=any_of(surv_measurements), names_to = NULL, values_to = "survival") %>% 
  drop_na(survival) 

survival_data[1:5,] %>% kable_mydf
```

## Run the models

Stan code of the mortality model:

```{r CompileMortalityModel, message=F,warning=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_BinomialMortalityModel.stan"))
print(stancode)
```

We run the models for each common garden and each genomic offset predictions/climatic transfer distances, so a total of 5 * 15 = 75 models runs.

```{r RunMortalityModels, eval=F}
coefftab <- lapply(unique(survival_data$site),function(site_i){
  
lapply(unique(df$method_input_code), function(method_input_code_i){

# Subset the data for the site i and method i
sub_data <- survival_data %>% 
  filter(site == site_i) %>% 
  group_by(pop) %>% 
  dplyr::summarise(nb_dead=n()-sum(survival),nb_tot=n()) # transform survival data into mortality data
    
sub_data <- df %>% 
  filter(method_input_code == method_input_code_i & cg == site_i) %>% 
  inner_join(sub_data, by="pop") %>% 
  inner_join(pop_heights %>% dplyr::select(any_of(c("height", "pop"))), by="pop") %>% 
  arrange(pop)
      
# Data in a list for Stan 
stanlist <- list(N = nrow(sub_data),
                 nb_dead = sub_data$nb_dead,
                 nb_tot = sub_data$nb_tot,
                 H = (sub_data$height-mean(sub_data$height)) / sd(sub_data$height),
                 X = (sub_data$varX -mean(sub_data$varX)) / sd(sub_data$varX))
    
# Running the model
mod <- sampling(stancode, data = stanlist, iter = 2000, chains = 4, cores = 4, save_warmup = FALSE) 
    
# Save the model and the stanlist
list(mod = mod, 
     stanlist = stanlist) %>% 
  saveRDS(file=here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",
                                                           site_i,"_",method_input_code_i,".rds")))
    
  })
  
})

```

```{r CoefftabMortalityModels, eval=T}
coefftab <- lapply(unique(survival_data$site),function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
    
    # Subset the data - keeping only one set of method / SNP set
    sub_data <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
  
    mod <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",
                                    site_i,"_",method_input_code_i,".rds")))[["mod"]]
                     
    # Save coefficients
    broom.mixed::tidyMCMC(mod,
                          droppars = NULL, 
                          robust = FALSE, # give mean and standard deviation
                          ess = F, 
                          rhat = F, 
                          conf.int = T,
                          conf.level = 0.95) %>% 
      filter(str_detect(term, c('beta'))) %>% 
      dplyr::rename(mean=estimate,
                    std_deviation=std.error,
                    conf_low=conf.low,
                    conf_high=conf.high) %>% 
      mutate(cg = site_i,
             method_input_code = method_input_code_i,
             method_input_name = unique(sub_data$method_input_name),
             method = unique(sub_data$method),
             input_name = unique(sub_data$input_name),
             input_code = unique(sub_data$input_code),
             .before=1)     

}) %>% bind_rows()
 
}) %>% bind_rows()
  
coefftab %>% saveRDS(file=here("outputs/ValidationCommonGarden/MortalityModels/coefftab.rds"))
```


## Model coefficients

We load the model coefficients: 

```{r LookTablePosteriorsMortalityModels, eval=T}
coefftab <- readRDS(file=here("outputs/ValidationCommonGarden/MortalityModels/coefftab.rds"))
coefftab[1:5,] %>% kable_mydf()
```

Below, we plot the mean and 95% credible intervals of:

  - the **$\beta_X$ coefficients**, which stand for the association between the counts of dead trees and the genomic offset predictions (i.e. capturing the potential maladaptation of the populations when transplanted in the new environment of the common gardens) or the climatic transfer distances.
  
  - the $\beta_H$ coefficients, which stand for the association between the counts of dead trees and the BLUPs for height in the five common gardens, used as a proxy of the initial seedling height (a confounder in the model).
  
Graph titles include the time in months corresponding to the age at which height and survival were recorded. Coefficients in the green area have the expected sign, reflecting higher mortality rates in populations with higher GO predictions.

```{r CoeffPlotsMortalityModels, fig.height=9, fig.width=12, eval=T}
coeff_match <- list(beta_H = "Regression coefficients $\\beta_H$ in mortality models",
                    beta_X = "Regression coefficients $\\beta_X$ in mortality models")

p <- lapply(c("beta_X","beta_H"), function(coeff){
  
p <- coefftab %>% 
  filter(term == coeff) %>% 
  mutate(cg_name = case_when(cg == "asturias" ~ "Asturias, Spain (37 months)",
                             cg == "bordeaux" ~ "Bordeaux, France (85 months)",
                             cg == "caceres" ~ "Cáceres, Spain (8 months)",
                             cg == "madrid" ~ "Madrid, Spain (13 months)",
                             cg == "portugal" ~ "Fundão, Portugal (27 months)")) %>% 
  mutate(input_name = factor(input_name, levels = c(unique(coefftab$input_name)[[13]],
                                                    unique(coefftab$input_name)[[11]],
                                                    unique(coefftab$input_name)[[12]],
                                                    unique(coefftab$input_name)[[10]],
                                                    unique(coefftab$input_name)[[8]],
                                                    unique(coefftab$input_name)[[9]],
                                                    unique(coefftab$input_name)[[1]],
                                                    unique(coefftab$input_name)[[2]],
                                                    unique(coefftab$input_name)[[3]],
                                                    unique(coefftab$input_name)[[4]],
                                                    unique(coefftab$input_name)[[5]],
                                                    unique(coefftab$input_name)[[6]],
                                                    unique(coefftab$input_name)[[7]])),
         method = factor(method, levels = c(unique(coefftab$method)[[2]],
                                            unique(coefftab$method)[[3]],
                                            unique(coefftab$method)[[4]],
                                            unique(coefftab$method)[[5]],
                                            unique(coefftab$method)[[6]],
                                            unique(coefftab$method)[[1]])),
         cg_name = factor(cg_name, levels = c("Madrid, Spain (13 months)",
                                              "Cáceres, Spain (8 months)",
                                              "Asturias, Spain (37 months)",
                                              "Bordeaux, France (85 months)",
                                              "Fundão, Portugal (27 months)")))


# Plots with CTD and SNP sets
# ===========================
p_allvar <- p %>% ggplot(aes(x = method,
                             y = mean,
                             ymin = conf_low, 
                             ymax = conf_high,
                             color = input_name,
                             shape = input_name)) +
  {if(coeff=="beta_X")  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=0, ymax=Inf), color="transparent", fill="green", alpha=0.005)} + 
  geom_hline(yintercept = 0,color="gray") +
  geom_pointinterval(position = position_dodge(width = 0.6),
                     point_size=3, size=2) +
  facet_wrap(~cg_name, ncol=2) + 
  ylab(TeX(coeff_match[[coeff]])) +
  xlab("") +
  scale_color_manual(values=colors_coeff)+
  scale_shape_manual(values = c(rep(17,6),rep(16,7))) +
  theme_bw() +
  labs(color="",shape="") +
  theme(axis.text.x =  element_text(size=13),
        axis.text.y = element_text(size=13),
        axis.title.y = element_text(size=16),
        legend.title = element_text(size=13), 
        strip.text.x = element_text(size = 16),
        strip.background = element_blank(),
        legend.position = c(0.77,0.15),
        legend.text=element_text(size=12),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  guides(color = guide_legend(ncol=1),
         shape = guide_legend(override.aes = list(size =2 )))

# save in pdf and png
ggsave(p_allvar,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsandCTD.pdf")),
       device="pdf",
       height=11,
       width=13)

ggsave(p_allvar,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsandCTD.png")),
       height=11,
       width=13)


# Plots with SNPs only
# ====================
p_SNPs <- p %>% 
  filter(!method == "CTD") %>% 
  ggplot(aes(x = method,
             y = mean,
             ymin = conf_low, 
             ymax = conf_high,
             color = input_name,
             shape = input_name)) +
  {if(coeff=="beta_X")  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=0, ymax=Inf), color="transparent", fill="green", alpha=0.007)} + 
  geom_hline(yintercept = 0,color="gray") +
  geom_pointinterval(position = position_dodge(width = 0.45),
                     point_size=3, size=2) + # 
  facet_wrap(~cg_name, ncol=2) +
  ylab(TeX(coeff_match[[coeff]])) +
  xlab("") +
  scale_color_manual(values=colors_coeff) +
  scale_shape_manual(values = c(rep(17,6),rep(16,6))) +
  theme_bw() +
  labs(color="",shape="") +
  theme(axis.text.x =  element_text(size=13),
        axis.text.y = element_text(size=13),
        axis.title.y = element_text(size=16),
        axis.title.x = element_text(size=1),
        legend.title=element_text(size=13), 
        strip.text.x = element_text(size = 16),
        strip.background = element_blank(),
        legend.position = c(0.77,0.15),
        legend.text=element_text(size=14),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  guides(color=guide_legend(ncol=1),
         shape = guide_legend(override.aes = list(size =2 )))

# save in pdf and png
ggsave(p_SNPs,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsets.pdf")),
       device="pdf",
       height=11,
       width=13)

ggsave(p_SNPs,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsets.png")),
       height=11,
       width=13)

# Figure in the main manuscript
###############################

# We want to add some images to represent the climatic differences among common gardens

if(coeff=="beta_X"){
  
annotation_custom2 <- function (grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, data){ layer(data = data, stat = StatIdentity, position = PositionIdentity, 
        geom = ggplot2:::GeomCustomAnn,
        inherit.aes = TRUE, params = list(grob = grob, 
                                          xmin = xmin, xmax = xmax, 
                                          ymin = ymin, ymax = ymax))}

df_png <- p %>% 
  dplyr::select(cg_name) %>%
  distinct %>% 
  dplyr::mutate(image = case_when(cg_name == "Asturias, Spain (37 months)" ~ "reports/cloud.png",
                                  cg_name == "Bordeaux, France (85 months)" ~ "reports/cloud.png",
                                  cg_name == "Cáceres, Spain (8 months)" ~ "reports/sun.png",
                                  cg_name == "Madrid, Spain (13 months)" ~ "reports/sun.png",
                                  cg_name == "Fundão, Portugal (27 months)" ~ 'reports/cloud_and_sun.png'))

list_pngs <- lapply(unique(p$cg_name), function(cg_name_i){
  
sub <-  p %>% 
  filter(cg_name==cg_name_i) %>%
  slice(1)

png_cg = annotation_custom2(rasterGrob(readPNG(here(df_png[df_png$cg_name==cg_name_i,"image"])),interpolate=TRUE), 
                            ymin = -0.54,
                            ymax= -0.24,
                            xmin = 0.42,
                            xmax = 1, 
                            data=sub)
})

p_allvar_images <- p_allvar + list_pngs[[1]]+ list_pngs[[2]]+ list_pngs[[3]]+ list_pngs[[4]]+ list_pngs[[5]]

# save in pdf and png
ggsave(p_allvar_images,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsets_WithCloudAndSunImages.pdf")),
       device="pdf",
       height=11,
       width=13)

}

return(p_allvar)

})

p
```

<span style="color: orange;">Interpretation</span>

As expected, the association between mortality rates and the initial tree height was particularly strong in Madrid and Cáceres (Spain) where the seedlings experienced an extreme drought event the same year they were planted, resulting in very high mortality rates. More surprisingly, this association was also osberved in Fundão, Portugal. However, the initial tree height was not associated with mortality rates in Bordeaux (France) and Asturias (Spain), which benefit from the favorable climates of the Atlantic region and in which the mortality rates were very low.

In Fundão, Cáceres and Madrid, for most genomic offset predictions, populations experiencing higher mortality rates also showed higher genomic offset. The most consistent associations across the three common gardens were obtained with:

  - <span style="color: orange;">**Gradient Forest (GF)** with both candidate and control SNPs.</span>
  
  - <span style="color: orange;">**Redundancy analysis (RDA)** with both candidate and control SNPs.</span>
  
  - <span style="color: orange;">**Latent factor mixed model (LFMM)** with all SNPs or control SNPs.</span>


Interestingly, climatic transfer distances generally explain mortality probability less well than genomic offset predictions, and none of them show a consistent association with the number of dead trees across the three common gardens. Note that it is almost the case for the climatic transfer distance calculated based on the temperature seasonality, which shows a positive association with the counts of dead trees in Madrid and Fundão, and almost in Cáceres.

In Asturias, no association was detected between genomic offset predictions and mortality rates, which may be due to the favorable climatic conditions of this common garden and the associated low mortality rates (only 206 dead trees). Therefore, in this common garden, mortality events are likely to be mostly random events due to other factors than climate. However, we can note that an association was detected between mortality rates and isothermality: populations from areas with high isothermality tend to die more in the common garden of Asturias, Spain.

In Bordeaux, there were even less dead trees than in Asturias (119 dead trees). However, the two nonparametric approach used to predict the genomic offset (GDM and GF) detected a positive association between mortality rates and the genomic offset predictions obtained with both the candidate and the control SNPs. A positive association was also detected with the genomic offset predictions obtained with candidate SNPs with the LFMM approach. On the other hand, none of the genomic offset predictions from the RDA approach were associated with the mortality rates. Interestingly, the only association with a climatic transfer distance was with the temperature seasonality (`bio4`), which was the most important variable to explain the turnover in allele frequency in the GF and GDM approaches.


## Predictions of tree mortality probability

### Plots

Let's visualize the uncertainty around the estimation of the probability of tree mortality $p$.

```{r MortalityPredictions, message=F,warning=F, fig.height=6, fig.width=6, eval=T}
####################################################################################################
# Visualizing the relationships between GO predictions or CTDs and mortality probability predictions
####################################################################################################

coefftab <- readRDS(file = here("outputs/ValidationCommonGarden/MortalityModels/coefftab.rds")) %>%
  mutate(cg_name = case_when(cg == "asturias" ~ "Asturias, Spain (37 months)",
                             cg == "bordeaux" ~ "Bordeaux, France (85 months)",
                             cg == "caceres" ~ "Cáceres, Spain (8 months)",
                             cg == "madrid" ~ "Madrid, Spain (13 months)",
                             cg == "portugal" ~ "Fundão, Portugal (27 months)"))

lapply(unique(coefftab$cg), function(site_i){
  
  lapply(unique(coefftab$method_input_code), function(method_input_code_i){
    
    sub_coefftab <- coefftab %>% 
      filter(method_input_code == method_input_code_i & cg == site_i)
    
    # We load the stanlist
    stanlist <- readRDS(file = here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",
                                       site_i,"_",method_input_code_i,".rds")))$stanlist

    # We load the model
    mod <- readRDS(file = here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",
                                      site_i,"_",method_input_code_i,".rds")))$mod

    # We extract the posterior distributions of all parameters
    post <- as.data.frame(mod)

    # Vector of predictor values (based on the min and max of the GO predictions)
    x_vec <- seq(min(stanlist$X),max(stanlist$X),0.05)

    # Function to predict the mortality probability p with the initial tree height fixed to the mean
    f_p <- function(x) 1 / (exp(-(post$`beta_0` + post$`beta_H` * mean(stanlist$H) + post$`beta_X` * x)) + 1)

    p_pred <- 
      sapply(x_vec, f_p) %>% 
      tibble::as_tibble() %>%
      rename_all(function(x) x_vec) %>%
      mutate(Iter = row_number()) %>%
      gather(x, p, -Iter) %>%
      group_by(x) %>%
      mutate(hpdi_l = HDInterval::hdi(p, credMass = 0.90)[1],
             hpdi_h = HDInterval::hdi(p, credMass = 0.90)[2],
             p_mean = mean(p)) %>%
      ungroup() %>%
      mutate(x = as.numeric(x))
             
    # Keep mean and 90% HDPI of p (one value for each iteration)
    p_mean_df <- p_pred %>%
      dplyr::select(x,hpdi_l,hpdi_h,p_mean) %>% 
      dplyr::distinct()


    # Plots
    #=======

    # Plot options 
    y_limits <- c(0,1)
    if(unique(sub_coefftab$method) == "CTD"){x_axis <- "Mean-centered CTD"} else {x_axis <- "Mean-centered GO predictions"}
    y_axis <- "Probability of tree mortality"
    
    p <- ggplot() +
      ylim(y_limits) +
      labs(y=y_axis, x=x_axis) +
      theme_bw()

    # First 100 posterior draws of the mortality probability p
    p1 <- p +
      geom_point(data = p_pred %>% filter(Iter < 101),
                 aes(x, p), alpha = .2, color = 'dodgerblue')
  
   # Mean (line) and 90% HPDI (shaded region) of the mortality probability p
    p2 <- p +
      geom_ribbon(data = p_mean_df,
                  aes(x = x, ymin = hpdi_l, ymax = hpdi_h),
                  alpha = .2,
                  fill='dodgerblue') +
      geom_line(data = p_mean_df,
                aes(x=x, y=p_mean), col="dodgerblue4")

  p1_p2 <- ggarrange(p1, p2 + labs(y=""), nrow = 1)

  # Title
  title <- ggdraw() + 
    draw_label(paste0(unique(sub_coefftab$cg_name)," - ",unique(sub_coefftab$method_input_name)),
               fontface = 'bold',
               x = 0, 
               hjust = 0) +   
    theme(plot.margin = margin(0, 0, 0, 7))

  # merge title and plots 
  p1_p2 <- plot_grid(title, p1_p2, ncol = 1, rel_heights = c(0.1, 1))

ggsave(p1_p2,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/MortalityProbabilityPredictions_UncertaintyIntervals/",
                        method_input_code_i,"_",site_i,".pdf")),
       device="pdf",
       height=6,
       width=11)

})
})
```

### Table

In the table below:

  - mean and 90% credible intervals (highest posterior density intervals) of $p$ for $x=\{-1, 0, 1\}$.
  
  - percent change in $p$ associated with a one-unit increase in $x$ (which corresponds to a one-standard deviation increase).

```{r MortalityPredictionsTable, message=F,warning=F, fig.height=6, fig.width=6, eval=T}
p_pred <- lapply(names(cg_names), function(site_i){
  
lapply(unique(df$method_input_code), function(method_input_code_i){   
#lapply(names(methods), function(method_i){

# We load the stanlist
stanlist <- readRDS(file = here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",
                                       site_i,"_",method_input_code_i,".rds")))$stanlist

# We load the model
mod <- readRDS(file = here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",
                                  site_i,"_",method_input_code_i,".rds")))$mod

# We extract the posterior distributions of all parameters
post <- as.data.frame(mod)

# Vector of predictor values (based on the min and max of the GO predictions)
x_vec <- c(-1,0,1)

# Function to predict the mortality probability p with the initial tree height fixed to the mean
f_p <- function(x) 1 / (exp(-(post$`beta_0` + post$`beta_H` * mean(stanlist$H) + post$`beta_X` * x)) + 1)

p_pred <- 
  sapply(x_vec, f_p) %>% 
  tibble::as_tibble() %>%
  rename_all(function(x) x_vec) %>%
  mutate(Iter = row_number()) %>%
  gather(x, p, -Iter) %>%
  group_by(x) %>%
  mutate(hpdi_l = HDInterval::hdi(p, credMass = 0.90)[1], # Highest posterior density intervals
         hpdi_h = HDInterval::hdi(p, credMass = 0.90)[2]
         # pi_l = rethinking::PI(p, prob = 0.90)[1], # Highest posterior percentile intervals
         # pi_h = rethinking::PI(p, prob = 0.90)[2]
         ) %>%
  mutate(p_mean = mean(p)) %>%
  ungroup() %>%
  mutate(x = as.numeric(x)) %>% 
  dplyr::select(x,p_mean,hpdi_l,hpdi_h) %>% 
  distinct() %>% 
  round(3)

delta_p_pos <- (p_pred$p_mean[p_pred$x==1] * 100 / p_pred$p_mean[p_pred$x==0])-100
delta_p_neg <- (p_pred$p_mean[p_pred$x==-1] * 100 / p_pred$p_mean[p_pred$x==0])-100

tibble(Site = cg_names[[site_i]],
       "Method" = df %>% filter(method_input_code == method_input_code_i) %>% pull(method_input_name) %>% unique(),
       "p(x=-1)"=paste0(p_pred$p_mean[p_pred$x==-1], " [",
                       p_pred$hpdi_l[p_pred$x==-1],";",
                       p_pred$hpdi_h[p_pred$x==-1],"]"),
       "p(x=0)"=paste0(p_pred$p_mean[p_pred$x==0], " [",
                       p_pred$hpdi_l[p_pred$x==0],";",
                       p_pred$hpdi_h[p_pred$x==0],"]"),
       "p(x=1)"=paste0(p_pred$p_mean[p_pred$x==1], " [",
                       p_pred$hpdi_l[p_pred$x==1],";",
                       p_pred$hpdi_h[p_pred$x==1],"]"),
       "+Δp"=paste0(round(delta_p_pos,3),"%"),
       "-Δp"=paste0(round(delta_p_neg,3),"%"))

}) %>% bind_rows()

}) %>% bind_rows()


p_pred %>% saveRDS(file = here("tables/MortalityPredCGs.rds"))
```

```{r ShowMortalityPredictionsTable}
readRDS(file = here("tables/MortalityPredCGs.rds"))  %>% kable_mydf()
```


## Experimental design

We export in a table with the number and proportion of dead trees for each population in each common garden.

```{r ExpDesignMortalityModels, eval=F}
ExpDesignTab <- lapply(unique(survival_data$site),function(site_i){
  
survival_data %>% 
    filter(site==site_i) %>% 
    dplyr::select(pop,survival) %>% 
    drop_na() %>% 
    group_by(pop) %>% 
    dplyr::summarise(nb_dead=n()-sum(survival),nb_tot=n()) %>% 
    mutate(prop_dead=nb_dead*100/nb_tot)
  
}) %>% 
  setNames(unique(survival_data$site)) %>% 
  bind_rows(.id="cg") %>% 
  pivot_wider(names_from=cg,values_from = c(nb_dead, nb_tot,prop_dead),names_sep="_") %>% 
  dplyr::select(pop,contains("asturias"),contains("bordeaux"),contains("caceres"),contains("madrid"),contains("portugal"))

# To generate a latex table
# =========================
# print(xtable(ExpDesignTab, type = "latex",digits=2), 
#       file = paste0(here("tables/ExpDesignMortalityModelsPerPopCG.tex")), 
#       include.rownames=FALSE)

# Export the table for the Supplementary Information
# =================================================
ExpDesignTab %>% 
  dplyr::select(-contains("prop_dead")) %>% 
  saveRDS(here("tables/ExpDesignMortalityModelsPerPopCG.rds"))


# Show table
# ==========
ExpDesignTab %>% kable_mydf()

# Information used in the manuscript
ExpDesignTab[,-1] %>% 
  dplyr::summarise_all(mean) %>% 
  kable_mydf
```


## Correlation coefficients

Stan code of the mortality model without the genomic offset predictions or the CTD (i.e. only with height as predictor).

```{r CompileMortalityModelWithoutGO, message=F,warning=F, eval=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_BinomialMortalityModel_WithoutGO.stan"))
print(stancode)
```

```{r RunMortalityModelWithoutGO, message=F,warning=F, eval=F}
lapply(unique(survival_data$site),function(site_i){
  
# Subset the data for the site i and add the initial heights
sub_data <- survival_data %>% 
  filter(site == site_i) %>% 
  group_by(pop) %>% 
  dplyr::summarise(nb_dead=n()-sum(survival),nb_tot=n()) %>% # transform survival data into mortality data
  inner_join(pop_heights %>% dplyr::select(any_of(c("height", "pop"))), by="pop") %>% 
  arrange(pop)
      
# Data in a list for Stan 
stanlist <- list(N = nrow(sub_data),
                 nb_dead = sub_data$nb_dead,
                 nb_tot = sub_data$nb_tot,
                 H = (sub_data$height-mean(sub_data$height)) / sd(sub_data$height))
    
# Running the model
mod <- sampling(stancode, data = stanlist, iter = 2000, chains = 4, cores = 4, save_warmup = FALSE) 

# Save the model and the stanlist
list(mod = mod, 
     stanlist = stanlist) %>% 
  saveRDS(file=here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",
                                                           site_i,"_ModelWithoutGO.rds")))
    
})
```

```{r extractMortalityProbabilityModelWithoutGO, eval=T}
corrtab <- lapply(unique(survival_data$site),function(site_i){
  
  list_mod <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/MortalityModels/stan_models/",site_i,"_ModelWithoutGO.rds")))

  # Extract posterior samples
  posterior_samples <- rstan::extract(list_mod[[1]])

  # Extract parameters (posterior samples for beta_0 and beta_H)
  beta_0_samples <- posterior_samples$beta_0
  beta_H_samples <- posterior_samples$beta_H

  # Mean tree height for each population (H)
  H <- list_mod[[2]]$H

  # Generate posterior predictions for each population
  N <- list_mod[[2]]$N # number of populations
  num_samples <- length(beta_0_samples)  # Number of posterior samples

  # Initialize matrix to store predicted probabilities
  mortality_prob <- matrix(NA, nrow=num_samples, ncol=N)

  # Compute mortality probability for each population for each posterior sample
  for (i in 1:num_samples) {
    for (j in 1:N) {
      # Logistic transformation to get probability of mortality
      mortality_prob[i, j] <- 1 / (1 + exp(-(beta_0_samples[i] + beta_H_samples[i] * H[j])))
    }
  }

  # Summary of posterior predictive mortality probabilities for each population
  mortality_prob_summary <- apply(mortality_prob, 2, function(x) c(mean=mean(x), sd=sd(x), quantile(x, probs=c(0.025, 0.975))))

  # Convert to a readable data frame (optional)
  mortality_prob_df <- tibble(
    pop = unique(df$pop),
    mean_prob = mortality_prob_summary["mean", ],
    sd_prob = mortality_prob_summary["sd", ],
    lower_95 = mortality_prob_summary["2.5%", ],
    upper_95 = mortality_prob_summary["97.5%", ],
    prob_obs = list_mod[[2]]$nb_dead / list_mod[[2]]$nb_tot, # Observed proportion of dead trees
    diff_p = prob_obs - mean_prob, # diff bwt obs prob. and estimated prob.
    cg = site_i
  ) #%>% 
    #arrange(diff_p) %>% 
    #mutate(diff_p_rank = 1:nrow(.))
  
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
  
  sub_data <- df %>% 
    filter(method_input_code == method_input_code_i & cg == site_i) %>% 
    #arrange(varX) %>% 
    #mutate(varX_rank = 1:nrow(.)) %>% 
    inner_join(mortality_prob_df, by=c("pop","cg"))
  
  tibble(pearson_correlation = cor.test(sub_data$varX, sub_data$diff_p, method="pearson")$estimate[[1]],
         pearson_pvalue = cor.test(sub_data$varX, sub_data$diff_p, method="pearson")$p.value,
         spearman_correlation = cor.test(sub_data$varX, sub_data$diff_p, method="spearman")$estimate[[1]],
         spearman_pvalue = cor.test(sub_data$varX, sub_data$diff_p, method="spearman")$p.value,
         method_input_code = method_input_code_i,
         method_input_name = unique(sub_data$method_input_name),
         input_name = unique(sub_data$input_name),
         input_code = unique(sub_data$input_code),
         method = unique(sub_data$method),
         cg = site_i)
}) %>% bind_rows()
  

}) %>% bind_rows()

saveRDS(corrtab, here("outputs/ValidationCommonGarden/MortalityModels/corrtab.rds"))
```


We plot the correlations.

```{r PlotCorrelationsModelWithoutGO, eval=T}
corrtab <- readRDS(here("outputs/ValidationCommonGarden/MortalityModels/corrtab.rds"))

correlation_types <- c("pearson_correlation", "spearman_correlation")

lapply(correlation_types, function(coeff){
  
  p <- corrtab %>%
    pivot_longer(values_to = "correlation_estimate", names_to = "correlation_type", cols = all_of(correlation_types)) %>% 
    mutate(correlation_pvalue = ifelse(correlation_type == "pearson_correlation", pearson_pvalue, spearman_pvalue)) %>% 
    dplyr::select(-pearson_pvalue,-spearman_pvalue) %>% 
    mutate(pvalue_signi = ifelse(correlation_pvalue < 0.05, "p-value < 0.05", "p-value ≥ 0.05")) %>% 
    filter(correlation_type == coeff) %>% 
    mutate(cg_name = case_when(cg == "asturias" ~ "Asturias, Spain (37 months)",
                               cg == "bordeaux" ~ "Bordeaux, France (85 months)",
                               cg == "caceres" ~ "Cáceres, Spain (8 months)",
                               cg == "madrid" ~ "Madrid, Spain (13 months)",
                               cg == "portugal" ~ "Fundão, Portugal (27 months)")) %>% 
    mutate(input_name = factor(input_name, levels = c(unique(corrtab$input_name)[[13]],
                                                      unique(corrtab$input_name)[[11]],
                                                      unique(corrtab$input_name)[[12]],
                                                      unique(corrtab$input_name)[[10]],
                                                      unique(corrtab$input_name)[[8]],
                                                      unique(corrtab$input_name)[[9]],
                                                      unique(corrtab$input_name)[[1]],
                                                      unique(corrtab$input_name)[[2]],
                                                      unique(corrtab$input_name)[[3]],
                                                      unique(corrtab$input_name)[[4]],
                                                      unique(corrtab$input_name)[[5]],
                                                      unique(corrtab$input_name)[[6]],
                                                      unique(corrtab$input_name)[[7]])),
           method = factor(method, levels = c(unique(corrtab$method)[[2]],
                                              unique(corrtab$method)[[3]],
                                              unique(corrtab$method)[[4]],
                                              unique(corrtab$method)[[5]],
                                              unique(corrtab$method)[[6]],
                                              unique(corrtab$method)[[1]])),
           cg_name = factor(cg_name, levels = c("Madrid, Spain (13 months)",
                                                "Cáceres, Spain (8 months)",
                                                "Asturias, Spain (37 months)",
                                                "Bordeaux, France (85 months)",
                                                "Fundão, Portugal (27 months)")))

# Plots with CTD and SNP sets
# ===========================
p_allvar <- p %>% ggplot(aes(x = method,
                             y = correlation_estimate,
                             color = input_name,
                             shape = pvalue_signi)) +
  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=0, ymax=Inf), color="transparent", fill="green", alpha=0.005) + 
  geom_hline(yintercept = 0,color="gray") +
  geom_point(position = position_dodge(width = .5), size=5) +
  facet_wrap(~cg_name, ncol=2) + 
  {if(coeff=="pearson_correlation") ylab("Pearson correlation estimates")} + 
  {if(coeff=="spearman_correlation") ylab("Spearman correlation estimates (rank correlations)") } + 
  xlab("") +
  ylim(c(-0.44,0.6)) +
  scale_color_manual(values=colors_coeff)+
  scale_shape_manual(values = c(16,18)) + #, name="p-value of the correlations"
  theme_bw() +
  labs(color="",shape="") +
  theme(axis.text.x =  element_text(size=13),
        axis.text.y = element_text(size=13),
        axis.title.y = element_text(size=16),
        legend.title = element_blank(), 
        strip.text.x = element_text(size = 16),
        strip.background = element_blank(),
        legend.position = c(0.77,0.15),
        legend.text=element_text(size=13),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  guides(color = guide_legend(ncol=1),
         shape = guide_legend(override.aes = list(size =2 )))
p_allvar
# save in pdf and png
ggsave(p_allvar,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsandCTD.pdf")),
       device="pdf",
       height=13.6,
       width=15)

ggsave(p_allvar,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsandCTD.png")),
       height=13.6,
       width=15)



# Adding some images to represent the climatic differences among common gardens
annotation_custom2 <- function (grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, data){ layer(data = data, stat = StatIdentity, position = PositionIdentity, 
        geom = ggplot2:::GeomCustomAnn,
        inherit.aes = TRUE, params = list(grob = grob, 
                                          xmin = xmin, xmax = xmax, 
                                          ymin = ymin, ymax = ymax))}

df_png <- p %>% 
  dplyr::select(cg_name) %>%
  distinct %>% 
  dplyr::mutate(image = case_when(cg_name == "Asturias, Spain (37 months)" ~ "reports/cloud.png",
                                  cg_name == "Bordeaux, France (85 months)" ~ "reports/cloud.png",
                                  cg_name == "Cáceres, Spain (8 months)" ~ "reports/sun.png",
                                  cg_name == "Madrid, Spain (13 months)" ~ "reports/sun.png",
                                  cg_name == "Fundão, Portugal (27 months)" ~ 'reports/cloud_and_sun.png'))

list_pngs <- lapply(unique(p$cg_name), function(cg_name_i){
  
sub <-  p %>% 
  filter(cg_name==cg_name_i) %>%
  slice(1)

png_cg = annotation_custom2(rasterGrob(readPNG(here(df_png[df_png$cg_name==cg_name_i,"image"])),interpolate=TRUE), 
                            ymin = -0.5,
                            ymax= -0.3,
                            xmin = 0.5,
                            xmax = 1.1, 
                            data=sub)
})

p_allvar_images <- p_allvar + list_pngs[[1]]+ list_pngs[[2]]+ list_pngs[[3]]+ list_pngs[[4]]+ list_pngs[[5]]

p_allvar_images

# save in pdf and png
ggsave(p_allvar_images,
       file=here(paste0("figs/ValidationCommonGarden/MortalityModels/",coeff,"_SNPsandCTD_WithImages.pdf")),
       device="pdf",
       height=13.6,
       width=15)

})
```


# Height models

In this section, we estimate the association between **genomic offset (GO) predictions** or **climate transfer distances (CTD)** and **tree height**, independently in the five common gardens. We compare four different mathematical models.

We first subset height measurements from the dataset (below the first five rows of the dataset are shown).

```{r LoadHeigthData}
height_measurements <- c("AST_htmar14","BDX_htnov18","CAC_htdec11","MAD_htdec11","POR_htmay13")

height_data <- pheno_data %>% 
  dplyr::rename(cg = site) %>% 
  dplyr::select(cg,block,pop,clon,tree,any_of(height_measurements)) %>% 
  pivot_longer(cols=any_of(height_measurements), names_to=NULL,values_to="height",values_drop_na = TRUE)

height_data[1:5,] %>% kable_mydf
```


We write a function to plot the model coefficients :

```{r FunctionPlotCoefficients, eval=T}
coeff_y_axis <- list(beta_X1 = "Regression coefficients $\\beta_{X_1}$ in height models",
                     beta_X2 = "Regression coefficients $\\beta_{X_2}$ in height models",
                     beta_H = "Regression coefficients $\\beta_H$ in height models",
                     R_squared = "Proportion of variance explained ($R^2$) in height models",
                     classic_R2 = "Classic $R^2$ in height models",
                     bayes_R2_res = "Residual-based Bayes $R^2$ in height models",
                     bayes_R2_mod = "Model-based Bayes $R^2$ in height models")


generate_interval_plots <- function(model_i){
  
  coefftab <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/coefftab_",model_i,".rds")))
  params <-  coefftab$term %>% unique() %>% str_subset("^beta|squared|R2")
  
  
  p <- lapply(params, function(coeff){
    
    if(coeff %in% c("beta_X1", "beta_X2","beta_H","R_squared")){
      p_beta <- coefftab %>% 
        filter(term %in% c("beta_X1", "beta_X2")) %>% 
        pivot_wider(names_from = "term", values_from = c("mean","conf_low","conf_high","std_deviation")) %>% 
        mutate(expected = ifelse(conf_high_beta_X1<0 & conf_low_beta_X2<0 & conf_high_beta_X2>0 , "Expected associations", "Non-expected associations")) %>% 
        dplyr::select(-contains("mean"),-contains("conf"), -contains("deviation"))
      }
    
    p <- coefftab %>% filter(term==coeff) 
    
    if(coeff %in% c("beta_X1", "beta_X2","beta_H","R_squared")){p <- p %>% left_join(p_beta)}
    
    p <- p %>% mutate(cg_name = case_when(cg == "asturias" ~ "Asturias, Spain (37 months)",
                                          cg == "bordeaux" ~ "Bordeaux, France (85 months)",
                                          cg == "caceres" ~ "Cáceres, Spain (8 months)",
                                          cg == "madrid" ~ "Madrid, Spain (13 months)",
                                          cg == "portugal" ~ "Fundão, Portugal (27 months)"),
                      input_name = factor(input_name, levels = c(unique(coefftab$input_name)[[13]],
                                                                 unique(coefftab$input_name)[[11]],
                                                                 unique(coefftab$input_name)[[12]],
                                                                 unique(coefftab$input_name)[[10]],
                                                                 unique(coefftab$input_name)[[8]],
                                                                 unique(coefftab$input_name)[[9]],
                                                                 unique(coefftab$input_name)[[1]],
                                                                 unique(coefftab$input_name)[[2]],
                                                                 unique(coefftab$input_name)[[3]],
                                                                 unique(coefftab$input_name)[[4]],
                                                                 unique(coefftab$input_name)[[5]],
                                                                 unique(coefftab$input_name)[[6]],
                                                                 unique(coefftab$input_name)[[7]])),
                      method = factor(method, levels = c(unique(coefftab$method)[[2]],
                                                         unique(coefftab$method)[[3]],
                                                         unique(coefftab$method)[[4]],
                                                         unique(coefftab$method)[[5]],
                                                         unique(coefftab$method)[[6]],
                                                         unique(coefftab$method)[[1]])),
                      cg_name = factor(cg_name, levels = c("Madrid, Spain (13 months)",
                                                           "Cáceres, Spain (8 months)",
                                                           "Asturias, Spain (37 months)",
                                                           "Bordeaux, France (85 months)",
                                                           "Fundão, Portugal (27 months)")))

# Plots with CTD and SNP sets
# ===========================
    if(coeff %in% c("beta_X1", "beta_X2","beta_H", "R_squared")){
      p_allvar <- p %>% 
        ggplot(aes(x = method,
                   y = mean,
                   ymin = conf_low, 
                   ymax = conf_high,
                   color = input_name,
                   shape = expected)) +
        {if(coeff=="beta_X1")  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=0), color="transparent", fill="green", alpha=0.005)} +
        {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_rect(data=nullR2,inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf,
                                                                                                                                      ymin=conf_low, ymax=conf_high),
                                                                                                   color="transparent", fill="brown", alpha=0.2)} + 
        {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_hline(data=nullR2,aes(yintercept=mean), color="brown")} +
        geom_hline(yintercept = 0,color="gray") +
        geom_pointinterval(position = position_dodge(width = .4),point_size=3.5,size=3) + # 
        facet_wrap(~cg_name, ncol=2) + #, scales="free_x", space = "free" 
        ylab(TeX(coeff_y_axis[[coeff]])) + xlab("") +
        scale_color_manual(values=colors_coeff) +
        scale_shape_manual(
          values = c(16, 3),
          labels = c(expression("Expected associations, i.e., " ~ CI[95~"%"](beta[X1]) < 0 ~ "& " ~ 0 %in% CI[95~"%"](beta[X2])),
                     "Non-expected associations")) +
        theme_bw() +
        labs(color="",shape="") +
        theme(axis.text.x =  element_text(size=13),
              axis.text.y = element_text(size=13),
              axis.title.y = element_text(size=16),
              axis.title.x = element_text(size=1),
              legend.title=element_blank(), 
              strip.text.x = element_text(size = 16),
              strip.background = element_blank(),
              legend.position = c(0.77,0.15),
              legend.box.spacing = unit(0, "pt"),
              legend.text=element_text(size=11),
              panel.grid.minor.x=element_blank(),
              panel.grid.major.x=element_blank()) +
        guides(color=guide_legend(ncol=1),
               shape = guide_legend(override.aes = list(size =2)))
      
       # save in pdf
      ggsave(p_allvar,
             file=here(paste0("figs/ValidationCommonGarden/HeightModels/",coeff,"_",model_i,"_SNPsandCTD.pdf")),
             device="pdf",
             height=13.6,
             width=15)
      
      
      
      # Figure in the main manuscript
      ###############################
      
      # We want to add some images to represent the climatic differences among common gardens
      
      
      if(coeff=="beta_X1"& model_i=="M2"){
        
        annotation_custom2 <- function (grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, data){ layer(data = data, 
                                                                                                             stat = StatIdentity, 
                                                                                                             position = PositionIdentity, 
                                                                                                             geom = ggplot2:::GeomCustomAnn,
                                                                                                             inherit.aes = TRUE, 
                                                                                                             params = list(grob = grob, 
                                                                                                                           xmin = xmin, 
                                                                                                                           xmax = xmax, 
                                                                                                                           ymin = ymin, 
                                                                                                                           ymax = ymax))}
        
        df_png <- p %>% 
          dplyr::select(cg_name) %>%
          distinct %>% 
          dplyr::mutate(image = case_when(cg_name == "Asturias, Spain (37 months)" ~ "reports/cloud.png",
                                          cg_name == "Bordeaux, France (85 months)" ~ "reports/cloud.png",
                                          cg_name == "Cáceres, Spain (8 months)" ~ "reports/sun.png",
                                          cg_name == "Madrid, Spain (13 months)" ~ "reports/sun.png",
                                          cg_name == "Fundão, Portugal (27 months)" ~ 'reports/cloud_and_sun.png'))
        
        list_pngs <- lapply(unique(p$cg_name), function(cg_name_i){
          sub <-  p %>% 
            filter(cg_name==cg_name_i) %>%
            slice(1)
          
          png_cg = annotation_custom2(rasterGrob(readPNG(here(df_png[df_png$cg_name==cg_name_i,"image"])),interpolate=TRUE), 
                                      ymin = -0.44,
                                      ymax= -0.3,
                                      xmin = 0.37,
                                      xmax = 1.4, 
                                      data=sub)
          })
        
        
        p_allvar_images <- p_allvar + list_pngs[[1]]+ list_pngs[[2]]+ list_pngs[[3]]+ list_pngs[[4]]+ list_pngs[[5]]
        
        # save in pdf
        ggsave(p_allvar_images,
               file=here(paste0("figs/ValidationCommonGarden/HeightModels/",coeff,"_",model_i,"_SNPsandCTD_WithCloudAndSunImages.pdf")),
               device="pdf",
               height=13.6,
               width=15)
      }
      }
    
    if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2"){
      nullR2 <- readRDS(file = here("outputs/ValidationCommonGarden/HeightModels/coefftab_M2_WithoutPredictor.rds")) %>%
        filter(term==coeff) %>% 
        inner_join(distinct(p[,c("cg","cg_name")]),by="cg")
      
      
      p_allvar <- p %>% 
        ggplot(aes(x = method,
                   y = mean,
                   ymin = conf_low, 
                   ymax = conf_high,
                   color = input_name,
                   shape = input_name)) +
        {if(coeff=="beta_X1")  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=0), color="transparent", fill="green", alpha=0.005)} + 
        {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_rect(data=nullR2,inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf,
                                                                                                                                      ymin=conf_low, ymax=conf_high),
                                                                                                   color="transparent", fill="brown", alpha=0.2)} + 
        {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_hline(data=nullR2,aes(yintercept=mean), color="brown")} +
        geom_hline(yintercept = 0,color="gray") +
        geom_pointinterval(position = position_dodge(width = .4),point_size=3.5,size=3) + # 
        facet_wrap(~cg_name, ncol=2) + #, scales="free_x", space = "free" 
        ylab(TeX(coeff_y_axis[[coeff]])) + xlab("") +
        scale_color_manual(values=colors_coeff) +
        scale_shape_manual(values = c(rep(17,6),rep(16,7))) +
        theme_bw() +
        labs(color="",shape="") +
        theme(axis.text.x =  element_text(size=13),
              axis.text.y = element_text(size=13),
              axis.title.y = element_text(size=16),
              axis.title.x = element_text(size=1),
              legend.title=element_blank(), 
              strip.text.x = element_text(size = 16),
              strip.background = element_blank(),
              legend.position = c(0.77,0.15),
              legend.text=element_text(size=11),
              panel.grid.minor.x=element_blank(),
              panel.grid.major.x=element_blank()) +
        guides(color=guide_legend(ncol=1),
               shape = guide_legend(override.aes = list(size =2 )))
      
          # save in pdf
      ggsave(p_allvar,
             file=here(paste0("figs/ValidationCommonGarden/HeightModels/",coeff,"_",model_i,"_SNPsandCTD.pdf")),
             device="pdf",
             height=11,
             width=11)
}
    

    
    # save in png
    # ggsave(p_allvar,
    #        file=here(paste0("figs/ValidationCommonGarden/HeightModels/",coeff,"_",model_i,"_SNPsandCTD.png")),
    #        height=11,
    #        width=14)
    
    
    # Plots only SNP sets
    # ===================
    if(coeff %in% c("beta_X1", "beta_X2", "beta_H",  "R_squared")){

            p_SNPs <- p %>% 
              filter(!method == "CTD") %>% 
              ggplot(aes(x = method,
                         y = mean,
                         ymin = conf_low, 
                         ymax = conf_high,
                         color = input_name,
                         shape = expected)) +
              {if(coeff=="beta_X1")  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=0), color="transparent", fill="green", alpha=0.005)} +
              {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_rect(data=nullR2,inherit.aes=FALSE, aes(xmin=-Inf, 
                                                                                                                                            xmax=Inf,
                                                                                                                                            ymin=conf_low,
                                                                                                                                            ymax=conf_high),
                                                                                                         color="transparent", fill="brown", alpha=0.2)} + 

              {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_hline(data=nullR2,aes(yintercept=mean), color="brown")} + 
              geom_hline(yintercept = 0,color="gray") +
              geom_pointinterval(position = position_dodge(width = .4),point_size=3.5,size=3) +
              facet_wrap(~cg_name, ncol=2) + #, scales="free_x", space = "free" 
              ylab(TeX(coeff_y_axis[[coeff]])) + xlab("") +
              scale_color_manual(values=colors_coeff) +
              scale_shape_manual(
                values = c(16, 3),
                labels = c(expression("Expected associations, i.e., " ~ CI[95~"%"](beta[X1]) < 0 ~ "& " ~ 0 %in% CI[95~"%"](beta[X2])),
                           "Non-expected associations"))+
              theme_bw() +
              labs(color="",shape="") +
              theme(axis.text.x =  element_text(size=13),
                    axis.text.y = element_text(size=13),
                    axis.title.y = element_text(size=16),
                    axis.title.x = element_text(size=1),
                    legend.title=element_blank(), 
                    strip.text.x = element_text(size = 16),
                    strip.background = element_blank(),
                    legend.position = c(0.77,0.15),
                    legend.text=element_text(size=13),
                    panel.grid.minor.x=element_blank(),
                    panel.grid.major.x=element_blank()) +
              guides(color=guide_legend(ncol=1),
                     shape = guide_legend(override.aes = list(size =2 )))
            
                # save in pdf
            ggsave(p_SNPs,
                   file=here(paste0("figs/ValidationCommonGarden/HeightModels/",coeff,"_",model_i,"_SNPsets.pdf")),
                   device="pdf",
                   height=12,
                   width=12)
    
    }
    
    
    
    if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2"){
      
      p_SNPs <- p %>% 
        filter(!method == "CTD") %>% 
        ggplot(aes(x = method,
                   y = mean,
                   ymin = conf_low, 
                   ymax = conf_high,
                   color = input_name,
                   shape = input_name)) +
        {if(coeff=="beta_X1")  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=0), color="transparent", fill="green", alpha=0.005)} + 
        {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_rect(data=nullR2,inherit.aes=FALSE, aes(xmin=-Inf, 
                                                                                                                                      xmax=Inf,
                                                                                                                                      ymin=conf_low, 
                                                                                                                                      ymax=conf_high),
                                                                                                   color="transparent", fill="brown", alpha=0.2)} + 
        {if(coeff %in% c("classic_R2", "bayes_R2_mod", "bayes_R2_res") & model_i=="M2")  geom_hline(data=nullR2,aes(yintercept=mean), color="brown")} +
        geom_hline(yintercept = 0,color="gray") +
        geom_pointinterval(position = position_dodge(width = .4),point_size=3.5,size=3) +
        facet_wrap(~cg_name, ncol=2) + #, scales="free_x", space = "free" 
        ylab(TeX(coeff_y_axis[[coeff]])) + xlab("") +
        scale_color_manual(values=colors_coeff) +
        scale_shape_manual(values = c(rep(17,6),rep(16,7))) +
        theme_bw() +
        labs(color="",shape="") +
        theme(axis.text.x =  element_text(size=13),
              axis.text.y = element_text(size=13),
              axis.title.y = element_text(size=16),
              axis.title.x = element_text(size=1),
              legend.title=element_blank(), 
              strip.text.x = element_text(size = 16),
              strip.background = element_blank(),
              legend.position = c(0.77,0.15),
              legend.text=element_text(size=13),
              panel.grid.minor.x=element_blank(),
              panel.grid.major.x=element_blank()) +
        guides(color=guide_legend(ncol=1),
               shape = guide_legend(override.aes = list(size =2 )))
      
      
      # save in pdf
      ggsave(p_SNPs,
             file=here(paste0("figs/ValidationCommonGarden/HeightModels/",coeff,"_",model_i,"_SNPsets.pdf")),
             device="pdf",
             height=11,
             width=11)
      }

    
    # save in png
    # ggsave(p_SNPs,
    #        file=here(paste0("figs/ValidationCommonGarden/HeightModels/",coeff,"_",model_i,"_SNPsets.png")),
    #        height=7,
    #        width=8)
    
    
    return(p_allvar)
    
    })
  
  return(p)
  }
```

We write a function to plot the quadratic relationships between tree height and the GO predictions / CTD.

```{r MakePolyPlots, fig.width=12, fig.height=7, eval=T}
generate_poly_plots <- function(model_i){

coefftab <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/coefftab_",model_i,".rds")))

x <- seq(-2,2,0.01)
poly_function <- function(a,b,x) {a * x^2 + b * x}

ggtab <- coefftab %>% 
  filter(term %in% c("beta_X1","beta_X2")) %>% 
  mutate(cg_name = case_when(cg == "asturias" ~ "Asturias, Spain (37 months)",
                             cg == "bordeaux" ~ "Bordeaux, France (85 months)",
                             cg == "caceres" ~ "Cáceres, Spain (8 months)",
                             cg == "madrid" ~ "Madrid, Spain (13 months)",
                             cg == "portugal" ~ "Fundão, Portugal (27 months)"),
         input_name = factor(input_name, levels = c(unique(coefftab$input_name)[[13]],
                                                    unique(coefftab$input_name)[[11]],
                                                    unique(coefftab$input_name)[[12]],
                                                    unique(coefftab$input_name)[[10]],
                                                    unique(coefftab$input_name)[[8]],
                                                    unique(coefftab$input_name)[[9]],
                                                    unique(coefftab$input_name)[[1]],
                                                    unique(coefftab$input_name)[[2]],
                                                    unique(coefftab$input_name)[[3]],
                                                    unique(coefftab$input_name)[[4]],
                                                    unique(coefftab$input_name)[[5]],
                                                    unique(coefftab$input_name)[[6]],
                                                    unique(coefftab$input_name)[[7]])),
         method = factor(method, levels = c(unique(coefftab$method)[[2]],
                                            unique(coefftab$method)[[3]],
                                            unique(coefftab$method)[[4]],
                                            unique(coefftab$method)[[5]],
                                            unique(coefftab$method)[[6]],
                                            unique(coefftab$method)[[1]])),
         cg_name = factor(cg_name, levels = c("Madrid, Spain (13 months)",
                                              "Cáceres, Spain (8 months)",
                                              "Asturias, Spain (37 months)",
                                              "Bordeaux, France (85 months)",
                                              "Fundão, Portugal (27 months)"))) %>% 
  pivot_wider(names_from="term", values_from = c("mean","std_deviation","conf_low","conf_high"))

ggtab <- lapply(unique(ggtab$cg_name), function(cg_name_i){
  
  lapply(unique(ggtab$method_input_name), function(method_input_name_i){
  
  subggtab <- ggtab %>% filter(method_input_name == method_input_name_i & cg_name == cg_name_i)
  
  poly_function(a=subggtab$mean_beta_X2, b=subggtab$mean_beta_X1,x=x)
  }) %>% 
    setNames(unique(ggtab$method_input_name)) %>% 
    bind_rows(.id="method_input_name") %>% 
    mutate(x_axis = x)
}) %>% 
  setNames(unique(ggtab$cg_name)) %>% 
  bind_rows(.id="cg_name") %>% 
  pivot_longer(cols=any_of(unique(ggtab$method_input_name)),names_to="method_input_name",values_to="predictions") %>% 
  inner_join(ggtab[,c("method","input_name", "method_input_name","cg","cg_name")] %>% distinct(), by=c("method_input_name","cg_name"))
  

# Below, you can use unique(ggtab$cg) or unique(ggtab$cg_legend)
ggplots <- lapply(unique(ggtab$cg_name), function(cg_name_i){
  
  lapply(unique(ggtab$method), function(method_i){
    
    ptab <- ggtab %>%
      filter(cg_name %in% cg_name_i & 
             method %in% method_i)
    
 p <- ptab %>%  ggplot(aes(x = x_axis,
             y = predictions,
             col = input_name)) +
      geom_hline(yintercept=0,color="black") +
      geom_line(linewidth=1) +
      ylab('Standardized tree height') + 
      ylim(c(min(ggtab$predictions),max(ggtab$predictions))) +
      
      {if(method_i %in% c("GDM", "GF", "RDA", "pRDA", "LFMM")) scale_color_manual(values=c("#004586FF","#FF7F0FFF","#FFD320FF","#579D1CFF","#7E0021FF","#83CAFFFF"), name = "SNP set")} +
         
      {if(method_i %in% c("GDM", "GF", "RDA", "pRDA", "LFMM")) xlab(TeX("Standardized genomic offset predictions"))} + 
      {if(method_i == "CTD") scale_color_manual(values=c("aquamarine3","#FEB5A2FF","#F02720FF","darkviolet","deeppink","cyan2","chocolate4"), name = "Climatic distance")} +
      {if(method_i == "CTD") xlab(TeX("Standardized climatic transfer distance"))} + 
      labs(title=(paste0(cg_name_i, " - ", method_i))) +
      theme_bw() +
      theme(axis.text.x = element_text(size=13),
            axis.text.y = element_text(size=13),
            axis.title = element_text(size=16),
            legend.box="horizontal",
            legend.key.width = unit(1,"cm"),
            legend.background = element_blank(),
            legend.box.background = element_blank(),
            legend.key = element_blank(),
            legend.position = c(0.68,0.83)) + 
      guides(color=guide_legend(ncol=1))

    ggsave(filename = here(paste0("figs/ValidationCommonGarden/HeightModels/ScatterPlotsPredictedRelationships/ScatterPlotsPredictedRelationships_",
                              model_i,"_",unique(ptab$cg),"_",method_i,".pdf")), device="pdf", width=7,height=7)    
  })
})
}
```
  
## Model 1

### Model equation and code 


\begin{align*}
Y_{ipb}  &\sim \mathcal{N}(\mu_{pb},\sigma^{2}) \\
\mu_{pb} &= B_b + \beta_{X1}X_p + \beta_{X2}X^2_p\\
\sigma &\sim \text{Exp}(1) \\
\begin{bmatrix} B_b  \\ \beta_{X1} \\ \beta_{X2} \end{bmatrix} &\sim \mathcal{N}(0,1) \\
\end{align*}

  - $Y_{ipb}$ is the height of the individual $i$ in the population $p$ and block $b$.
  - $\sigma^{2}$ is the residual variance of the model.
  - $B_b$ are the block intercepts.
  - $X_p$ is the GO or CTD of the population $p$, with $\beta_{X1}$ and $\beta_{X2}$ being its linear and quadratic coefficients, respectively. The quadratic term was included to allow for potential nonlinearity in the response, following @fitzpatrick2021experimental.


```{r CompileHeightModelM1, message=F, warning=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_HeightModel_M1.stan"))
print(stancode)

params_to_estimate <- c("beta_X1","beta_X2","R_squared","sigma","alpha_bloc")
```

### Run the models

```{r RunHeightModelM1, eval=F}
lapply(unique(height_data$cg), function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
  
    # Subset the data
    df_sub <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
    
    sub_data <- height_data %>% 
      filter(cg == site_i) %>% 
      left_join(df_sub, by = c("cg","pop"))
      
    # Data in a list for Stan
    stanlist <- list(N = nrow(sub_data),
                     Y=(sub_data$height-mean(sub_data$height))/sd(sub_data$height),
                     X=(sub_data$varX -mean(sub_data$varX))/sd(sub_data$varX),
                     nb_bloc = length(unique(sub_data$block)),
                     bloc = as.numeric(as.factor(sub_data$block)))

    # Run the models
    mod <- sampling(stancode, 
                    data = stanlist, 
                    iter = 2000, 
                    warmup = 1400, 
                    chains = 4, 
                    cores = 4, 
                    save_warmup = FALSE,
                    pars = params_to_estimate) 
    
    # Save the model and the stanlist
    list(mod = mod, 
         stanlist = stanlist) %>% 
      saveRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M1/",site_i,"_",method_input_code_i,".rds")))
    
    
  })
})
```

```{r BuildCoeffTableM1, eval=T}
coefftab <- lapply(unique(height_data$cg),function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
    
    # Subset the data - keeping only one set of method / SNP set
    sub_data <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
  
    mod <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M1/",
                                    site_i,"_",method_input_code_i,".rds")))[["mod"]]
                     
    # Save coefficients
    broom.mixed::tidyMCMC(mod,
                          droppars = NULL, 
                          robust = FALSE, # give mean and standard deviation
                          ess = F, 
                          rhat = F, 
                          conf.int = T,
                          conf.level = 0.95) %>% 
      #filter(str_detect(term, c('beta'))) %>% 
      dplyr::rename(mean=estimate,
                    std_deviation=std.error,
                    conf_low=conf.low,
                    conf_high=conf.high) %>% 
      mutate(cg = site_i,
             method_input_code = method_input_code_i,
             method_input_name = unique(sub_data$method_input_name),
             method = unique(sub_data$method),
             input_name = unique(sub_data$input_name),
             input_code = unique(sub_data$input_code),
             .before=1)     

}) %>% bind_rows()
 
}) %>% bind_rows()
  
coefftab %>% 
  saveRDS(file=here("outputs/ValidationCommonGarden/HeightModels/coefftab_M1.rds"))
```

### Model coefficients

We plot the mean and 95% credible intervals of the $\beta_{X_1}$ and $\beta_{X_2}$ coefficients. Graph titles include the time in months corresponding to the age at which height and survival were recorded. Coefficients in the green area have the expected sign, reflecting lower height in populations with higher GO predictions.

```{r ModelCoeffM1, fig.width=15, fig.height=13.6, eval=T}
generate_interval_plots(model_i = "M1")
```

### Predicted quadratic relationships

We plot the predicted quadratic relationships between tree height and GO predictions / CTD.

```{r MakePolyPlotsM1, fig.width=12, fig.height=7, eval=T}
generate_poly_plots(model_i="M1")
```

### Interpretation

Higher genomic offset predictions are consistently associated with lower tree height only in Asturias. Most genomic offset predictions are also associated with lower tree height in Bordeaux.

In Fundão, Cáceres and Madrid, the association between genomic offset predictions and tree height are often in the opposite direction as expected. 

Interestingly, the climatic transfer distances based in the mean annual temperature and the annual precipitation are negatively associated with tree height in all common gardens (except Cáceres for the CTD based on annual precipitation). These CTD may therefore be better predictors of tree height in common gardens than the genomic offset predictions. 

Finally, I think that using tree height as a proxy for fitness to evaluate genomic offset predictions in common gardens may not be appropriate in maritime pine because this trait has a very low genetic-by-environment interaction (see previous papers). 
Therefore, the association between genomic offset predictions and tree height in Asturias and Bordeaux may not be due to a higher fitness of the trees that are best adapted to the climate in these common gardens, but more probably to height differences that are common across all environments (i.e. populations from Atlantic climates are generally taller).
This is confirmed by the models below in which the population-specific BLUPs for height across all common gardens was included as a confounder. When included, the association between genomic offset predictions and tree height in Asturias almost disappears and either disappears or goes in the opposite direction as expected in Bordeaux. Except the genomic offset predictions based on the RDA remain negatively associated with tree height in Bordeaux and Asturias. 

Therefore, I am not sure we can go very far in this validation step. We may retain that genomic offset predictions seem to show the most consistent association with tree height when generated with the RDA, and that this association is robust (though smaller) even when the fixed genetic differences across populations are included as confounder. 



## Model 2

### Model equation and code 

Model 2 = Model 1 + Initial height as a confounder.

\begin{align*}
Y_{ipb}  &\sim \mathcal{N}(\mu_{pb},\sigma^{2}) \\
\mu_{pb} &= B_b + \beta_{X1}X_p + \beta_{X2}X^2_p + \beta_H H_p\\
\sigma &\sim \text{Exp}(1) \\
\begin{bmatrix} B_b  \\ \beta_{X1} \\ \beta_{X2} \\ \beta_H \end{bmatrix} &\sim \mathcal{N}(0,1) \\
\end{align*}

  - $Y_{ipb}$ is the height of the individual $i$ in the population $p$ and block $b$.
  - $\sigma^{2}$ is the residual variance of the model.
  - $B_b$ are the block intercepts.
  - $X_p$ is the GO or CTD of the population $p$, with $\beta_{X1}$ and $\beta_{X2}$ being its linear and quadratic coefficients, respectively. The quadratic term was included to allow for potential nonlinearity in the response, following @fitzpatrick2021experimental.
  - $H_p$ is a proxy of the initial height of the trees from population $p$, i.e. when trees were planted. For that, we used the population varying intercepts calculated across all common gardens in the model 1 of @archambeau2022combining.


```{r CompileHeightModelM2, message=F,warning=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_HeightModel_M2.stan"))
print(stancode)

params_to_estimate <- c("beta_X1","beta_X2","beta_H","sigma","alpha_bloc",
                        "classic_R2","bayes_R2_mod","bayes_R2_res")
```

### Run the models


```{r RunHeightModelM2, eval=F}
lapply(unique(height_data$cg), function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
  
    # Subset the data
    df_sub <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
    
    sub_data <- height_data %>% 
      filter(cg == site_i) %>% 
      left_join(df_sub, by = c("cg","pop")) %>% 
      left_join(pop_heights %>% dplyr::select(any_of(c("height", "pop"))) %>% dplyr::rename(init_height=height), by="pop")
      
    # Data in a list for Stan
    stanlist <- list(N = nrow(sub_data),
                     Y=(sub_data$height-mean(sub_data$height))/sd(sub_data$height),
                     X=(sub_data$varX -mean(sub_data$varX))/sd(sub_data$varX),
                     H=(sub_data$init_height -mean(sub_data$init_height))/sd(sub_data$init_height),
                     nb_bloc = length(unique(sub_data$block)),
                     bloc = as.numeric(as.factor(sub_data$block)))

    # Run the models
    mod <- sampling(stancode, 
                    data = stanlist, 
                    iter = 2000, 
                    warmup = 1400, 
                    chains = 4, 
                    cores = 4, 
                    save_warmup = FALSE,
                    pars = params_to_estimate) 
    
    # Save the model and the stanlist
    list(mod = mod, 
         stanlist = stanlist) %>% 
      saveRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M2/",site_i,"_",method_input_code_i,".rds")))
    
    
  })
})
```


```{r BuildCoeffTableM2, eval=T}
coefftab <- lapply(unique(height_data$cg),function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
    
    # Subset the data - keeping only one set of method / SNP set
    sub_data <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
  
    mod <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M2/",
                                    site_i,"_",method_input_code_i,".rds")))[["mod"]]
                     
    # Save coefficients
    broom.mixed::tidyMCMC(mod,
                          droppars = NULL, 
                          robust = FALSE, # give mean and standard deviation
                          ess = F, 
                          rhat = F, 
                          conf.int = T,
                          conf.level = 0.95) %>% 
      #filter(str_detect(term, c('beta'))) %>% 
      dplyr::rename(mean=estimate,
                    std_deviation=std.error,
                    conf_low=conf.low,
                    conf_high=conf.high) %>% 
      mutate(cg = site_i,
             method_input_code = method_input_code_i,
             method_input_name = unique(sub_data$method_input_name),
             method = unique(sub_data$method),
             input_name = unique(sub_data$input_name),
             input_code = unique(sub_data$input_code),
             .before=1)     

}) %>% bind_rows()
 
}) %>% bind_rows()
  
coefftab %>% 
  saveRDS(file=here("outputs/ValidationCommonGarden/HeightModels/coefftab_M2.rds"))
```

### Proportion of variance explained



The proportion of variance explained by the height models was estimated with the classical $\mathcal{R}^{2}$, the residual-based Bayesian $\mathcal{R}^{2}$ and the model-based Bayesian $\mathcal{R}^{2}$.

The classical $\mathcal{R}^{2}$ is calculated as follows:
 
 $$\mathcal{R}^{2}=1 - \frac{Var(Y-\mu)}{Var(Y)} = \frac{Var(\mu)}{Var(Y)}$$

where $\mu$ is the linear predictor of the model and $Y$ the observed data (tree height).

The Bayesian version of $\mathcal{R}^{2}$ introduced in \citet{gelmanRsquaredBayesianRegression2019} is calculated as follows:

$$\mathcal{R}^{2}=Var_\mu/(Var_\mu + Var_ {res})$$

where $Var_\mu$ is the variance of the modelled predictive means and $Var_{res}$ is the residual variance. 

In the residual-based Bayesian $\mathcal{R}^{2}$, $Var_{res}$ comes from draws from the residual distribution: $Var_{res} = Var(Y-\mu)$. In the model-based Bayesian $\mathcal{R}^{2}$, $Var_{res}$ comes from the posterior quantities of the fitted model such as $Var_{res} = \sigma^2$. As stated in \cite{gelmanRsquaredBayesianRegression2019}, this Bayesian version of $\mathcal{R}^{2}$ can be considered as `a data-based estimate of the proportion of variance explained for new data`.

More information on the Bayesian $\mathcal{R}^{2}$ can also be found in the following vignette: [Bayesian R2 and LOO-R2 by Aki Vehtari, Andrew Gelman, Ben Goodrich and Jonah Gabry](https://avehtari.github.io/bayes_R2/bayes_R2.html).

In the main manuscript, we report results from the model-based Bayesian $\mathcal{R}^{2}$.

### Running model without predictor

```{r M2WithoutPredictor, eval=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_HeightModel_M2_WithoutPredictor.stan"))

params_to_estimate <- c("beta_H","sigma","alpha_bloc","classic_R2","bayes_R2_mod","bayes_R2_res")

coefftab <- lapply(unique(height_data$cg), function(site_i){
  
    # Subset the data
    sub_data <- height_data %>% 
      filter(cg == site_i) %>% 
      left_join(pop_heights %>% dplyr::select(any_of(c("height", "pop"))) %>% dplyr::rename(init_height=height), by="pop")
      
    # Data in a list for Stan
    stanlist <- list(N = nrow(sub_data),
                     Y=(sub_data$height-mean(sub_data$height))/sd(sub_data$height),
                     H=(sub_data$init_height -mean(sub_data$init_height))/sd(sub_data$init_height),
                     nb_bloc = length(unique(sub_data$block)),
                     bloc = as.numeric(as.factor(sub_data$block)))

    # Run the models
    mod <- sampling(stancode, data = stanlist, iter = 2000, chains = 4, cores = 4, save_warmup = FALSE,
                    pars = params_to_estimate) 
    
    # Save the models
    mod %>% saveRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M2/M2_",site_i,"_WithoutPredictor.rds")))
    
    
    # Extract coefficients
    broom.mixed::tidyMCMC(mod,
                          pars=params_to_estimate,
                          droppars = NULL, 
                          robust = FALSE, # give mean and standard deviation
                          ess = F, 
                          rhat = F, 
                          conf.int = T,
                          conf.level = 0.95) %>% 
    dplyr::rename(mean=estimate,
                  std_deviation=std.error,
                  conf_low=conf.low,
                  conf_high=conf.high) %>% 
    mutate(cg=site_i,
           method="WithoutPredictor",
           .before=1)
    
    
  }) %>% bind_rows()

coefftab %>% saveRDS(file=here("outputs/ValidationCommonGarden/HeightModels/coefftab_M2_WithoutPredictor.rds"))
```

### Model coefficients

We plot the mean and 95% credible intervals of the $\beta_{X_1}$, $\beta_{X_2}$ and $\beta_H$ coefficients. Graph titles include the time in months corresponding to the age at which height and survival were recorded. Coefficients in the green area have the expected sign, reflecting lower height in populations with higher GO predictions.

```{r IntervalPlotsM2, fig.width=15, fig.height=13.6, eval=T}
generate_interval_plots(model_i = "M2")
```

### Vizualising predicted associations

#### Mean height predictions

We plot the mean predicted relationships between tree height and GO predictions / CTD.

```{r PolyPlotsM2, fig.width=12, fig.height=7, eval=T}
generate_poly_plots(model_i = "M2")
```
 
#### Height predictions with uncertainty intervals

The graphs above do not show the estimate uncertainty. We generate some graphs to visualize the uncertainty around the estimates :

  - the uncertainty in the mean estimates (i.e. variability in posterior draws of the linear predictor $\mu$)
  
  - the uncertainty in tree height predictions (i.e. after accounting for $\sigma$ in the predictions).

```{r HeightPredictionsM2, message=F,warning=F, fig.height=6, fig.width=6, eval=T}
#############################################################################
# Visualizing the relationships between GO predictions and height predictions
#############################################################################
model_i <- "M2"

coefftab <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/coefftab_",model_i,".rds"))) %>% 
  mutate(cg_name = case_when(cg == "asturias" ~ "Asturias, Spain (37 months)",
                             cg == "bordeaux" ~ "Bordeaux, France (85 months)",
                             cg == "caceres" ~ "Cáceres, Spain (8 months)",
                             cg == "madrid" ~ "Madrid, Spain (13 months)",
                             cg == "portugal" ~ "Fundão, Portugal (27 months)"))

lapply(unique(coefftab$cg), function(cg_i){
  
  lapply(unique(coefftab$method_input_code), function(method_input_code_i){
    
    sub_coefftab <- coefftab %>% 
      filter(method_input_code == method_input_code_i & cg == cg_i)
    
    # Load the stanlist
    stanlist <- readRDS(file = here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M2/",cg_i,"_",method_input_code_i,".rds")))[[2]]
  
    # Loading the model
    mod <- readRDS(file = here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M2/",cg_i,"_",method_input_code_i,".rds")))[[1]]

    # we extract the posterior distributions of all parameters
    post <- as.data.frame(mod)

    # Vector of predictor values (based on the min and max of the GO predictions/CTD )
    x_vec <- seq(min(stanlist$X),max(stanlist$X),0.05)


    # Predicting the linear predictor mu (predicting mean-centered height without sigma uncertainty)
    ################################################################################################

    # we extract the posterior draws of mu, and its mean and HDPIs for each predictor value

    # Function to predict mean-centered height in block 2 and with the initial tree height fixed to the mean (i.e. fixed to zero as explanatory variables were mean-centered)
    f_mu <- function(x) post$`alpha_bloc[2]` + post$`beta_X1` * x + post$`beta_X2` * x^2 + post$`beta_H` * mean(stanlist$H)#mean(sub_data$init_height) 

    mu_pred <- 
      sapply(x_vec, f_mu) %>% 
      tibble::as_tibble() %>%
      rename_all(function(x) x_vec) %>%
      mutate(Iter = row_number()) %>%
      gather(x, y, -Iter) %>%
      group_by(x) %>%
      mutate(hpdi_l = HDInterval::hdi(y, credMass = 0.90)[1],
             hpdi_h = HDInterval::hdi(y, credMass = 0.90)[2]) %>%
      mutate(mu_mean = mean(y)) %>%
      ungroup() %>%
      mutate(x = as.numeric(x))
    
    # Keep mean and 90% HDPI of mu (one value for each iteration)
    mu_mean_df <- mu_pred %>%
      dplyr::select(x,mu_mean,hpdi_l,hpdi_h) %>% 
      dplyr::distinct()

   # Predicting mean-centered height with sigma uncertainty
   #########################################################

   # we extract the posterior draws of height predictions, and its mean and PIs for each predictor value
    
    y_pred <- 
      sapply(x_vec,
         function(x)
           rnorm(NROW(post),
                 post$`alpha_bloc[2]` + post$`beta_X1` * x + post$`beta_X2` * x^2 + post$`beta_H` *  mean(stanlist$H),#mean(sub_data$init_height),
                 post$sigma)) %>%
  as_tibble() %>%
  rename_all(function(x) x_vec) %>%
  mutate(Iter = row_number()) %>%
  gather(x, y, -Iter) %>%
  group_by(x) %>%
  mutate(hpdi_l = HDInterval::hdi(y, credMass = 0.90)[1],
         hpdi_h = HDInterval::hdi(y, credMass = 0.90)[2]
         # pi_l = rethinking::PI(y, prob = 0.90)[1],
         # pi_h = rethinking::PI(y, prob = 0.90)[2]
         ) %>%
  ungroup() %>%
  mutate(x = as.numeric(x)) %>% 
  dplyr::select(x,hpdi_l,hpdi_h) %>% 
  dplyr::distinct()


  # Plots
  #######

  # Plot options 
  y_limits <- c(-3,3)
  if(unique(sub_coefftab$method == "CTD")){x_axis <- "Mean-centered CTD"} else {
    x_axis <- "Mean-centered GO predictions"}
  y_axis <- "Mean-centered tree height"

  p <- ggplot() +
    ylim(y_limits) +
    labs(y=y_axis, x=x_axis) +
    theme_bw()

  # First 100 posterior draws of the linear predictor mu
  p1 <- p +
    geom_point(data = mu_pred %>% filter(Iter < 101),
               aes(x, y), alpha = .2, color = 'dodgerblue')
  
  # Mean (line) and 90% HPDI (shaded region) of the linear predictor mu
  p2 <- p +
    geom_ribbon(data = y_pred,
                mapping = aes(x=x, ymin=hpdi_l, ymax=hpdi_h), alpha = .1, fill='dodgerblue') +
    geom_ribbon(data = mu_mean_df,
                aes(x = x, ymin = hpdi_l, ymax = hpdi_h),
                alpha = .2,
                fill='dodgerblue') +
    geom_line(data = mu_mean_df,
              aes(x=x, y=mu_mean), 
              col="dodgerblue4")

  p1_p2 <- ggarrange(p1, p2 + labs(y=""), nrow = 1)

  # Title
  title <- ggdraw() + 
    draw_label(paste0(unique(sub_coefftab$cg_name)," - ",unique(sub_coefftab$method_input_name)),
               fontface = 'bold',
               x = 0, 
               hjust = 0) +   
  theme(plot.margin = margin(0, 0, 0, 7))

  # merge title and plots
  p1_p2 <- plot_grid(title, p1_p2, ncol = 1, rel_heights = c(0.1, 1))

  ggsave(p1_p2,
         file=here(paste0("figs/ValidationCommonGarden/HeightModels/HeightPredictions_MuPosteriorDraws_UncertaintyIntervals/",model_i,
                        "_",cg_i,"_",method_input_code_i,".pdf")),
         device="pdf",
         height=6,
         width=11)
  })
  })
```

### Correlation coefficients

Stan code of the height model without the genomic offset predictions or the CTD (i.e. only with height as predictor).

```{r CompileHeightModelWithoutPredictorWithPredictions, message=F, warning=F, eval=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_HeightModel_M2_WithoutPredictor_WithPredictions.stan"))
print(stancode)
```

```{r RunHeightModelWithoutPredictorWithPredictions, message=F,warning=F, eval=F}
lapply(unique(height_data$cg), function(site_i){
  
  # Subset the data
  sub_data <- height_data %>% 
    filter(cg == site_i) %>% 
    left_join(pop_heights %>% dplyr::select(any_of(c("height", "pop"))) %>% dplyr::rename(init_height=height), by="pop")
  
  # Data in a list for Stan
  stanlist <- list(N = nrow(sub_data),
                   Y=(sub_data$height-mean(sub_data$height))/sd(sub_data$height),
                   H=(sub_data$init_height -mean(sub_data$init_height))/sd(sub_data$init_height),
                   nb_bloc = length(unique(sub_data$block)),
                   bloc = as.numeric(as.factor(sub_data$block)))

  # Run the models
  mod <- sampling(stancode, 
                  data = stanlist, 
                  iter = 2000, 
                  chains = 4, 
                  cores = 4, 
                  save_warmup = FALSE,
                  warmup = 1400,
                  pars = "y_pred")
  
  # Save the stanlist and the model
  saveRDS(list(data=sub_data, mod=mod),
          file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M2/M2_WithoutPredictorWithPredictions_",site_i,".rds")))
                  
})
```

```{r BuildCorrTabHeightModelWithoutPredictorWithPredictions, message=F, warning=F, eval=T}
corrtab <-lapply(unique(height_data$cg), function(site_i){
  
  mod <- readRDS(mod, file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M2/M2_WithoutPredictorWithPredictions_",site_i,".rds")))
  
  # Model coefficients
  coefftab <- broom.mixed::tidyMCMC(mod$mod,
                                    pars= "y_pred",
                                    droppars = NULL, 
                                    robust = FALSE, # give mean and standard deviation
                                    ess = T, # effective sample size estimates
                                    rhat = T, # Rhat estimates
                                    conf.int = T, 
                                    conf.level = 0.95 # include 95% credible intervals
                                    ) %>% 
    dplyr::rename(conf95_low=conf.low,
                  conf95_high=conf.high,
                  mean=estimate,
                  std_deviation=std.error)  
  
  res_height_df <- mod$data %>%
    mutate(height_sd = (height-mean(height))/sd(height)) %>% 
    bind_cols(coefftab) %>% 
    mutate(res_height = height_sd - mean) %>% # observed height - predicted height 
    dplyr::select(cg, pop, res_height) %>% 
    group_by(pop) %>% 
    summarise(mean_res_height_pop =mean(res_height))
  
  
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
    
    sub_data <- df %>% 
      filter(method_input_code == method_input_code_i & cg == site_i) %>% 
      inner_join(res_height_df, by="pop")
    
    tibble(pearson_correlation = cor.test(sub_data$varX, sub_data$mean_res_height_pop, method="pearson")$estimate[[1]],
           pearson_pvalue = cor.test(sub_data$varX, sub_data$mean_res_height_pop, method="pearson")$p.value,
           spearman_correlation = cor.test(sub_data$varX, sub_data$mean_res_height_pop, method="spearman")$estimate[[1]],
           spearman_pvalue = cor.test(sub_data$varX, sub_data$mean_res_height_pop, method="spearman")$p.value,
           method_input_code = method_input_code_i,
           method_input_name = unique(sub_data$method_input_name),
           input_name = unique(sub_data$input_name),
           input_code = unique(sub_data$input_code),
           method = unique(sub_data$method),
           cg = site_i)
    }) %>% bind_rows()   
  }) %>% bind_rows()

saveRDS(corrtab, here("outputs/ValidationCommonGarden/HeightModels/corrtab_M2.rds"))
```


```{r PlotCorrelationsHeightModelWithoutPredictorWithPredictions, eval=T}
corrtab <- readRDS(here("outputs/ValidationCommonGarden/HeightModels/corrtab_M2.rds"))

correlation_types <- c("pearson_correlation", "spearman_correlation")

lapply(correlation_types, function(coeff){
  
  p <- corrtab %>%
    pivot_longer(values_to = "correlation_estimate", names_to = "correlation_type", cols = all_of(correlation_types)) %>% 
    mutate(correlation_pvalue = ifelse(correlation_type == "pearson_correlation", pearson_pvalue, spearman_pvalue)) %>% 
    dplyr::select(-pearson_pvalue,-spearman_pvalue) %>% 
    mutate(pvalue_signi = ifelse(correlation_pvalue < 0.05, "p-value < 0.05", "p-value ≥ 0.05")) %>% 
    filter(correlation_type == coeff) %>% 
    mutate(cg_name = case_when(cg == "asturias" ~ "Asturias, Spain (37 months)",
                               cg == "bordeaux" ~ "Bordeaux, France (85 months)",
                               cg == "caceres" ~ "Cáceres, Spain (8 months)",
                               cg == "madrid" ~ "Madrid, Spain (13 months)",
                               cg == "portugal" ~ "Fundão, Portugal (27 months)")) %>% 
    mutate(input_name = factor(input_name, levels = c(unique(corrtab$input_name)[[13]],
                                                      unique(corrtab$input_name)[[11]],
                                                      unique(corrtab$input_name)[[12]],
                                                      unique(corrtab$input_name)[[10]],
                                                      unique(corrtab$input_name)[[8]],
                                                      unique(corrtab$input_name)[[9]],
                                                      unique(corrtab$input_name)[[1]],
                                                      unique(corrtab$input_name)[[2]],
                                                      unique(corrtab$input_name)[[3]],
                                                      unique(corrtab$input_name)[[4]],
                                                      unique(corrtab$input_name)[[5]],
                                                      unique(corrtab$input_name)[[6]],
                                                      unique(corrtab$input_name)[[7]])),
           method = factor(method, levels = c(unique(corrtab$method)[[2]],
                                              unique(corrtab$method)[[3]],
                                              unique(corrtab$method)[[4]],
                                              unique(corrtab$method)[[5]],
                                              unique(corrtab$method)[[6]],
                                              unique(corrtab$method)[[1]])),
           cg_name = factor(cg_name, levels = c("Madrid, Spain (13 months)",
                                                "Cáceres, Spain (8 months)",
                                                "Asturias, Spain (37 months)",
                                                "Bordeaux, France (85 months)",
                                                "Fundão, Portugal (27 months)")))

# Plots with CTD and SNP sets
# ===========================
p_allvar <- p %>% ggplot(aes(x = method,
                             y = correlation_estimate,
                             color = input_name,
                             shape = pvalue_signi)) +
  geom_rect(inherit.aes=FALSE, aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=0), color="transparent", fill="green", alpha=0.005) + 
  geom_hline(yintercept = 0,color="gray") +
  geom_point(position = position_dodge(width = .5), size=5) +
  facet_wrap(~cg_name, ncol=2) + 
  {if(coeff=="pearson_correlation") ylab("Pearson correlation estimates")} + 
  {if(coeff=="spearman_correlation") ylab("Spearman correlation estimates (rank correlation)") } + 
  xlab("") +
  #ylim(c(-0.44,0.55)) +
  scale_color_manual(values=colors_coeff)+
  scale_shape_manual(values = c(16,18)) + #, name="p-value of the correlations"
  theme_bw() +
  labs(color="",shape="") +
  theme(axis.text.x =  element_text(size=13),
        axis.text.y = element_text(size=13),
        axis.title.y = element_text(size=16),
        legend.title = element_blank(), 
        strip.text.x = element_text(size = 16),
        strip.background = element_blank(),
        legend.position = c(0.77,0.15),
        legend.text=element_text(size=13),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  guides(color = guide_legend(ncol=1),
         shape = guide_legend(override.aes = list(size =2 )))
p_allvar
# save in pdf and png
ggsave(p_allvar,
       file=here(paste0("figs/ValidationCommonGarden/HeightModels/Correlations/",coeff,"_SNPsandCTD.pdf")),
       device="pdf",
       height=13.6,
       width=15)

ggsave(p_allvar,
       file=here(paste0("figs/ValidationCommonGarden/HeightModels/Correlations/",coeff,"_SNPsandCTD.png")),
       height=13.6,
       width=15)



# Adding some images to represent the climatic differences among common gardens
annotation_custom2 <- function (grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, data){ layer(data = data, stat = StatIdentity, position = PositionIdentity, 
        geom = ggplot2:::GeomCustomAnn,
        inherit.aes = TRUE, params = list(grob = grob, 
                                          xmin = xmin, xmax = xmax, 
                                          ymin = ymin, ymax = ymax))}

df_png <- p %>% 
  dplyr::select(cg_name) %>%
  distinct %>% 
  dplyr::mutate(image = case_when(cg_name == "Asturias, Spain (37 months)" ~ "reports/cloud.png",
                                  cg_name == "Bordeaux, France (85 months)" ~ "reports/cloud.png",
                                  cg_name == "Cáceres, Spain (8 months)" ~ "reports/sun.png",
                                  cg_name == "Madrid, Spain (13 months)" ~ "reports/sun.png",
                                  cg_name == "Fundão, Portugal (27 months)" ~ 'reports/cloud_and_sun.png'))

list_pngs <- lapply(unique(p$cg_name), function(cg_name_i){
  
sub <-  p %>% 
  filter(cg_name==cg_name_i) %>%
  slice(1)

png_cg = annotation_custom2(rasterGrob(readPNG(here(df_png[df_png$cg_name==cg_name_i,"image"])),interpolate=TRUE), 
                            ymin = -0.65,
                            ymax= -0.45,
                            xmin = 0.5,
                            xmax = 1.1, 
                            data=sub)
})

p_allvar_images <- p_allvar + list_pngs[[1]]+ list_pngs[[2]]+ list_pngs[[3]]+ list_pngs[[4]]+ list_pngs[[5]]

p_allvar_images

# save in pdf and png
ggsave(p_allvar_images,
       file=here(paste0("figs/ValidationCommonGarden/HeightModels/Correlations/",coeff,"_SNPsandCTD_WithImages.pdf")),
       device="pdf",
       height=13.6,
       width=15)

})
```

## Model 3

### Model equation and code 

Model 3 = Model 2 + Initial height as a confounder + Clone fixed intercepts

\begin{align*}
Y_{ipb}  &\sim \mathcal{N}(\mu_{pb},\sigma^{2}) \\
\mu_{pb} &= \beta_0 + B_b + \beta_{X1}X_p + \beta_{X2}X^2_p + \beta_H H_p\\
\beta_0 &\sim \mathcal{N}(\text{mean}(Y),2) \\ 
\sigma &\sim \text{Exp}(1) \\
\begin{bmatrix} B_b \\ C_c \\ \beta_{X1} \\ \beta_{X2} \\ \beta_H \end{bmatrix} &\sim \mathcal{N}(0,1) \\
\end{align*}

  - $Y_{ipb}$ is the height of the individual $i$ in the population $p$ and block $b$.
  - $\sigma^{2}$ is the residual variance of the model.
  - $B_b$ are the block intercepts. 
  - $X_p$ is the GO or CTD of the population $p$, with $\beta_{X1}$ and $\beta_{X2}$ being its linear and quadratic coefficients, respectively. The quadratic term was included to allow for potential nonlinearity in the response, following @fitzpatrick2021experimental.
  - $H_p$ is a proxy of the initial height of the trees from population $p$, i.e. when trees were planted. For that, we used the population varying intercepts calculated across all common gardens in the model 1 of @archambeau2022combining.
  - $\beta_0$ is the model global intercept.
  - $C_c$ are the clone intercepts. 

```{r CompileHeightModel3, message=F,warning=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_HeightModel_M3.stan"))
print(stancode)

params_to_estimate <- c("beta_X1","beta_X2","beta_H","R_squared","sigma")
```


### Run the models


```{r RunHeightModelM3, eval=F}
lapply(unique(height_data$cg), function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
  
    # Subset the data
    df_sub <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
    
    sub_data <- height_data %>% 
      filter(cg == site_i) %>% 
      left_join(df_sub, by = c("cg","pop")) %>% 
      left_join(pop_heights %>% dplyr::select(any_of(c("height", "pop"))) %>% dplyr::rename(init_height=height), by="pop")
      
    # Data in a list for Stan
    stanlist <- list(N = nrow(sub_data),
                     Y=(sub_data$height-mean(sub_data$height))/sd(sub_data$height),
                     X=(sub_data$varX -mean(sub_data$varX))/sd(sub_data$varX),
                     H=(sub_data$init_height -mean(sub_data$init_height))/sd(sub_data$init_height),
                     nb_bloc = length(unique(sub_data$block)),
                     nb_clon = length(unique(sub_data$clon)),
                     bloc = as.numeric(as.factor(sub_data$block)),
                     clon = as.numeric(as.factor(sub_data$clon)))

    # Run the models
    mod <- sampling(stancode, 
                    data = stanlist, 
                    iter = 2000, 
                    warmup = 1400, 
                    chains = 4, 
                    cores = 4, 
                    save_warmup = FALSE,
                    pars = params_to_estimate) 
    
    # Save the model and the stanlist
    list(mod = mod, 
         stanlist = stanlist) %>% 
      saveRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M3/",site_i,"_",method_input_code_i,".rds")))
    
    
  })
})
```

Warning message: "Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess"

```{r BuildCoeffTableM3, eval=T}
coefftab <- lapply(unique(height_data$cg),function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
    
    # Subset the data - keeping only one set of method / SNP set
    sub_data <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
  
    mod <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M3/",
                                    site_i,"_",method_input_code_i,".rds")))[["mod"]]
                     
    # Save coefficients
    broom.mixed::tidyMCMC(mod,
                          droppars = NULL, 
                          robust = FALSE, # give mean and standard deviation
                          ess = F, 
                          rhat = F, 
                          conf.int = T,
                          conf.level = 0.95) %>% 
      #filter(str_detect(term, c('beta'))) %>% 
      dplyr::rename(mean=estimate,
                    std_deviation=std.error,
                    conf_low=conf.low,
                    conf_high=conf.high) %>% 
      mutate(cg = site_i,
             method_input_code = method_input_code_i,
             method_input_name = unique(sub_data$method_input_name),
             method = unique(sub_data$method),
             input_name = unique(sub_data$input_name),
             input_code = unique(sub_data$input_code),
             .before=1)     

}) %>% bind_rows()
 
}) %>% bind_rows()
  
coefftab %>% 
  saveRDS(file=here("outputs/ValidationCommonGarden/HeightModels/coefftab_M3.rds"))
```

### Model coefficients

We plot the mean and 95% credible intervals of the $\beta_{X_1}$, $\beta_{X_2}$ and $\beta_H$ coefficients. Graph titles include the time in months corresponding to the age at which height and survival were recorded. Coefficients in the green area have the expected sign, reflecting lower height in populations with higher GO predictions.

```{r IntervalPlotsM3, fig.width=15, fig.height=13.6, eval=T}
generate_interval_plots(model_i = "M3")
```

### Predicted quadratic relationships

We plot the predicted quadratic relationships between tree height and GO predictions / CTD.

```{r PolyPlotsM3, fig.width=12, fig.height=7, eval=T}
generate_poly_plots(model_i = "M3")
```


## Model 4

### Model equation and code 

Model 4 = Model 2 + Initial height as a confounder + Clone varying intercepts

\begin{align*}
Y_{ipb}  &\sim \mathcal{N}(\mu_{pb},\sigma^2) \\
\mu_{pb} &= \beta_0 + B_b + \beta_{X1}X_p + \beta_{X2}X^2_p + \beta_H H_p\\
\beta_0 &\sim \mathcal{N}(\text{mean}(Y),2) \\ 
C_c &\sim \mathcal{N}(0,\sigma_C^2) \\ 
\begin{bmatrix} \sigma \\ \sigma_C \end{bmatrix} &\sim \text{Exp}(1) \\
\begin{bmatrix} B_b \\ \beta_{X1} \\ \beta_{X2} \\ \beta_H \end{bmatrix} &\sim \mathcal{N}(0,1) \\
\end{align*}

  - $Y_{ipb}$ is the height of the individual $i$ in the population $p$ and block $b$.
  - $\sigma^{2}$ is the residual variance of the model.
  - $B_b$ are the block intercepts. 
  - $X_p$ is the GO or CTD of the population $p$, with $\beta_{X1}$ and $\beta_{X2}$ being its linear and quadratic coefficients, respectively. The quadratic term was included to allow for potential nonlinearity in the response, following @fitzpatrick2021experimental.
  - $H_p$ is a proxy of the initial height of the trees from population $p$, i.e. when trees were planted. For that, we used the population varying intercepts calculated across all common gardens in the model 1 of @archambeau2022combining.
  - $\beta_0$ is the model global intercept.
  - $C_c$ are the clone varying intercepts which follow a normal distribution of variance $\sigma_C^2$.

```{r CompileHeightModel4, message=F,warning=F}
stancode = stan_model(here("scripts/StanModels/ValidationCommonGarden_HeightModel_M4.stan"))
print(stancode)

params_to_estimate <- c("beta_X1","beta_X2","beta_H","R_squared","sigma")
```

```{r RunHeightModelM4, eval=F}
lapply(unique(height_data$cg), function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
  
    # Subset the data
    df_sub <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
    
    sub_data <- height_data %>% 
      filter(cg == site_i) %>% 
      left_join(df_sub, by = c("cg","pop")) %>% 
      left_join(pop_heights %>% dplyr::select(any_of(c("height", "pop"))) %>% dplyr::rename(init_height=height), by="pop")
      
    # Data in a list for Stan
    stanlist <- list(N = nrow(sub_data),
                     Y=(sub_data$height-mean(sub_data$height))/sd(sub_data$height),
                     X=(sub_data$varX -mean(sub_data$varX))/sd(sub_data$varX),
                     H=(sub_data$init_height -mean(sub_data$init_height))/sd(sub_data$init_height),
                     nb_bloc = length(unique(sub_data$block)),
                     nb_clon = length(unique(sub_data$clon)),
                     bloc = as.numeric(as.factor(sub_data$block)),
                     clon = as.numeric(as.factor(sub_data$clon)))

    # Run the models
    mod <- sampling(stancode, 
                    data = stanlist, 
                    iter = 2000, 
                    warmup = 1400, 
                    chains = 4, 
                    cores = 4, 
                    save_warmup = FALSE,
                    pars = params_to_estimate) 
    
    # Save the model and the stanlist
    list(mod = mod, 
         stanlist = stanlist) %>% 
      saveRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M4/",site_i,"_",method_input_code_i,".rds")))
    
    
  })
})
```

Warning message: "Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess"

```{r BuildCoeffTableM4, eval=T}
coefftab <- lapply(unique(height_data$cg),function(site_i){
  
  lapply(unique(df$method_input_code), function(method_input_code_i){
    
    # Subset the data - keeping only one set of method / SNP set
    sub_data <- df %>% filter(method_input_code == method_input_code_i & cg == site_i)
  
    mod <- readRDS(file=here(paste0("outputs/ValidationCommonGarden/HeightModels/stan_models/M4/",
                                    site_i,"_",method_input_code_i,".rds")))[["mod"]]
                     
    # Save coefficients
    broom.mixed::tidyMCMC(mod,
                          droppars = NULL, 
                          robust = FALSE, # give mean and standard deviation
                          ess = F, 
                          rhat = F, 
                          conf.int = T,
                          conf.level = 0.95) %>% 
      dplyr::rename(mean=estimate,
                    std_deviation=std.error,
                    conf_low=conf.low,
                    conf_high=conf.high) %>% 
      mutate(cg = site_i,
             method_input_code = method_input_code_i,
             method_input_name = unique(sub_data$method_input_name),
             method = unique(sub_data$method),
             input_name = unique(sub_data$input_name),
             input_code = unique(sub_data$input_code),
             .before=1)     

}) %>% bind_rows()
 
}) %>% bind_rows()
  
coefftab %>% 
  saveRDS(file=here("outputs/ValidationCommonGarden/HeightModels/coefftab_M4.rds"))
```

### Model coefficients

We plot the mean and 95% credible intervals of the $\beta_{X_1}$, $\beta_{X_2}$ and $\beta_H$ coefficients. Graph titles include the time in months corresponding to the age at which height and survival were recorded. Coefficients in the green area have the expected sign, reflecting lower height in populations with higher GO predictions.

```{r IntervalPlotsM4, fig.width=15, fig.height=13.6, eval=T}
generate_interval_plots(model_i = "M4")
```

### Predicted quadratic relationships

We plot the predicted quadratic relationships between tree height and GO predictions / CTD.

```{r PolyPlotsM4, fig.width=12, fig.height=7, eval=T}
generate_poly_plots(model_i = "M4")
```

## Sample size for each clone

We look at the number of height measurements for each clone. In the tables below (one for each common garden), the first column correspond to the number of height measurements and the second column correspond to the number of clones with this number of measurements.

```{r SampleSizeForEachClone}
lapply(unique(height_data$cg), function(site_i){
  
  
height_data %>% 
    filter(cg==site_i) %>% 
    dplyr::select(pop,clon) %>% 
    drop_na() %>% 
    group_by(clon) %>% 
    dplyr::summarise(nb_measurements=n()) %>% 
    count(nb_measurements)
  
  
}) %>% set_names(unique(height_data$cg))
```

# DRYAD repository

<span style="color: orange;">**DRYAD REPOSITORY:** We export mortality and height data in the DRYAD repository: `CommonGardenData_cleaned.csv` dataset.</span>

```{r PhenoDataInDryadRepo}
pheno_data %>% 
  dplyr::rename(cg = site) %>% 
  dplyr::select(cg,block,pop,clon,tree,any_of(height_measurements),any_of(surv_measurements)) %>% 
  write_csv(here("data/DryadRepo/CommonGardenData_cleaned.csv"))
```


# Session information

```{r SessionInfo}
devtools::session_info()
```

