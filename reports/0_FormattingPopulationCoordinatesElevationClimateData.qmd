---
title: "Populatin coordinates, elevation and climatic data"
subtitle: "Checking population information - Extracting climatic data with ClimateDT"
author: "Juliette Archambeau"
date: "`r format(Sys.time(), '%d %B, %Y')`"
number-sections: true
format: 
  html:
    toc: true
    toc-depth: 4
    code-fold: true
    page-layout: full
embed-resources: true
bibliography: references.bib
editor_options: 
  chunk_output_type: console
---

<style type="text/css">
body {
   font-size: 15px;
}
code.r{
  font-size: 11px;
}
pre {
  font-size: 11px
}

table {
  font-size: 10px
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=F)
options(width = 300)
library(knitr)      # CRAN v1.26
library(kableExtra) # CRAN v1.1.0
library(tidyverse)  # CRAN v1.3.0
library(janitor)
library(purrr)
library(SPEI)
library(raster)
library(magrittr)
library(here)
library(adespatial) # to calculate the Moran eigen vectors

# my own function for building tables in reports
source(here("scripts/functions/kable_mydf.R"))
```

# Introduction

In this document, we first build a table with updated population coordinates and elevation. The information on maritime pine populations has been gathered by different teams across many years, so we had to merge the different sources of information. We first check that we have the most up to date population information.

We have some information on 116 populations that were sampled within different projects. The different sampling are referred as CLONAPIN, B4ESTnew, CORSICA, FORGENIUS and GENTREE. The populations we use in the present study are the populations sampled within the CLONAPIN sampling (except the SID population, and the ROD population for which there is no genomic information). The entire set of populations is analysed within the PhD project of Adélaïde Theraroz.

Then we use the population coordinates and elevation data to extract their climatic data using the [Climate Downscaling Tool (ClimateDT)](https://www.ibbr.cnr.it/climate-dt/) developed within the framework of the B4EST project. Annual climatic variables are extracted between 1901 and 2098. 


# Population coordinates and elevation

We load the dataset with the coordinates of the 116 populations that Adélaïde uses during its PhD.

```{r AllPopsCoordinates}
pop_coord <- read_csv(here("data/PopulationData/coordinates_pinaster_populations_ade_phd.csv"),show_col_types = FALSE) %>% 
  filter(if_any(everything(), ~ !is.na(.))) %>% # remove NAs rows at the end of the csv file
  dplyr::rename(code = CODE, 
                dataset = Data_set,
                latitude = Latitude, 
                longitude = Longitude) %>% 
  filter(!code == "VAL") %>% # we remove the VAL pop which is duplicated (other name code: VAL-CORSICA)
  mutate(dataset = ifelse(dataset == "B4EST new", "B4ESTnew", as.character(dataset)))

# to check that there are no other duplicated rows
# pop_coord %>% dplyr::select(latitude,longitude) %>% get_dupes()
```

<span style="color: red;">**Warning!**</span> There are two VAL populations in this dataset: VAL-VMQ and VAL-CORSICA. The VAL population that I used during my PhD is referred as VAL-VMQ (and belong to the CLONAPIN dataset). I will change its name.

```{r VALpop}
pop_coord %>% filter(str_detect(code,"VAL")) %>% kable_mydf()
```

We load the dataset with population information that I used during my PhD and we compare the population coordinates from the `coordinates_pinaster_populations_ade_phd.csv` file.

```{r MyClonapinCoordinates}
clonapin_pop_coord_juliette <- read_csv(here("data/PopulationData/coordinates_pinaster_populations_juliette_phd.csv"),
                                        show_col_types = FALSE) %>%
  filter(!is.na(CODE)) %>% # remove NAs rows at the end of the csv file 
  dplyr::select(CODE, LATITUDE, LONGITUDE, ALTITUDE) %>% 
  dplyr::rename(code = CODE, latitude_juliette = LATITUDE, longitude_juliette = LONGITUDE, altitude_juliette = ALTITUDE) %>% 
  mutate(code = ifelse(code == "VAL", "VAL-VMQ", as.character(code))) %>% # rename VAL pop
  mutate(altitude_juliette = ifelse(code == "CAS", 158, altitude_juliette)) %>% 
  left_join(pop_coord, by=c("code")) %>% 
  mutate(diff_longitude = longitude - longitude_juliette,
         diff_latitude = latitude - latitude_juliette)


clonapin_pop_coord_juliette %>% kable_mydf(boldfirstcolumn = T, round_number = 10)
```

The two files (`coordinates_pinaster_populations_juliette_phd.csv` and `coordinates_pinaster_populations_ade_phd.csv`) show small differences in the population coordinates. 

We merge the two datasets using:

  - the coordinates from the file `coordinates_pinaster_populations_juliette_phd.csv` for the CLONAPIN populations (i.e. the population coordinates I used during my PhD). 
  
  - the coordinates from the file `coordinates_pinaster_populations_ade_phd.csv` for the other populations.
  
  
<span style="color: red;">**Warning!**</span>  The SID population (from Sidi-Meskour) is referred as belonging to the CLONAPIN dataset in the file `coordinates_pinaster_populations_ade_phd.csv` but was not included in the populations I used during my PhD (populations in the file `coordinates_pinaster_populations_juliette_phd.csv`). So we attribute to this population the coordinates from the file `coordinates_pinaster_populations_ade_phd.csv`.



```{r MergingWithMyPopulationCoordinates}
pop_coord <- pop_coord %>% 
  left_join(clonapin_pop_coord_juliette %>% dplyr::select(code, contains("juliette")), by="code") %>% 
  mutate(latitude = ifelse(dataset == "CLONAPIN" & !is.na(latitude_juliette), latitude_juliette,latitude),
         longitude = ifelse(dataset == "CLONAPIN" & !is.na(longitude_juliette), longitude_juliette, longitude)) %>% 
  dplyr::select(-longitude_juliette, -latitude_juliette)
```

In this dataset, the coordinates of some populations were not ok (eg the coordinates of the RIO population fall into the Mediterranean sea). Santi sent a new dataset (`coordinates_pinaster_populations_21022023.txt`) with updated coordinates (21/02/2023) and with elevation information (with some missing data for some populations).


```{r NewAllPopsCoordinates}
new_pop_coord <-read.delim(here("data/PopulationData/coordinates_pinaster_populations_21022023.txt")) %>% 
  dplyr::rename(code = CODE, 
                dataset = Data_set,
                latitude_new = Latitude, 
                longitude_new = Longitude,
                altitude_new = Elevation,
                country= Country)


pop_coord <- pop_coord %>% 
  left_join(new_pop_coord, by = c("dataset", "code")) %>% 
  mutate(latitude_diff = latitude - latitude_new,
         longitude_diff = longitude - longitude_new,
         altitude_diff = altitude_juliette - altitude_new)
```

Which populations have new coordinates?

```{r PopWithDifferentCoordinates}
pop_coord %>% filter(latitude_diff != 0 | longitude_diff != 0) %>% 
  dplyr::select(-contains("altitude")) %>% 
  kable_mydf()
```

How many NAs in each column?

```{r ChekingsNbNAs}
pop_coord %>% 
  dplyr::summarise(across(everything(), ~ sum(is.na(.)))) %>% 
  pivot_longer(everything(), names_to = "Variable", values_to = "Number of NAs") %>% 
  kable_mydf() 
```

Looking at altitude differences for the CLONAPIN populations 

```{r AltitudeDifferences}
pop_coord %>% 
  dplyr::select(dataset,code,contains("altitude")) %>% 
  dplyr::filter(dataset=="CLONAPIN") %>% 
  kable_mydf()
```

We keep the new altitude information (those from the file `coordinates_pinaster_populations_21022023.txt`)

```{r KeepingNewAltitudes}
pop_coord <- pop_coord %>% 
  mutate(latitude = latitude_new,
         longitude = longitude_new,
         altitude = case_when(dataset != "CLONAPIN" ~ as.numeric(altitude_new),
                              dataset == "CLONAPIN" & is.na(altitude_new) ~ altitude_juliette, # for the ROD population
                              dataset == "CLONAPIN" & !is.na(altitude_new) ~ as.numeric(altitude_new))) %>% 
  dplyr::select(-contains("ude_"))
```

`r pop_coord %>% summarise(sum(is.na(altitude))) %>% pull()` have missing data for altitude.

```{r MissingDataForAltitude}
pop_coord %>%
  dplyr::filter(is.na(altitude)) %>% 
  kable_mydf()
```

We attribute to these populations the same elevation data as the one of the DEM used by ClimateDT (i.e. Google maps DEM).

```{r AttributeDEEMelevationDataToPopulationsWithMissingDataForAltitude}
pop_coord <- pop_coord %>% 
  mutate(altitude = case_when(code == "CAV" ~ 1259,
                              code == "FPN" ~ 792,
                              code == "TAB" ~ 76,
                              code == "TUS" ~ 84,
                              code == "VCA" ~ 396,
                              code == "ES_PP_58/MAE" ~ 1353,
                              code == "ES_PP_59" ~ 1007,
                              code == "ES_PP_60" ~ 1136,
                              code == "MAUbis/FR-PP-12" ~ 606,
                              TRUE ~ altitude))
```


We visualize and save the dataset. Sent to Santi and Adé the 22/02/2023. 

```{r VizAndSavingAllPopsInfo}
pop_coord %>% 
  dplyr::select(-POP) %>% 
  write_csv(here("data/PopulationData/population_information_pinaster_feb2023.csv"))


pop_coord %>% 
  dplyr::select(-POP) %>% 
  kable_mydf()
```


# Extracting climatic data

## Preparing a file for the extraction

We generate a `csv` file for the extraction with ClimateDT. The format of the input file has to be:

  - `1st Column` **ID** (alphanumeric) unique ID of the location (either a number or a code).

  - `2nd Column` **Latitude** (float) latitude of the location expressed in decimal degrees (dot as decimal separator).

  - `3rd Column` **Longitude** (float) longitude of the location expressed in decimal degrees (dot as decimal separator).

  - `4th Column` **Elevation** (integer) elevation of the location expressed in meters a.s.l.


```{r CsvFileForClimaticExtraction}
# csv file sent to Maurizio Marchi the 22/02/2023
# -----------------------------------------------
pop_coord %>% 
  dplyr::select(code,latitude,longitude,altitude) %>% # rm the column dataset
  write_csv(here("data/ClimaticData/MaritimePinePops/ClimateDTfiles/Preextraction/PopCoordinates_ClimateDT_PreExtractionTab.csv"))
```



## Generating datasets with climatic information

### Point estimates

We load the csv files sent by Maurizio Marchi with **point estimate** climatic values at the location of each population.

We generate some datasets with climatic information for the variables of interest and only for the CLONAPIN populations. We generate two .rds files: one for the climatic data adjusted for elevation, and one for the climatic data not adjusted for elevation. In each file, we store a list with each element corresponding to a reference period (i.e. 1901-1950 and 1961-1990). And for each reference period, we generate a dataset with the climatic variables in columns averaged over the period considered. **Important**: In this dataset, the indices such `bio1`, `bio2`, `AHM`, `SHM` etc are re-calculated using the annual `tmn`, `tmx` and `prc` values averaged over the period considered.

The climatic variables are calculated based on the `biovars` function of the dismo R package: <https://rdrr.io/cran/dismo/src/R/biovars.R>


#### Past climate 

```{r FunctionGeneratePastClimaticDatasets}
# Function from the dismo R package
window <- function(x)  { 
			lng <- length(x)
			x <- c(x,  x[1:3])
			m <- matrix(ncol=3, nrow=lng)
			for (i in 1:3) { m[,i] <- x[i:(lng+i-1)] }
			apply(m, MARGIN=1, FUN=sum)}


# Function to generate a list of two datasets of past climates.
# Each element of the list corresponds to a reference period

generate_past_climate_df <- function(ref_period,clim_df){
  
# ====================================================================================================
# Generating a dataset with the climatic variables calculated across the reference period of interest
# ====================================================================================================
  
# Selecting the years of interest
clim_past <- clim_df %>% 
  dplyr::filter(!Year %in% c("2041-2070","baseline")) %>% # we remove future climatic data (which are not noted as a unique year)
  dplyr::mutate(Year=as.numeric(Year)) %>% # year column as numeric so that we can remove years after a given date
  dplyr::filter(ref_period$range[[1]]<=Year& Year<=ref_period$range[[2]]) %>%  # we keep the years of the period of interest
  dplyr::select(-Year)

# Calculating the mean of tmn, tmx and prc over the period considered
tab <- clim_past %>% 
  group_by(pop) %>% 
  summarise_at(vars(contains("tmn"),contains("tmx"),contains("prc")),"mean")

tavg <- (tab %>% dplyr::select(contains("tmn")) + tab %>% dplyr::select(contains("tmx")))  / 2
tmx <- tab %>% dplyr::select(contains("tmx"))
tmn <- tab %>% dplyr::select(contains("tmn"))
prc <- tab %>% dplyr::select(contains("prc"))
wet <- t(apply(prc, 1, window))
tmp <- t(apply(tavg, 1, window)) / 3


tab$bio1 <- apply(tavg ,MARGIN=1, FUN=mean)
tab$bio2 <- apply(tmx-tmn , MARGIN=1, FUN=mean)
tab$bio4 <- 100 * apply(tavg, 1, sd)
tab$bio5 <- apply(tmx, 1, max)
tab$bio6 <- apply(tmn, 1, min)
tab$bio7 <- tab$bio5 - tab$bio6
tab$bio3 <- 100 * tab$bio2 / tab$bio7
tab$bio12 <- apply(prc, MARGIN=1, FUN= sum)
tab$bio13 <- apply(prc,1,max)
tab$bio14 <- apply(prc,1,min)
tab$bio15 <- apply(prc+1, 1, raster::cv) # the "1 +" is to avoid strange CVs for areas where mean rainfaill is < 1)
tab$bio16 <- apply(wet,1,max)
tab$bio17 <- apply(wet,1,min)


if (all(is.na(wet))) {
			tab$bio8 <- NA		
			tab$bio9 <- NA		
		} else {
			wetqrt <- cbind(1:nrow(wet), as.integer(apply(wet, 1, which.max)))
			tab$bio8 <- tmp[wetqrt]

			dryqrt <- cbind(1:nrow(wet), as.integer(apply(wet, 1, which.min)))
			tab$bio9 <- tmp[dryqrt]
		}



tab$bio10 <- apply(tmp, 1, max)
tab$bio11 <- apply(tmp, 1, min) 

if (all(is.na(tmp))) {
			tab$bio18 <- NA		
			tab$bio19 <- NA
		} else {
			hot <- cbind(1:nrow(tmp), as.integer(apply(tmp, 1, which.max)))
			tab$bio18 <- wet[hot]

			cold <- cbind(1:nrow(tmp), as.integer(apply(tmp, 1, which.min)))
			tab$bio19 <- wet[cold]
		}

tab$AHM <- (tab$bio1+10)/(tab$bio12*1e-3)
tab$MWMT <- apply(tavg,MARGIN=1, FUN=max)
tab$SP <- apply(tab %>% dplyr::select(prc05,prc06,prc07,prc08,prc09),MARGIN=1,FUN=sum)
tab$SHM <- (tab$MWMT)/((tab$SP+0.1)*1e-3)


tab <- clim_past %>%
  dplyr::select(pop,contains("ude"),elevation) %>% 
  distinct() %>% 
  right_join(tab,by="pop") %>% # adding the latitude and longitude of the populations
  bind_cols(dbmem(.[,c("latitude","longitude")]))  # we add the distance-based Moran’s Eigenvector Maps (dbMEMs)

  
tab$Eref <- lapply(c("tmn","tmx","prc"), function(x) {
  
tab %>% 
  dplyr::select(pop,contains(x)) %>% 
  pivot_longer(cols=contains(x),names_to="variable",values_to = "mean_ref") %>% 
  mutate(month=str_sub(variable,4,-1),
         variable=str_sub(variable,1,3)) 

}) %>% 
  bind_rows() %>% 
  pivot_wider(names_from="variable", values_from=mean_ref) %>% 
  left_join(tab[,c("pop","latitude")],by="pop") %>% 
  group_by(pop) %>% 
  group_split() %>% 
  purrr::map(\(x){ 
    
hargreaves(Tmin = x$tmn, Tmax = x$tmx, lat = unique(x$latitude), Pre=x$prc, verbose=F) %>% sum() 
    
    }) %>% unlist()
  

ref_period$ref_means <- tab


################################################################################################

# =======================================================================================================================
# Generating a dataset with the climatic variables means and standard deviations across the reference period of interest
# =======================================================================================================================


# I wrote the code below to calculate the mean and standard deviations of the climatic variables
# over the period of interest. 
# For that, I first calculated the annual values of the climatic variables based on tmn, tmx and prc
# I then calculated the mean and sd over the period considered for each population.
# But, this way of calculating the climatic variables gives different values than the way I used above 
# ie first calculating the mean of tmn, tmx and prc over the period considered and then calculating the
# climatic variables

# tab_wide <- clim_past %>% 
#   group_by(pop) %>% 
#   group_split() %>% 
#   purrr::map(\(x){
# 
# 
# tavg <- (x %>% dplyr::select(contains("tmn")) + x %>% dplyr::select(contains("tmx")))/2
# tmx <- x %>% dplyr::select(contains("tmx"))
# tmn <- x %>% dplyr::select(contains("tmn"))
# prc <- x %>% dplyr::select(contains("prc"))
# wet <- t(apply(prc, 1, window))
# tmp <- t(apply(tavg, 1, window)) / 3
# 
# vars <- list()
# 
# vars$bio1 <- apply(tavg,1,mean)
# vars$bio2 <- apply(tmx-tmn , MARGIN=1, FUN=mean)
# vars$bio4 <- 100 * apply(tavg, 1, sd)
# vars$bio5 <- apply(tmx, 1, max)
# vars$bio6 <- apply(tmn, 1, min)
# vars$bio7 <- vars$bio5 - vars$bio6
# vars$bio3 <- 100 * vars$bio2 / vars$bio7
# vars$bio12 <- apply(prc, MARGIN=1, FUN= sum)
# vars$bio13 <- apply(prc,1,max)
# vars$bio14 <- apply(prc,1,min)
# vars$bio15 <- apply(prc+1, 1, raster::cv) # the "1 +" is to avoid strange CVs for areas where mean rainfaill is < 1)
# vars$bio16 <- apply(wet,1,max)
# vars$bio17 <- apply(wet,1,min)
# 
# 
# 		
# if (all(is.na(wet))) {
# 			vars$bio8 <- NA		
# 			vars$bio9 <- NA		
# 		} else {
# 			wetqrt <- cbind(1:nrow(wet), as.integer(apply(wet, 1, which.max)))
# 			vars$bio8 <- tmp[wetqrt]
# 
# 			dryqrt <- cbind(1:nrow(wet), as.integer(apply(wet, 1, which.min)))
# 			vars$bio9 <- tmp[dryqrt]
# 		}
# 
# 
# 
# vars$bio10 <- apply(tmp, 1, max)
# vars$bio11 <- apply(tmp, 1, min) 
# 
# if (all(is.na(tmp))) {
# 			vars$bio18 <- NA		
# 			vars$bio19 <- NA
# 		} else {
# 			hot <- cbind(1:nrow(tmp), as.integer(apply(tmp, 1, which.max)))
# 			vars$bio18 <- wet[hot]
# 
# 			cold <- cbind(1:nrow(tmp), as.integer(apply(tmp, 1, which.min)))
# 			vars$bio19 <- wet[cold]
# 		}
# 
# vars$AHM <- (vars$bio1+10)/(vars$bio12*1e-3)
# vars$MWMT <- apply(tavg,MARGIN=1, FUN=max)
# vars$SP <- apply(x %>% dplyr::select(prc05,prc06,prc07,prc08,prc09),MARGIN=1,FUN=sum)
# vars$SHM <- (vars$MWMT)/((vars$SP+0.1)*1e-3)
# 
# 
# 
#   
# vars$Eref <-  lapply(c("tmn","tmx","prc"), function(y) {
#   
# x %>% 
#   dplyr::select(pop,contains(y),latitude) %>% 
#   mutate(year=ref_period$range[[1]]:ref_period$range[[2]]) %>% 
#   pivot_longer(cols=contains(y),names_to="variable",values_to = "mean_ref") %>% 
#   mutate(month=str_sub(variable,4,-1),
#          variable=str_sub(variable,1,3)) 
# 
# }) %>% 
#   bind_rows() %>% 
#   group_by(year) %>% 
#   group_split() %>% 
#   purrr::map(\(y){ 
#     
# df <- y %>% pivot_wider(names_from="variable", values_from=mean_ref)
# hargreaves(Tmin = df$tmn, Tmax = df$tmx, lat = unique(df$latitude), Pre=df$prc, verbose=F) %>% sum()
# 
#     }) %>% unlist()
# 
# 
# tab <- tibble(variable = names(vars),
#               mean_ref = lapply(vars, function(x) mean(x)) %>% unlist(),
#               sd_ref = lapply(vars, function(x) sd(x)) %>%  unlist())
# 
# 
# })  %>% 
#     set_names(unique(clim_past$pop)) %>% 
#     list_rbind(names_to="pop") 
#   
# 
# ref_period$ref_sdmeans <- tab_wide

########
#
# TO check whether the two datasets gives similar values:
#
# lapply(unique(tab_wide$variable),function(x){
#   all.equal(tab[,x] %>% pull() %>% as.numeric(),tab_wide[tab_wide$variable==x,"mean_ref"] %>% pull() %>% as.numeric())}) %>%
#   setNames(unique(tab_wide$variable))
# 
########


return(ref_period)


}
```



```{r BuildingClimaticDatasetClonapinPopForPresentStudy, results="hide"}
# extracting CLONAPIN population names
clonapin_name_pops <- pop_coord %>% 
  dplyr::filter(dataset=="CLONAPIN") %>% 
  dplyr::filter(!code %in% c("ROD","SID")) %>% # no genomic data for these two populations
  pull(code)


# Specify the reference periods for whichc are will calculate the mean climates
list_ref_periods <- list(ref_1901_1950 = list(range=c(1901,1950)),
                         ref_1961_1990 = list(range=c(1961,1990)))
  

# we generate two files with climatic data adjusted (or not) for elevation
lapply(list("ADJ","noADJ"), function(adj){

  
# A first filtering: keeping only CLONAPIN populations, removing monthly climatic variables
  
clim <- read_csv(here(paste0("data/ClimaticData/MaritimePinePops/ClimateDTfiles/Extraction/ClimateDT_cmip6_GFDL-ESM4_POPcoordinates_",adj,".csv")), show_col_types = FALSE) %>% 
  dplyr::rename(longitude=Longitude,
                latitude=Latitude,
                elevation=Elevation,
                pop=ID,
                SP=MSP) %>% # replace mean summer precipitation by summer precipitation
  dplyr::filter(pop %in% clonapin_name_pops) %>% # we keep only CLONAPIN pops
  dplyr::mutate(pop= ifelse(pop=="VAL-VMQ", "VAL",pop)) # the VAL-VMQ population is referred as VAL in the present study


# we create a list with each element corresponding to a reference period
lapply(list_ref_periods, function(ref_period) generate_past_climate_df(ref_period = ref_period, clim_df = clim)) %>% 
saveRDS(here(paste0("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationPointEstimates_ReferencePeriods_",adj,".rds")))
  
})
```


#### Future climates 

> for the period 2041-2070 with the GCM CMIP6 GFDL-ESM4 and scenario  SSP3.7-0

```{r PredictionsFutureClimates}
# Predictions of future climates for the period 2041-2070 with the GCM CMIP6 GFDL-ESM4 and scenario  SSP3.7-0
# -----------------------------------------------------------------------------------------------------------

lapply(list("ADJ","noADJ"), function(adj){
  
tab <-   read_csv(here(paste0("data/ClimaticData/MaritimePinePops/ClimateDTfiles/Extraction/ClimateDT_cmip6_GFDL-ESM4_POPcoordinates_",adj,".csv")), 
           show_col_types = FALSE) %>% 
  dplyr::rename(longitude=Longitude,
                latitude=Latitude,
                elevation=Elevation,
                pop=ID,
                SP=MSP) %>% # replace mean summer precipitation by summer precipitation
  dplyr::filter(pop %in% clonapin_name_pops) %>% # we keep only CLONAPIN pops
  dplyr::mutate(pop= ifelse(pop=="VAL-VMQ", "VAL",pop)) %>% # the VAL-VMQ population is referred as VAL in the present study
  dplyr::filter(Year=="2041-2070") %>% 
  dplyr::select(pop,elevation,contains("ude"),contains("prc"), contains("tmx"), contains("tmn"))
  

tavg <- (tab %>% dplyr::select(contains("tmn")) + tab %>% dplyr::select(contains("tmx")))  / 2
tmx <- tab %>% dplyr::select(contains("tmx"))
tmn <- tab %>% dplyr::select(contains("tmn"))
prc <- tab %>% dplyr::select(contains("prc"))
wet <- t(apply(prc, 1, window))
tmp <- t(apply(tavg, 1, window)) / 3



tab$bio1 <- apply(tavg ,MARGIN=1, FUN=mean)
tab$bio2 <- apply(tmx-tmn , MARGIN=1, FUN=mean)
tab$bio4 <- 100 * apply(tavg, 1, sd)
tab$bio5 <- apply(tmx, 1, max)
tab$bio6 <- apply(tmn, 1, min)
tab$bio7 <- tab$bio5 - tab$bio6
tab$bio3 <- 100 * tab$bio2 / tab$bio7
tab$bio12 <- apply(prc, MARGIN=1, FUN= sum)
tab$bio13 <- apply(prc,1,max)
tab$bio14 <- apply(prc,1,min)
tab$bio15 <- apply(prc+1, 1, raster::cv) # the "1 +" is to avoid strange CVs for areas where mean rainfaill is < 1)
tab$bio16 <- apply(wet,1,max)
tab$bio17 <- apply(wet,1,min)



		
if (all(is.na(wet))) {
			tab$bio8 <- NA		
			tab$bio9 <- NA		
		} else {
			wetqrt <- cbind(1:nrow(wet), as.integer(apply(wet, 1, which.max)))
			tab$bio8 <- tmp[wetqrt]

			dryqrt <- cbind(1:nrow(wet), as.integer(apply(wet, 1, which.min)))
			tab$bio9 <- tmp[dryqrt]
		}



tab$bio10 <- apply(tmp, 1, max)
tab$bio11 <- apply(tmp, 1, min) 

if (all(is.na(tmp))) {
			tab$bio18 <- NA		
			tab$bio19 <- NA
		} else {
			hot <- cbind(1:nrow(tmp), as.integer(apply(tmp, 1, which.max)))
			tab$bio18 <- wet[hot]

			cold <- cbind(1:nrow(tmp), as.integer(apply(tmp, 1, which.min)))
			tab$bio19 <- wet[cold]
		}

tab$AHM <- (tab$bio1+10)/(tab$bio12*1e-3)
tab$MWMT <- apply(tavg,MARGIN=1, FUN=max)
tab$SP <- apply(tab %>% dplyr::select(prc05,prc06,prc07,prc08,prc09),MARGIN=1,FUN=sum)
tab$SHM <- (tab$MWMT)/((tab$SP+0.1)*1e-3)


tab <- tab %>% bind_cols(dbmem(.[,c("latitude","longitude")]))  # we add the distance-based Moran’s Eigenvector Maps (dbMEMs)

  
tab$Eref <- lapply(c("tmn","tmx","prc"), function(x) {
  
tab %>% 
  dplyr::select(pop,contains(x)) %>% 
  pivot_longer(cols=contains(x),names_to="variable",values_to = "mean_ref") %>% 
  mutate(month=str_sub(variable,4,-1),
         variable=str_sub(variable,1,3)) 

}) %>% 
  bind_rows() %>% 
  pivot_wider(names_from="variable", values_from=mean_ref) %>% 
  left_join(tab[,c("pop","latitude")],by="pop") %>% 
  group_by(pop) %>% 
  group_split() %>% 
  purrr::map(\(x){ 
    
hargreaves(Tmin = x$tmn, Tmax = x$tmx, lat = unique(x$latitude), Pre=x$prc, verbose=F) %>% sum() #mean()
    
    }) %>% unlist()
  

return(tab)

}) %>% 
  setNames(c("ADJ","noADJ")) %>% 
  saveRDS(here::here("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationsPointEstimates_GFDL-ESM4_SSP370_2041-2070.rds"))
```


### Raster-extracted values



```{r GenerateDatasetExtractedFutureClimaticValuesFromRasters}
# function to extract the climatic values from rasters
source(here("scripts/functions/extract_clim_from_rasters.R"))

# GCM names
gcm_names <- list.files(here("data/ClimaticData/ClimateDTRasters/")) %>%  str_sub(5,-35) %>% setdiff("")

# Climatic variables
clim_var <- readRDS(here("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationPointEstimates_ReferencePeriods_ADJ.rds"))[[1]]$ref_means %>% 
  dplyr::select(-pop,-elevation,-contains("ude"),-contains("tmn"),-contains("tmx"),-contains("prc"),-contains("MEM")) %>% 
  colnames()

# Population coordinates
pop_coord <- readRDS(here("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationPointEstimates_ReferencePeriods_ADJ.rds"))[[1]]$ref_means %>% 
  dplyr::select(longitude,latitude) %>% 
  SpatialPoints(proj4string=CRS("+proj=longlat +datum=WGS84 +no_defs"))

# Population names
pop_names <- readRDS(here("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationPointEstimates_ReferencePeriods_ADJ.rds"))[[1]]$ref_means %>% 
  pull(pop)


# List of dataframes (one for each GCM) with the climatic variables in columns
clim_df <- lapply(gcm_names, function(gcm){
  
lapply(clim_var, function(x) extract_clim_from_rasters(x=x, gcm=gcm, period="2041-2070", ssp="ssp370",pop_coord=pop_coord)) %>% 
  setNames(clim_var) %>% 
  as_tibble() %>% 
  mutate(pop=pop_names,
         gcm=gcm)

}) %>% setNames(gcm_names) 

clim_df %>% saveRDS(here("data/ClimaticData/MaritimePinePops/ClimatePopulationLocationValuesExtractedFromRasters_FiveGCMs_2041-2070_SSP370.rds"))

# Another option: one dataframe with the four columns: 
  # variable = climatic variable#
  # pop = population
  # gcm = Global Clinatic Model (GCM)
  # mean_fut = value of the climatic variable
# clim_df <- lapply(clim_var, function(x){
#   
# lapply(gcm_names, function(gcm) extract_clim_from_rasters(x=x, gcm=gcm, period="2041-2070", ssp="ssp370",pop_coord=pop_coord)) %>% 
#   setNames(gcm_names) %>% 
#   as_tibble() %>% 
#   mutate(pop=pop_names)
# 
# }) %>% 
#   setNames(clim_var) %>% 
#   bind_rows(.id = "variable") %>% 
#   pivot_longer(names_to = "gcm",values_to="mean_fut",cols=all_of(gcm_names)) 

```

# Main gene pool of each population

```{r MainGPpop}
# Incorporating gene pool information
# -----------------------------------

genotypes <- read_csv(here("data/DryadRepo/FormattedFilteredGenomicData_AlleleCounts_withmaf.csv"),show_col_types = FALSE) %>% 
  dplyr::select(-snp_ID) %>% 
  colnames() 
  
# we load the gene pool information with the ancestry coefficients for each clone
gps <- read_csv(here("data/DryadRepo/PopulationStructureCorrea2015.csv"), show_col_types = FALSE) %>% 
  dplyr::filter(clon %in% genotypes) %>% 
  dplyr::rename(main_gp_clon_code=max.Q,
                main_gp_clon=main_gp,
                color_main_gp_clon=color_main_gp)

# we extract the main gene pool of each population
# LEI and QUA populations have somes clones that belong to different gene pools, we have to account for that
gp_poplevel <- gps %>% 
  group_by(pop) %>% 
  group_split() %>% 
  modify(\(x) mutate(x, main_gp_pop= x$main_gp_clon  %>% table() %>% which.max() %>% names())) %>% 
  list_rbind() %>% 
  dplyr::select(pop, main_gp_pop) %>% 
  distinct()
  
# Information of the main gene pool for each pop
gp_poplevel <- gps %>% 
  dplyr::select(main_gp_clon,color_main_gp_clon) %>% 
  distinct() %>% 
  dplyr::rename(main_gp_pop=main_gp_clon,
                color_main_gp_pop=color_main_gp_clon) %>% 
  right_join(gp_poplevel,by="main_gp_pop") 

# Information of the main gene pool for each clone
gps <- gp_poplevel %>% 
  right_join(gps, by="pop") %>% 
  arrange(clon) # The clone order has to be the same as in the genomic data


list(pop_level=gp_poplevel,
     clon_level=gps) %>% 
saveRDS(here("data/GenomicData/MainGenePoolInformation.rds"))
```

