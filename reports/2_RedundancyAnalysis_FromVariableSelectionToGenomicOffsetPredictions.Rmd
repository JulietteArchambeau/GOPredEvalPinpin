---
title: "Climatic variable selection, candidate SNPs identification, genomic offset predictions"
subtitle: "Based on RDA"
author: "Juliette Archambeau"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::html_document2:
    df_print: kable
    fig.caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: no
  pdf_document:
    toc: yes
    toc_depth: '4'
editor_options:
  chunk_output_type: console
bibliography: references.bib
always_allow_html: true
---


<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

<style type="text/css">
div.main-container {
  max-width: 2000px;
  margin-left: auto;
  margin-right: auto;
}
</style>




```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 600px;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=F)
options(width = 300)
library(knitr)      # CRAN v1.26
library(kableExtra) # CRAN v1.1.0
library(dplyr)      # CRAN v1.0.0
library(psych)      # CRAN v1.8.12 (pairs.panels function)
library(tidyverse)  # CRAN v1.3.0
library(raster)     # CRAN v3.3-13
library(stringr)    # CRAN v1.4.0
library(ggbiplot)
library(corrplot)
library(vegan)
library(xtable)
library(reshape2)
library(robust)
library(qvalue)
library(ggpubr)
library(magrittr)
```

```{r FunctionsAndVizOptions}
# Functions from other packages:
source("scripts/functions/corpmat.R") # to compute the matrix of p-value
source("scripts/functions/rdadapt.R") # to conduct a RDA based genome scan


# Function to generate a corrplot
GenerateCorrplot <- function(df,variables,fig.options){
  
  # correlation matrix
  cor <- cor(df[,variables]) 
  
  # matrix of the p-value of the correlation
  p.mat <- corpmat(cor)

  # Generate a correlation plot
  png(filename=fig.options$path,
      width=fig.options$width,
      height=fig.options$height,
      res=fig.options$res)
  corrplot::corrplot(cor, 
                     method="color", 
                     col=colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))(200),
                     type="upper", 
                     order="hclust",
                     addCoef.col = "black", # Add coefficient of correlation
                     tl.col="black", 
                     tl.srt=45, #Text label color and rotation
                   
                     # Combine with significance
                     p.mat = p.mat, 
                     sig.level = 0.01, 
                     insig = "blank",
                     
                     # hide correlation coefficient on the principal diagonal
                     diag=FALSE,
                     number.cex=0.6)
  dev.off()
  
}

# Function to build tables
KableMyDf <- function(x, boldfirstcolumn){
  x %>% 
  kable() %>%  
  kable_styling(bootstrap_options = c("stripped","hover", "condensed"), full_width = F) %>% 
  {if(boldfirstcolumn == TRUE) column_spec(., 1, bold = T) else .}
}
```

<br>


Most analyses conducted in this document are based on:

  - @forester2018comparing and the associated [vignette](https://popgen.nescent.org/2018-03-27_RDA_GEA.html). 
  
  - @capblancq2021redundancy and the associated [Github repository](https://github.com/Capblancq/RDA-landscape-genomics).
  

RDA can either be performed on *individual-based genotypes* (i.e. allele counts 0, 1 or 2) or *population-based allele frequencies*. @forester2018comparing suggests to use individual-based allele counts when most samples have individual coordinates and individual environment data (which depends on the resolution of the environmental data across the study area). In the present study, it seems more relevant to work with allele frequencies as several genotypes were collected at each sampling site (i.e. source population) and therefore experience the same climatic conditions. Moreover, the sample sizes varies across populations.

However, when I first conducted these analyses (in the third chapter of my PhD), I used *individual-based genotypes* because I accounted for the neutral population genetic structure with the ancestry coefficients from @jaramillo2015molecular, which are at the genotype level (i.e. proportion of gene pool assignment for each genotype). As the population genetic structure is highly confounded with the climatic gradients across the populations sampled (see section \ref(VarPart)), correcting for population structure with the ancestry coefficient most likely resulted in overcorrection for population structure. 

In the present document,  we will therefore use *population-based allele frequencies* to select the climatic variables with the stepwise selection procedure (section \ref(StepwiseSelection)), identify the candidate SNPs with RDA and calculate the genomic offset.

We only use the *individual-based allele counts* for variance partitioning in section \ref(VarPart), in which we estimate the relative contribution of climate, population structure and geography. Population structure is either accounted for with the ancestry coefficients at the genotype level from @jaramillo2015molecular (section \ref(VarPartInd)), either using the first PCs of a PCA based on *population-level allele frequencies* (section \ref(VarPartPop)).

  
# Downloading the data

## Genomic data


```{r LoadGenomicData}
# Individual-based allele counts
# ==============================
geno.ind <- read.csv("data/DryadRepo/ImputedGenomicData_AlleleCounts_NOMAF_454clones_9817snps.csv",row.names = 1) %>% 
  t() %>% 
  as.data.frame()

KableMyDf(geno.ind[1:10,1:10], boldfirstcolumn = T)


# Population-based allele frequencies
# ===================================
geno.pop <- read.csv("data/DryadRepo/ImputedGenomicData_AlleleFrequencies_NOMAF_34pops_9817snps.csv",
                     row.names = 1)

KableMyDf(geno.pop[1:10,1:10] %>% round(3), boldfirstcolumn = T)
```

The genomic dataset with *individual-based allele counts* contains `r nrow(geno.ind)` clones (i.e. genotypes) and `r ncol(geno.ind)` SNPs. The genomic dataset with *population-based allele frequencies* contains `r nrow(geno.pop)` populations and `r ncol(geno.pop)` SNPs.

RDA requires complete data frames (i.e., no missing data). Missing data were imputed based on the main gene pool of the clone, i.e. using the most common allele at each SNP (see report `1_FormattingGenomicData.Rmd`).

## Climatic data


### Load ClimateDT data 

Climatic data comes from the [Climate Downscaling Tool (ClimateDT)](https://www.ibbr.cnr.it/climate-dt/). Annual climatic variables were extracted between 1901 and 2098. 

**Reference period:** we use the annual values between 1901 and 1950 to capture the climatic conditions under which the populations have evolved. 


```{r LoadClimateDToutputs}
clim <- read_csv("data/DryadRepo/ClimateDT/ClimateDToutputs_Populations_1901_2098.csv",
               show_col_types = FALSE) %>% 
  dplyr::filter(Year<1951) %>%  # we keep the years btw 1901 to 1950
  group_by(ID) %>% # group by population
  summarise_all("mean") %>% # take the average of the annual values for the ref period 1901-1950
  dplyr::select(-Year) %>% 
  dplyr::rename(longitude=Longitude,
                latitude=Latitude,
                elevation=Elevation,
                pop=ID)

KableMyDf(clim[1:10,1:10], boldfirstcolumn = F)
```

The dataset contains `r nrow(clim)` populations and `r ncol(clim)-4` climatic variables. The description of the climatic variables is available [here](https://www.ibbr.cnr.it/climate-dt/?action=fldlist).

### Filtering the climatic variables

```{r IdCorrelatedClimaticVariables}
# Function to identify climatic variable with a correlation coeff higher than a given threshold
IdentifyCorrelatedVariables <- function(df,correlation.threshold){

# calculate the correlation matrix among the variables
clim.cor <- df %>% 
  dplyr::select(-pop,-elevation,-contains("itude")) %>% 
  cor()

# attribute NA to the lower triangle and diagonal of the matrix
clim.cor[lower.tri(clim.cor,diag=T)] <- NA

# build a dataframe with the correlated variables
clim.cor <- clim.cor %>% 
  melt() %>% 
  na.omit() %>% 
  dplyr::filter(value>correlation.threshold)

}

# we want to identify variables with a correlation coefficient higher than:
correlation.threshold <- 0.95

# we ran the function to identify the highly correlated variables
clim.cor <- IdentifyCorrelatedVariables(df=clim,correlation.threshold = correlation.threshold)

KableMyDf(clim.cor, boldfirstcolumn = F)
```

`r nrow(clim.cor)` pairs of variables have a correlation coefficient higher than `r correlation.threshold`.

We remove some variables so that there are no more pairs of variables with a correlation coefficient greater than `r correlation.threshold`.

We also remove the variables `MOP` and `AOP` because there is no metadata for these variables on the ClimateDT website.

We remove also some variables of low biological interest for maritime past adaptation or adaptation to future climate: `PAS` (precipitation as snow between August and July), `bio13` (precipitation of the wettest month).

When estimating exposure to climate change in section \ref(ExpCC), we saw that `bFFP` has weird future climatic values, so we remove it also. 

We remove `EPQ` (Emberger Pluviometric Quotient) because there is very low information about this variable in the litterature and its possible influence on forest trees.

```{r FilteringClimVariables}
clim.var.to.rm <- c("bio7","TD", # we keep bio4
                       "bio6","bio11","EMT","NFFD","eFFP", # we keep MCMT
                       "GDD0","GDD5", # we keep bio1
                       "bio17","bio18","bio14", # we keep MSP
                       "DMA","bio19","bio16", # we keep bio12
                       "bio2","CMD", # we keep Eref
                       "bio10", # we keep MWMT
                       "MOP","AOP", # we rm these variables because there is no metadata for them in the ClimateDT website!
                       "PAS","bio13", # low biological interest
                       "bFFP",
                       "EPQ"
                       )

clim <- clim %>% dplyr::select(-all_of(clim.var.to.rm))

# we check that there are no more pairs of highly correlated variables
IdentifyCorrelatedVariables(df=clim,correlation.threshold = 0.95) %>% nrow()
```

### Viz 

We can look at the distribution of the climatic variables.

```{r PlotDistributionClimaticVariables, fig.height=12, fig.width=15}
p <- clim %>% 
  dplyr::select(-pop,-contains("itude"),-elevation) %>% 
  pivot_longer(everything(),names_to="variable") %>% 
  ggplot(aes(x=value)) +  
  geom_histogram(aes(y=after_stat(density)), colour="blue",fill="white",bins = 34) +
  geom_density(alpha=.2,fill="pink") +
  facet_wrap(~variable,scales="free") + 
  theme_bw() 

p %>% ggsave(file="figs/ExploratoryAnalyses/DistributionClimaticVariables_selected.png",
               width=15,height=12)

p
```

We also generate a correlation plot and perform a PCA to look at the correlation among the remaining climatic variables.

```{r CorrelationsPanels,fig.height=9,fig.width=12}
# Chunk to generate figures to visualize the correlations among the climatic variables
fig.options <- list(
  path = "figs/ExploratoryAnalyses/CorrplotClimVariables.png",
  width=1000,
  height=1000,
  res=100)

GenerateCorrplot(df = clim, 
                 variables = colnames(clim)[-1], # we keep long, lat, elev and clim variables
                 fig.options = fig.options)


# Generate a PCA
pca <- prcomp(clim[,-1], center = TRUE,scale. = TRUE)

p <- ggbiplot(pca,varname.size =4) +  
  ylim(-4, 2.5) +    
  xlim(-3, 3) + 
  theme_minimal(base_size = 12)

ggsave(p,file="figs/ExploratoryAnalyses/PCAClimVariables.png",width=8,height=8,
       bg="white")
p
```



## Population genetic structure


### Ancestry coefficients

The proportion of gene pool assignment was estimated in @jaramillo2015molecular for each genotype with the *STRUCTURE* software.

```{r GenerateListDfIndividualLevel}
# We will store two datasets in a list: one with raw variables, the other one with mean-centered variables

listdf.ind <- list()

listdf.ind$df <- read.csv("data/DryadRepo/PopulationStructureCorrea2015.csv") %>% 
  filter(clon %in% rownames(geno.ind)) %>% # keep the same clones as in the genomic data
  unique() %>% 
  dplyr::rename(pop=prov) %>% 
  left_join(clim,by="pop") %>% # merge with the climatic variables
  dplyr::select(-max.Q) %>% 
  arrange(clon) # the clones have to be in the same order as in the genomic data.

# Run this line to check that the order of the clones in the genomic data and explanatory variables data is the same.
# identical(as.vector(listdf.ind$df$clon),rownames(geno.ind)) # should be TRUE 

KableMyDf(listdf.ind$df[1:10,1:14],boldfirstcolumn = F)


# create df with standardized variables (ie centered and scaled)
listdf.ind$df.sc <- listdf.ind$df %>% 
  dplyr::mutate(across(where(is.numeric), ~ (. - mean(.)) / sd(.)))

KableMyDf(listdf.ind$df.sc[1:10,1:14],boldfirstcolumn = F)
```


### PC scores

Another way to account for population structure in the RDA models is to use PCs from a *principal component analysis* (PCA) as proxies of the population evolutionary history. This is the method used in @capblancq2021redundancy.

As advised in @capblancq2021redundancy, the estimation of the population genetic structure should be performed on genomic data not filtered for minor allele frequencies because small genetic variations are expected to be involved in differentiating neutral genetic groups. So, we use *population-based allele frequencies* not filtered for MAF and imputed for missing data (based on the most common allele in the gene pool, see report `1_FormattingGenomicData.Rmd`).


```{r LoadImtGenDataMAF}
geno.pop.maf <-  read.csv("data/DryadRepo/ImputedGenomicData_AlleleFrequencies_MAF_34pops_10520snps.csv")

KableMyDf(geno.pop.maf[1:10,1:8], boldfirstcolumn = F)
```

We run the PCA with the `rda` function of the `vegan` package, which performs a PCA when no predictor is included.

```{r RunPCA, fig.height=4,fig.width=6}
pca <- rda(geno.pop.maf[,-1], scale=T)

# Screeplot of the PCA eigenvalues
screeplot(pca, type = "barplot", npcs=10, main="PCA Eigenvalues")
```

Based on the screeplot, retaining three or four PCs may be reasonable to account for neutral population structure in downstream analyses. 

In our case, we keep the first three PCs.

```{r GenerateListDfPopLevelNotScaled}
# We store two datasets in a list: one with raw variables, the other one with mean-centered variables

listdf.pop <- list()

listdf.pop$df <- data.frame(pop = geno.pop.maf[,1], # population id
                      PCs = scores(pca, choices=c(1:3), display="sites", scaling="none")) %>% #
  setNames(c("pop", "PC1", "PC2", "PC3")) %>% 
  inner_join(clim, by="pop")


# extract mean and variance of the PC scores
listdf.pop$df %>% 
  dplyr::select(contains("PC")) %>% 
  dplyr::summarise(across(everything(),list(mean=mean,sd=sd))) %>% 
  pivot_longer(everything()) %>% 
  mutate(PC = str_sub(name,1,3),
         index = str_sub(name,5,-1)) %>%
  dplyr::select(-name) %>% 
  pivot_wider(names_from="index",values_from="value") %>% 
  KableMyDf(boldfirstcolumn = F)
```

The PC scores have a mean of O but a standard deviation of 0.2, so we scale them too so that they have the same standard deviation as the climatic variables.

```{r GenerateListDfPopLevelNotScaled}
listdf.pop$df.sc <- listdf.pop$df %>% 
  dplyr::mutate(across(where(is.numeric), ~ (. - mean(.)) / sd(.)))

KableMyDf(listdf.pop$df.sc[1:8,1:9], boldfirstcolumn = F)
```


<!-- ## Standardize the variables -->


<!-- ```{r StandardizeVariables} -->
<!-- df.var.sc <- df.var -->

<!-- df.var.sc2 <- df.var.sc %>%  -->
<!--   dplyr::select(-c("pop","clon")) %>%  -->
<!--   scale(center=TRUE, scale=TRUE) -->

<!-- ## Recovering scaling coefficients -->
<!-- scale_coeff <- attr(df.var.sc2, 'scaled:scale') -->
<!-- center_coeff <- attr(df.var.sc2, 'scaled:center') -->

<!-- df.var.sc[,colnames(df.var.sc2)]  <-  df.var.sc2 -->
<!-- ``` -->

### Population main gene pool

We extract the main gene pool for each population.

```{r IdAdmixturePopulations}
# Split into dataframes specific to each population
gp.pop <- listdf.ind$df %>% 
  dplyr::select(clon,pop) %>% 
  left_join(read.csv("data/DryadRepo/PopulationStructureCorrea2015.csv") %>% dplyr::rename(pop=prov), by=c("pop","clon")) %>% 
  group_by(pop) %>% 
  group_split() %>% 
  setNames(unique(sort(listdf.ind$df$pop)))

# Are there some populations for which the main gene pool is not the same for all genotypes?
gp.pop %>% 
  map_dfr(\(x) {
    data.frame(pop = unique(x$pop),
               grou = x$max.Q %>% unique() %>% length())
  }) %>% 
  group_by(grou) %>% 
  group_split()  %>% 
  map_dfr(\(x) {
    data.frame(Populations = paste0(x$pop, collapse =", "),
               MainGenePoolNumber = unique(x$grou))
  }) %>% 
  KableMyDf(boldfirstcolumn = F)
```


The LEI and QUA populations have genotypes that belong to two different main gene pool, the main gene pool corresponding to the gene pool with the highest proportion of assignment from the STRUCTURE analysis in @jaramillo2015molecular.

We can visualize the admixture in the following tables.


```{r AdmixturePopulations}
gp.pop[["LEI"]] %>% KableMyDf(boldfirstcolumn = F)
gp.pop[["QUA"]] %>% KableMyDf(boldfirstcolumn = F)
```


```{r CreateNewColumWithMainGenePoolPopulations}
gp.pop <- gp.pop %>% 
  modify(\(x) mutate(x, mainGPpop= x$max.Q  %>% table() %>% which.max() %>% names())) %>% 
  list_rbind() %>% 
  dplyr::select(pop, mainGPpop) %>% 
  distinct()

# We add this column to the dataframes in  listdf.pop
listdf.pop <- listdf.pop %>% 
  modify(\(x) right_join(gp.pop,x,by="pop"))

KableMyDf(listdf.pop$df.sc[1:8,1:7], boldfirstcolumn = F)
```


# Selecting the climatic variables

## Criteria 1: exposure to climate change{#ExpCC}


For each climatic variable:

   + we calculate the *mean* and *standard deviation* of its annual values for the reference period 1901-1950: $\mu_{ref}$ and $\sigma_{ref}$, respectively.
  
  + we calculate the *Z-score* of each of its annual values $X$ for a given future period, such as *Z-score* = $(X - \mu_{ref})/\sigma_{ref}$


```{r CalculatingZscoreExposureCC,warning=F}
# Time window for future climates:
min.fut.clim <- 2023
max.fut.clim <- 2050

# Do we average the z-scores across future years?
avg <- FALSE

# We load ClimateDT outputs 
clim2 <-  read_csv("data/DryadRepo/ClimateDT/ClimateDToutputs_Populations_1901_2098.csv",
               show_col_types = FALSE)

# selected clim variables
var.clim <- colnames(clim2)[!colnames(clim2) %in% c("ID","Year","Longitude","Latitude","Elevation",clim.var.to.rm)]


# calculating the z-scores
zscores <- lapply(var.clim, function(x){
  
past.clim <- clim2 %>% 
  dplyr::filter(Year<1951) %>%  # keep 1901 to 1950
  dplyr::select(ID,all_of(x)) %>% 
  group_by(ID) %>% 
  dplyr::summarise_all(list(mean="mean",sd="sd"))

# z-scores
zcores <- clim2 %>% 
  dplyr::filter(Year>min.fut.clim & Year<max.fut.clim) %>% 
  dplyr::select(ID,Year,all_of(x)) %>% 
  dplyr::rename(var=x) %>% 
  left_join(past.clim,by="ID") %>% 
  dplyr::mutate(zscore=(var-mean)/sd) 

if(avg==TRUE){
  zcores <-  zcores %>% 
    group_by(ID) %>% 
    dplyr::summarise_at("zscore","mean")
} else{
  zcores <-  zcores %>% 
    dplyr::select(ID,Year,zscore)
}
  
}) %>% 
  setNames(var.clim) %>% 
  bind_rows(.id="var") 

# we sort the average z-scores (across populations and years) to determine 
# which climatic variables have the highest abs(Z-scores)
abs.mean.zscore <- zscores %>% 
  spread(var,zscore) %>% 
  mutate_if(is.numeric,abs) %>%
  dplyr::select(all_of(var.clim)) %>% 
  dplyr::summarise_all("mean") %>% 
  gather(variable, value) %>% 
  arrange(value)
```

```{r ViolinPlotExposureCC, fig.cap="\\large Deviation of future values of the climatic variables from the reference period 1901-1950. A point is specific to a given year and a given population", fig.height=10,fig.width=10, fig.align="center"}
# Violin plots
p <- zscores %>%
  mutate(var=factor(var,levels=c(abs.mean.zscore$variable))) %>% 
  ggplot(aes(x=var, y=zscore)) + 
  geom_jitter(shape=16,aes(colour = Year),position=position_jitter(0.2),size=0.5) +
  geom_violin(alpha=0.2) + 
  scale_colour_gradient2(low = "blue", mid="yellow",high = "red",midpoint=(max.fut.clim+min.fut.clim)/2) +
  coord_flip() +
  xlab("") + ylab("Z-scores") +
  theme_bw() +
  theme(legend.position=c(0.8, 0.7),
        legend.title = element_text(size = 18),
        legend.text = element_text(size = 15),
        axis.text = element_text(size = 14),
        axis.title = element_text(size=16))

p %>% ggsave(file="figs/ExploratoryAnalyses/ExposureClimateChange.png",
             width=10,height=10)
p
```

*Temperature*-related variables show the *highest deviations* from their distribution under the reference period 1901-1950 and also all show a consistent increase across populations and years.

*Precipitation*-related variables show *lower deviations* from their distribution under the reference period 1901-1950. Moreover, they do not show a consistent decrease across years and populations. 

**Notes on the graph interpretation:** Figure \@ref(fig:ViolinPlotExposureCC) quantifies the relative deviations of the values of the climate variables from their distribution over the reference period 1901-1950. The highest deviations of temperature-related variables do not imply that populations will be less affected by future changes in precipitation than in temperatures.  Indeed, for some climate variables, even minor changes can severely affect populations. For example, some populations may already be suffering from summer droughts and even a small decrease in precipitation could have dramatic consequences.

## Criteria 2: a predictive approach{#StepwiseSelection}

To select the variables of interest, we may also use a *predictive approach* using *RDA with stepwise selection*, where the goal is to *maximize the genetic variance* explained by a set of predictors [@capblancq2021redundancy].

For that, we use the selection procedure from the `ordiR2step` function of the package `vegan`. 

We have to specify two models:

  - a *null* model where the response is explained only by an intercept.

  - a *full* model including all variables. 
  
In the `ordi2step` function, the default criteria for including the variables is based on both *significance* of the newly selected variables, and the comparison of *adjusted variation* ($R^2_{adj}$) explained by the selected variables to $R^2_{adj}$ explained by the full model. If the new variable is not significant or the $R^2_{adj}$ of the model including this new variable does not exceed the $R^2_{adj}$ of the full model, the selection procedure stops.

We use the following stopping criteria: variable significance of p < 0.01 using 1000 permutations, and the $R^2_{adj}$ of the full model.  

```{r NumberStewiseSelectionModels}
# How many iterations of the stepwise selection procedure do we perform?
nbmodels <- 100
```


```{r StepwiseSelectionPopLevel, eval=F}
# we standardize the climatic variables
clim.sc <- clim %>% dplyr::mutate(across(where(is.numeric), ~ (. - mean(.)) / sd(.)))

# null model
rda.null <- rda(geno.pop ~ 1, clim.sc)

# formula full model
formula.full.model <- colnames(clim.sc)[!colnames((clim.sc)) %in% c("pop","elevation","latitude","longitude")] %>% 
  paste(collapse= " + ") # climatic variables
formula.full.model <- paste0("geno.pop ~ ",formula.full.model) %>% as.formula()

# full model
rda.full <- rda(formula.full.model, clim.sc)

# Stepwise selection with ordiR2step function
sumstepwise <- lapply(1:nbmodels, function(x) {
  mod <- ordiR2step(rda.null, rda.full, Pin = 0.01, R2permutations = 1000, R2scope = T)
  return(names(mod$CCA$envcentre))}) %>% 
  setNames(paste0("model",1:nbmodels)) %>% 
  ldply(function(x) data.frame(variables=x),.id="models") %>%  
  dplyr::summarise(count(variables)) %>% 
  setNames(c("variable","count"))

saveRDS(sumstepwise,file=paste0("outputs/VariableSelection/SummaryStepwiseSelection_PopLevel_",nbmodels,"models.rds"))
```

```{r SummaryStepwiseSelection}
sumstepwise <- readRDS(file=paste0("outputs/VariableSelection/SummaryStepwiseSelection_PopLevel_",nbmodels,"models.rds"))

KableMyDf(sumstepwise, boldfirstcolumn = F)
```


## Criteria 3: biological meaning and study goals

Study goals:

  - evaluate the genomic offset predictions with different methods.
  
  - provide GO estimates for the studied populations to identify populations that may be at risk of maladaptation under climate change (those estimates will be provided based on the "best performing" genomic offset predictions in the evaluation part).
  
### Variable selection for the evaluation part

Importantly, it may be relevant not to select the same climatic variables for the different study goals and evaluation methods. 

Indeed, seedling survival in common gardens after a strong summer drought is likely to be mainly impacted by the differences in adaptation to drought conditions among populations. So, it may be relevant to estimate a genomic offset based only on climatic variables capturing summer droughts, aka a *summer-drought genomic offset* (ie *summer drought GO*).

To evaluate genomic offset predictions using height of young trees in common gardens as a proxy of fitness, both winter and summer temperature and precipitation variables can be used as they may all impact tree growth. However, it may still be interesting to compare the *summer drought GO* predictions with the GO predictions based on climatic variables capturing both winter and summer conditions (ie *global-climate genomic offset*, *global-climate GO*), as winter conditions may also impact tree growth in common gardens. 

In natural populations, climate change can *directly* impact tree mortality through more and more frequent and intense summer droughts. In contrast, an increase in winter temperatures is highly unlikely to directly impact the death of adult trees. Therefore, to determine whether current mortality rates in natural populations may be attributed to maladaptation to summer drought conditions, it may be relevant to evaluate the association between *drought genomic offset* predictions and mortality rates in National Forest Inventory plots.
On the other hand, increased temperatures in winter can benefit to pests and pathogens, which can indirectly impact tree death. In such a case, it may also be relevant to evaluate the association between mortality rates in NFI plots and GO predictions considering both winter and summer climatic conditions.
Note that in the NFI, a tree is not counted as dead if its death is attributed to pests. However, mortality is a multifactorial process and it can be very difficult (if not impossible) to determine the relative contributions of climate, pests and other factors to tree death.

Evaluation of the genomic offset predictions with ecophysiological models: I have to read the paper of Cailleux-Petit et al. to determine whether it is relevant to evaluate both *summer drought GO* and *global-climate GO* predictions.

### Variable selection for providing GO predictions for the studied populations

According to previous studies, maritime pine populations show strong patterns of adaption to temperatures, and especially cold temperatures (eg [@grivet2011molecular]). Under climate change, cold temperatures are expected to increase in average at the location of the studied populations (Figure \@ref(fig:ViolinPlotExposureCC)). An increase in cold temperatures is unlikely to directly negatively impact the fitness of adult trees but it may impact the survival of young trees, the reproductive ability and the impact of pests and pathogens. 

Thus, for the second objective of this paper (which is to provide GO estimates for the studied populations), whether or not to include winter conditions in GO predictions is a tricky question, for which there is probably no correct answer. 

In this paper, we will follow the following workflow:

  - if the predictions of *summer-drought GO* or *global-climate GO* are consistently better across the different evaluation methods, then we will provide these GO predictions for the studied populations.
  
  - if the predictions of *summer-drought GO* or *global-climate GO* are not consistently better across the different evaluation parts, then we will provide both the *summer-drought GO* or *global-climate GO* predictions for the studied populations.


## Selected variables

### Summer-drought climatic variables

Selected variables:

  - `MSP`: the precipitation of driest quarter (in mm).
  
  - `MWMT`: the mean warmest month temperature (in °C).
  

`MWMT` will increase a lot under climate change => strong exposure to climate change.

```{r VizSelectedDroughtVar, fig.width=5,fig.height=5}
## Selected summer-drought variables
drought.var <- list(name="Summer-drought variables",
                   code="Droughtvar",
                   variables=c("MSP","MWMT"))
```

### Global-climate variables

Selected variables:

  - `bio1`: mean annual temperature (in °C). 
  
  - `bio12`: annual precipitation (in mm).
  
  - `MSP`: summer precipitation (in mm).
  
  - `MWMT`: the mean warmest month temperature (in °C).
  
  - `MCMT`: the mean coldest month temperature (in °C).
  
  - `bio15`: mean annual temperature (in °C). 
  
  - `bio3`: isothermality (`bio2`/`bio7`) (x100) (index) with `bio2` the mean diurnal range (mean of monthly (max temp - min temp)) and `bio7` the temperature annual range (`bio5`-`bio6`, with `bio5` the max temperature of warmest month and `bio6` the minimum temperature of the coldest month).
  
  - `bio4`: temperature seasonality (standard deviation x100) (in °C). 
  

`bio1`, and to a lesser extent `MWMT`, will increase a lot under climate change => strong exposure to climate change.

```{r VizSelectedGlobalVar, fig.width=10,fig.height=10}
## Selected global-climate variables
global.var <- list(name="Global-climate variables",
                   code="GCvar",
                   variables=c("bio1","bio12","bio15","bio3","bio4")) #"MCMT","MWMT", "MSP"
```


### Viz correlation

We can look at the correlation amon variables and with the PCs scores and geographic variables.

```{r VizCorrSelectedVariables, fig.height=12,fig.width=12}
fig.options <- list(
  path = "figs/ExploratoryAnalyses/CorrplotSelectedClimVariables.png",
  width=900,
  height=900,
  res=100)

corrplot.var <- colnames(listdf.pop$df)[colnames(listdf.pop$df) %in% c("longitude","latitude","PC1","PC2","PC3",global.var$variables)]

GenerateCorrplot(df = listdf.pop$df, 
                 variables = corrplot.var, # we keep long, lat, elev and clim variables
                 fig.options = fig.options)

listdf.pop$df %>%
  dplyr::select(all_of(corrplot.var)) %>%
  unique() %>%
  pairs.panels(scale=T,hist.col="palegreen1")
```


# Variance partitioning{#VarPart}

We want to disentangle the *relative contribution* of different factors in explaining genetic variation, namely:

  - *climate*, either captured by the *summer-drought* climate variables or the *global* climate variables.
  
  - *neutral population structure*, captured by the ancestry coefficients from @jaramillo2015molecular. 
  
  - *geography*, accounted for by the population coordinates (longitude and latitude).
  
  

We will run:

  - one *full* RDA with all factors (population structure, environment and geographical distance), i.e. no variable conditioning.
  
  - three *partial* RDA in which the factor of interest is conditioned by the other two factors.
  

  
```{r FunctionVarPart}
VarPart <- function(df.geno, select.clim.var, df.var, scale.rda, center.rda){

# The df of the explanatory variables has to include only the variables included in the model
df.var <- df.var %>% 
  dplyr::select(all_of(select.clim.var$variables),
                starts_with("Q"),
                starts_with("PC"),
                ends_with("itude"))


# Build formulas of the RDA models
# ================================
form.clim.var <- paste(select.clim.var$variables,collapse= " + ") # climatic variables
form.pgs.var <- colnames(df.var) %>% stringr::str_subset("^Q|^PC") %>%  paste(collapse= " + ") # pop structure
form.geo.var <- colnames(df.var) %>% stringr::str_subset("itude") %>%  paste(collapse= " + ") # coordinates

# complete model formulas
form.full.rda <- paste("df.geno ~ ",
                       paste(c(form.clim.var,form.pgs.var,form.geo.var),collapse=" + " )) %>% 
  as.formula()

form.clim.rda <- paste("df.geno ~ ",
                       form.clim.var,"+ Condition(",paste(c(form.pgs.var,form.geo.var),collapse=" + " ), ")") %>% 
  as.formula()

form.pgs.rda <- paste("df.geno ~ ",
                       form.pgs.var,"+ Condition(",paste(c(form.clim.var,form.geo.var),collapse=" + " ), ")") %>% 
  as.formula()

form.geo.rda <- paste("df.geno ~ ",
                       form.geo.var,"+ Condition(",paste(c(form.clim.var,form.pgs.var),collapse=" + " ), ")") %>% 
  as.formula()


# Run the RDA models
# ==================

# Full RDA
full.rda <- rda(form.full.rda, 
                data=df.var, 
                scale=scale.rda,
                center=center.rda) 
anova.full.rda <- anova(full.rda)

# Partial RDA: pure climatic model
clim.rda <- rda(form.clim.rda, 
                data=df.var, 
                scale=scale.rda,
                center=center.rda)
anova.clim.rda <- anova(clim.rda)

# Partial RDA: pure neutral population structure model
pgs.rda <- rda(form.pgs.rda, 
                data=df.var, 
                scale=scale.rda,
                center=center.rda)
anova.pgs.rda <- anova(pgs.rda)

# Partial RDA: pure geography model
geo.rda <- rda(form.geo.rda, 
                data=df.var, 
                scale=scale.rda,
                center=center.rda)
anova.geo.rda <- anova(geo.rda)


# Summary table
# =============

sum.tab.RDA <- tibble("RDA models"=c("Full model: Y ~ clim + geo + pgs.",
                      "Pure climate model: Y ~ clim | (geo + pgs)",
                      "Pure pop. gen. structure model: Y ~ pgs | (geo + clim)",
                      "Pure geography model: Y ~ geo | (pgs + clim)"),
       "Total exp. variance"=c(RsquareAdj(full.rda)[[1]],
              RsquareAdj(clim.rda)[[1]],
              RsquareAdj(pgs.rda)[[1]],
              RsquareAdj(geo.rda)[[1]]),
       "Relative exp. variance"=c(1,
                                  RsquareAdj(clim.rda)[[1]]/RsquareAdj(full.rda)[[1]],
                                  RsquareAdj(pgs.rda)[[1]]/RsquareAdj(full.rda)[[1]],
                                  RsquareAdj(geo.rda)[[1]]/RsquareAdj(full.rda)[[1]]),
       "P-value"=c(anova.full.rda[["Pr(>F)"]][[1]],
                   anova.clim.rda[["Pr(>F)"]][[1]],
                   anova.pgs.rda[["Pr(>F)"]][[1]],
                   anova.geo.rda[["Pr(>F)"]][[1]]))

# Export the table in latex
xtable(sum.tab.RDA, type = "latex",digits=2) %>% 
  print(file = paste("tables/VariancePartitioningRDA_",select.clim.var$code,".tex"), include.rownames=FALSE)

return(sum.tab.RDA)
}
```

## Individual-based allele counts{#VarPartInd}

```{r VartPartIndividualLevel, eval=F}
list.sumVarPart <- lapply(c(global.var,drought.var), function(x){

  VarPart(df.geno=geno.ind,
          select.clim.var=x,
          df.var=listdf.ind$df.sc, 
          scale.rda=F,center.rda=F)
}) %>% setNames(c(global.var$name,drought.var$name))

saveRDS(list.sumVarPart, file="outputs/RDA/SummaryVartPartIndividualLevel.rds")
```

```{r ShowSummaryVarPartIndividualLevel}
list.sumVarPart <- readRDS(file="outputs/RDA/SummaryVartPartIndividualLevel.rds")

# Global-climate variables
KableMyDf(list.sumVarPart[[1]], boldfirstcolumn = T)


# Summer-drought climatic variables
KableMyDf(list.sumVarPart[[2]], boldfirstcolumn = T)
```

## Population-based allele frequencies{#VarPartPop}

```{r VartPartPopLevel, eval=F}
list.sumVarPart <- lapply(list(global.var,drought.var), function(x){

  VarPart(df.geno=geno.pop,
          select.clim.var=x,
          df.var=listdf.pop$df.sc, 
          scale.rda=F,center.rda=F)
}) %>% setNames(c(global.var$name,drought.var$name))

saveRDS(list.sumVarPart, file="outputs/RDA/SummaryVartPartPopLevel.rds")
```

```{r ShowSummaryVarPartIndividualLevel}
list.sumVarPart <- readRDS(file="outputs/RDA/SummaryVartPartPopLevel.rds")

# Global-climate variables
KableMyDf(list.sumVarPart[[1]], boldfirstcolumn = T)


# Summer-drought climatic variables
KableMyDf(list.sumVarPart[[2]], boldfirstcolumn = T)
```


# Identifying loci under selection


Run a RDA for:
  
  - the 2 sets of climatic variables
  
  - with or without correction for PS
  

Select the SNPs
  
## Run the RDA
```{r FunctionToRunRDAmodels}
# Functions
# =========


# create a S3 object with the RDA model and some info
new_RDA <- function(form.rda,mod.rda,r2,eigenvalues,model.significance,axis.significance,vif){
  
  structure(
    .Data = list(form.rda=form.rda,
                 mod.rda=mod.rda,
                 r2=r2,
                 eigenvalues=eigenvalues,
                 model.significance=model.significance,
                 axis.significance=axis.significance,
                 vif=vif),
    creation_time = Sys.time(),
    class = "myrda"
  )
  
}

# function to print S3 object of class "myrda"
print.myrda <- function(x,...){
  
  print_message <- c(paste0("  RDA formula: ", myRDA$form.rda),
      paste0("  Creation time: ", format(attr(myRDA, "creation_time"))))
  
  cat(
    print_message,
    sep = "\n"
  )
  
}

# function to run the RDA models and store the info in a S3 object of class "myrda"
runRDA <- function(df,geno.pop,selected.variables,pop.structure.correction){

  # write RDA formulas
form.clim.var <- paste(selected.variables$variables,collapse= " + ")
if(pop.structure.correction==T) {
  form.pgs.var <- colnames(df) %>% stringr::str_subset("^PC") %>%  paste(collapse= " + ")
  form.rda <- paste("geno.pop ~ ", form.clim.var,"+ Condition(",paste(c(form.pgs.var),collapse=" + " ), ")")
} else {
  form.rda <- paste("geno.pop ~ ", form.clim.var) 
  }
mod.rda <- rda(as.formula(form.rda), df)
r2 <- RsquareAdj(mod.rda)
eigenvalues <- summary(eigenvals(mod.rda, model = "constrained"))
model.significance <- anova.cca(mod.rda, parallel=getOption("mc.cores")) # default is permutation=999
axis.significance <- anova.cca(mod.rda, by="axis", parallel=getOption("mc.cores"))
vif <- vif.cca(mod.rda)

return(new_RDA(form.rda=form.rda,
               mod.rda=mod.rda,
               r2=r2,
               eigenvalues=eigenvalues,
               model.significance=model.significance,
               axis.significance=axis.significance,
               vif=vif))
  
}



# function to visualize RDA model outputs 
vizRDA <- function(x){
  
  # check the class of x
  stopifnot("x is not of class myrda" = class(x)=="myrda")
  
  # Generate R2 table
r2.tab <- x$r2 %>% 
  as.data.frame() %>%
  pivot_longer(everything()) %>%  
  column_to_rownames(var ="name") %>% 
  round(2) %>% 
  ggtexttable(rows = row.names(.),cols = NULL, theme = ttheme("blank"))
  
  # Generate table of eigenvalues and proportion of variance explained
eigenvalues.tab <- x$eigenvalues %>% 
  as.data.frame() %>% 
  round(2) %>% 
  ggtexttable(rows = rownames(.), theme = ttheme("blank")) %>% 
  tab_add_hline(at.row = 1:2, row.side = "top", linewidth = 2)

  # Generate table of model and axis significance
signi.tab <- bind_rows(as.data.frame(x$model.significance[-nrow(x$model.significance),]),
          as.data.frame(x$axis.significance[-nrow(x$axis.significance),])) %>% 
  dplyr::mutate(across(!Df, ~ round(.x,3))) %>% 
  ggtexttable(rows = rownames(.), theme = ttheme("blank")) %>% 
  tab_add_hline(at.row = 1:2, row.side = "top", linewidth = 2) %>% 
  tab_add_hline(at.row = 3, row.side = "top", linewidth = 0.01)

  # Generate table for VIF (Variance Inflation Factors)
vif.tab <- x$vif %>% 
  as.data.frame() %>% 
  round(2) %>% 
  rownames_to_column("Variable") %>%
  pivot_wider(values_from=".", names_from = "Variable") %>% 
  ggtexttable(rows = "VIF", theme = ttheme("blank")) %>% 
  tab_add_hline(at.row = 2, row.side = "top", linewidth = 2) 
  
  # Generate the screeplot of the eigenvalues
ggscreeplot <- x$eigenvalues %>% #
  as.data.frame() %>% 
  dplyr::filter(row.names(.) == "Eigenvalue")  %>% 
  pivot_longer(everything(),names_to="PC",values_to="eigenvalues") %>%
  ggplot(aes(x= PC,
             y=eigenvalues,
             group=1)) +
  geom_point(size=4)+
  geom_line() +
  ylab("Eigen values") + xlab("") + 
  labs(title="Scree plot") + 
  theme_bw()


ggarrange(ggarrange(r2.tab,signi.tab,vif.tab,nrow=3),
           ggarrange(eigenvalues.tab,ggscreeplot,nrow=2), 
           nrow = 1, 
           ncol = 2) %>% 
annotate_figure(top = text_grob(x$form.rda, 
                                size = 16, 
                                color = 'black', 
                                face = 'bold'))
  
}
```



```{r}
# Combinations of selected variables and correction or not by population structure
rda.combinations <- list(
  list(selected.variables = global.var,
       pop.structure.correction = FALSE),
  list(selected.variables = global.var,
       pop.structure.correction = TRUE),
  list(selected.variables = drought.var,
       pop.structure.correction = FALSE),
  list(selected.variables = drought.var,
       pop.structure.correction = TRUE))


# Run the RDA models and store their information
lists.rda <- lapply(rda.combinations, function(x){
  runRDA(df = listdf.pop$df.sc,
         geno.pop = geno.pop,
         selected.variables = x$selected.variables,
         pop.structure.correction = x$pop.structure.correction)})

# save the RDA models and their information
saveRDS(lists.rda, "outputs/RDA/RDAmodels.rds")

# viz RDA models and their information
pdf(width = 10, height = 6, "figs/RDA/RDAsummary.pdf")
lapply(lists.rda, vizRDA)
dev.off()
```


## Identify outliers



```{r}
## Running the function with K = 2
GSout <- rdadapt(RDA, 2)

## P-values threshold after Bonferroni correction
thres <- 0.01/length(GSout$p.values)

## Identifying the loci that are below the p-value threshold
outliers <- which(GSout$p.values<thres)
outliers <- data.frame(Loci = colnames(geno.pop)[outliers], 
                       p.value = GSout$p.values[outliers], 
                       contig = unlist(lapply(strsplit(colnames(geno.pop)[outliers], 
                                                       split = "_"), function(x) x[1])))




```


# References
